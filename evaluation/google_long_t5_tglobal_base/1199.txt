ABSTRACT: 
This paper demonstrates the feasibility and usefulness of survey research asking respondents to report voting probabilities in hypothetical election scenarios. Posing scenarios enriches the data available for studies of voting decisions, as a researcher can pose many more and varied scenarios than the elections that persons actually face. Multiple scenarios were presented to over 4000 participants in the American Life Panel (ALP). Each described a hypothetical presidential election, giving characteristics measuring candidate preference, closeness of the election, and the time cost of voting. Persons were asked the probability that they would vote in this election and were willing and able to respond. We analyzed the data through direct study of the variation of voting probabilities with election characteristics and through estimation of a random utility model of voting. Voting time and election closeness were notable determinants of decisions to vote, but not candidate preference. Most findings were corroborated through estimation of a model fit to ALP data on respondents' actual voting behavior in the 2012 election. 
 
PREDICTION: 
25 Figure 1: Screen viewed by respondents for one particular election scenario Your ratings for the feeling thermometer Candidate A 60 Candidate B 40 Forecast by a major poll the week before the election Percent chance that Candidate A will win the election 70 Percent chance that Candidate B will win the election 30 Percent chance that the vote margin between the two candidates will be less than 2% 85 Time it will take you to go to voting place and vote Percent chance it will take you less than 1 hour 10 Percent chance it will take you more than 1 hour 90 26 Figure 2: Distribution of probability of voting across the 24 scenarios 0.05.1.15.2.25Fraction0 10 20 30 40 50 60 70 80 90 100probability of voting27 Table 1: Characteristics of respondents who participated in at least one wave Characteristics All Persons whose voting probabilities varies across choice sets Always voters Never voters Non-credible respondents Female 59.9 60.9 57.5 56.0 42.9 Married 58.8 57.0 63.2 66.7 57.1 Working 58.2 57.7 59.2 66.7 28.6 White 77.5 74.7 84.7 88.0 71.4 Black 12.0 12.8 9.9 6.7 14.3 Latino 17.0 20.4 8.1 10.7 28.6 Less than than 30 years old 13.1 14.8 7.5 28.0 14.3 30 to 39 years old 17.3 18.8 12.5 24.0 14.3 40 to 49 years old 17.0 17.2 16.7 13.3 14.3 50 to 59 years old 24.2 23.1 27.9 18.7 14.3 60-69 years old 18.9 17.6 22.8 13.3 14.3 70+ years old 9.6 8.6 12.6 2.7 28.6 0-12 years of education 23.7 27.6 11.6 46.7 14.3 13-15 years of education 39.3 38.6 40.6 44.0 57.1 16+ years of education 37.0 33.8 47.8 9.3 28.6 Voted in November 2012 elections 84.4 80.7 99.0 9.4 100.0 Voted for Obama 57.4 59.5 52.8 50.0 60.0 Thermometer rating for Obama 53.1 54.1 51.3 35.0 41.5 Thermometer rating for Romney 41.9 41.1 44.1 32.9 45.0 Probability voting takes more than 1 hour 14.7 16.5 10.4 15.2 1 
 
FULL TEXT: 
  The research of Adeline Delavande was supported by the UK Economic and Social Research Council through the MiSoC research center. The research of Charles F. Manski was supported in part by the US National Institute of Health through grant P01AG026571-07. We are grateful to anonymous reviewers for their comments. 1 1. Introduction Social scientists have long struggled to understand why persons vote in large elections and why turnout varies across elections. See Aldrich (1993), Feddersen (2004), Geys (2006a, b) and Smets and van Ham (2013) for review articles. When performing empirical research on voting, it is natural to think first of analyzing data on actual elections. Aggregate data on turnout at the district or other geographic level are readily available and occasionally enable creative analysis as natural experiments (e.g. Brady and McNulty, 2011). However, these data do not describe individual voters and hence are ordinarily not well-suited to study interpersonal variation in decisions to vote. Surveys of individuals can provide richer data by asking persons to report their voting behavior, socioeconomic-demographic attributes, and their perceptions of election characteristics. However, surveys of voting in actual elections have significant limitations. First, persons typically face actual elections only once every two or four years. Second, there may not be much temporal variation in the characteristics of candidates and other aspects of actual elections. Third, although theories of voting commonly consider an idealized setting in which a person chooses whether to participate in an isolated election for a single office, actual decisions to vote usually occur in a complex environment with contemporaneous elections for multiple offices and possibly ballot initiatives as well. Given these limitations of data on actual elections, we think it useful to also perform empirical studies that pose hypothetical election scenarios and ask persons how they would vote in these scenarios. Data of this type can overcome the three limitations of data on actual elections. The researcher can pose many more scenarios than the number of elections that 2 persons actually face. The researcher can design the scenarios to exhibit considerable variation in the characteristics of candidates and other aspects of the election. And one can pose scenarios that hypothesize an isolated election. Of course studies of voting in hypothetical elections are not a panacea. One concern is that the responses that persons give may differ from the way that they would actually behave. Another is that the scenarios that a researcher can pose in practice inevitably omit some features of the environment that a person would face in an actual election. These concerns are legitimate, but studies of hypothetical elections can still usefully add to the empirical evidence currently available for analysis of decisions to vote. The broad precedent for our study is a long history of applied econometric research that poses choice scenarios, asks persons to state the choices they would make in these scenarios, and uses the data to estimate random-utility models of choice behavior, in the same manner that data on actual choices would be used. See, for example, Beggs, Cardell, and Hausman (1981), Fischer and Nagin (1981), Louviere and Woodworth (1983), Manski and Salomon (1987), and Ben-Akiva and Morikawa (1990). Our specific precedents are the methodological and empirical studies of Manski (1999) and Blass, Lach, and Manski (2010). Manski (1999) reasoned that stated choices may differ from actual ones because researchers provide respondents with different information than they have when facing actual choice problems. The norm has been to pose incomplete scenarios, ones in which respondents are given only a subset of the information they would have in actual choice settings. When scenarios are incomplete, stated choices cannot be more than point predictions of actual choices. Elicitation of choice probabilities overcomes the inadequacy of stated-choice analysis by 3 permitting respondents to express uncertainty about their behavior in incomplete scenarios. Manski (1999) showed how elicited choice probabilities may be used to estimate random utility models with random coefficients. Blass, Lach, and Manski (2010) used the methodology to estimate consumer preferences for electricity reliability. The present paper uses it to estimate a random utility model of voting decisions, the data being voting probabilities in hypothetical elections. The broad idea of measuring choice intentions probabilistically has much precedent, dating back to Juster (1966). See Manski (2004), Hurd (2009), and Delavande (2014) for review articles. Eliciting choice intentions probabilistically might be viewed as more cognitively demanding than eliciting them verbally, yet previous research has amply illustrated its feasibility by showing that most respondents are able to respond meaningfully in probabilistic terms when asked about events germane to their lives. Probabilistic measurement of voting intentions in actual elections has recently been implemented on a large scale in the American Life Panel (ALP). Delavande and Manski (2010, 2012) study the voting probabilities that ALP respondents reported prior to the 2008 presidential election and the 2010 congressional and gubernatorial elections. Kapteyn, Meijer, and Weerman (2014) study voting probabilities reported prior to the 2012 presidential election. The present study differs from the above research using ALP data in two important respects. First, it analyzes data on voting probabilities in hypothetical elections rather than voting probabilities prior to actual elections. Second, it uses the data to study how the decision to vote varies with the characteristics of the election. Section 2 describes the ALP, the design of the election scenarios, and the sample whose responses we analyze. Section 3 uses the data to examine the decision to vote. We first present 4 suggestive findings on the univariate variation of voting probabilities with election characteristics. We next explain the structure and estimation of the random utility model. We then pose a particular model specification and present the parameter estimates. To close the empirical analysis, we compare the estimates with those of a similar model estimated using ALP data on respondents' actual voting decisions. Section 4 discusses what we have learned substantively about voting and methodologically about survey research posing hypothetical election scenarios. 2. Data Description 2.1. The American Life Panel The American Life Panel is a national longitudinal survey of Americans of age 18 and older, begun by RAND in 2003. Since its start, the ALP has expanded from about 500 to roughly 4,500 respondents. The ALP recruits participants from several sources, including representative samples of the population and convenience samples.1 The ALP sampling process yields a wide spectrum of participants. However, respondents over-represent some demographic groups relative to others. The first column of Table 1 describes the composition of the 4,329 participants who responded to at least one of the three survey waves that posed hypothetical election scenarios. These waves were conducted several weeks apart in November and December 2012 following the presidential election. Only U.S. citizens were invited to respond to the election questions. 1 For details see https://mmicdata.rand.org/alp/index.php?page=panelcomposition 5 Relative to the population of the United States, the participants were more often female (60 percent) and college educated (37 percent with 16 or more years of schooling compared to 28 percent in the 2010 census; U.S. Census Bureau, 2013). They were similar in terms of ethnic group (12 percent Black and 17 percent Latinos) and proportion of adults above age 65 (18 percent). Among panel members who participated in at least one of the three waves with hypothetical election scenarios, 60 percent participated in all waves and 24 percent in two. [Table 1 here] 2.2. The Hypothetical Election Scenarios ALP panel members participating in the three survey waves were asked their intention to vote in a set of hypothetical presidential elections. Each scenario presented several election characteristics: (i) how much the participant likes each of the candidates, as measured on a thermometer scale previously used in the American National Election Survey, (ii) the closeness of the election as measured by a poll, and (iii) how costly it may be to vote in term of time. As pointed out in the introduction, these are expected to be salient election-specific determinants of the decision to vote. The wording used to describe the hypothetical elections was as follows: We now would like you to consider whether you would choose to vote in several hypothetical U.S. presidential elections with two candidates: Candidate A and Candidate B. In each case, we will ask you to imagine that 6 (a) You have specified assessments of the candidates in terms of the feeling thermometer. (Ratings between 50 degrees and 100 degrees mean that you feel favorable and warm toward the person. Ratings between 0 degrees and 50 degrees mean that you don't feel favorable toward the person and that you don't care too much for that person. You rate the person at the 50 degree mark if you don't feel particularly warm or cold toward the person.) (b) You know the results of a major poll released a week before the election (c) It takes you a specified amount of time to go to your voting place and vote. Figure 1 shows the screen that participants saw with the characteristics of the election. [Figure 1 here] Respondents faced eight distinct scenarios in each survey wave, totaling twenty four in all. The thermometer rating for Candidates A and B respectively could take two different values (60-40 and 20-80). The polling data included the percent chance that A will win the election (with one of the three values 70%, 50% and 30%) and the percent chance that the vote margin between the two candidates will be less than 2% (with one of the two values 25% and 85%). The time required to vote was specified as the percent chance that it will take less than one hour to vote (with one of the two values 10% and 90%). The twenty-four scenarios represent all possible combinations of these values.2 The order of presentations of the scenarios was the same for all respondents. 2 The twenty-four scenarios thus include settings in which the two items of polling data take all combinations of values. One might question whether an election could realistically have an 85 percent chance of a vote margin less than 2% and a 70-30 chance that a particular candidate will win. These two 7 Voting intentions for each scenario were elicited using a probabilistic format with the following question: In this scenario, what do you think is the percent chance that you would go to your voting place and vote in the hypothetical presidential election? Probabilistic polling is an alternative to verbal questioning that asks persons to state, in percent-chance terms, the likelihood that they will vote and for whom. The objective is to provide readily interpretable, interpersonally comparable, quantitative measures of the uncertainty that persons perceive about their voting behavior. Delavande and Manski (2010) found that responses to traditional verbal polling and probabilistic questions regarding an actual presidential election were well-aligned ordinally. Moreover, the probabilistic responses predicted actual voting behavior beyond what was possible using verbal responses alone. The item non-response rates in our study are very low, varying between 1.5% and 4.6% depending on the scenario. Thus, respondents are willing to express their voting intention in probabilistic format. A bit of respondent fatigue over the 24 scenarios can be seen, with a slight increase in the item non-response rate at wave 3 (above 3.2% for all 8 scenarios) compared to wave 1 (below 2% for all 8 scenarios), but nonresponse was still quite low even in wave 3. To assess the reliability of responses to the questions about hypothetical elections, we repeated in waves 2 and 3 a scenario that respondents had already encountered in wave 1. We found that 47 and 50 percent of the respondents provided the exact same responses at waves 2 and 3 respectively. The median differences in answers compared to wave 1 were 0 at both waves items of polling data are consistent in principle. In particular, they could co-occur in an election with a polarized populace in which one political party has a few percent more adherents than the other. 8 2 and 3, and the mean differences were 1.7 and 0.5 respectively. These very small differences give re-assurance that participants thought about the scenario and answered seriously. Further evidence that participants answered seriously will be given in Sections 2.3 and 3.4, where we compare voting probabilities in the hypothetical scenarios with actual voting behavior in the 2012 election. 2.3. The Analytical Sample Inspecting the voting probabilities that persons reported across the scenarios in which they participated, we found that 72.7 percent (3117 persons) sometimes expressed uncertainty about whether they would vote. Of the rest, 26 percent (1130 persons) gave a 100% chance of voting in every scenario and 1.7 percent (75 persons) always gave a 0% response. A negligible 0.002 percent (7 persons) reported 100% to all scenarios in one wave and 0% to all scenarios in another wave. Our analysis of voting decisions focuses on the first group, whose voting probabilities vary across scenarios. We refer to this group as the analytical sample. We call the second group always voters and the third group never voters. It seems evident that the decision to vote for always voters and never voters are based on different criteria than those we study. The fourth tiny group appear not to have answered the survey seriously, so we call them non-credible respondents. Table 1 describes the characteristics of the four groups. Always voters are more likely to be white, non-Latino, older and more educated than are members of the analytical sample. Consistent with their answers to the hypothetical scenarios, 99 percent of the always voters 9 reported that they actually voted for president in 2012. Never voters are more likely to be white, non-Latino, younger and less educated than are members of the analytical sample. Consistent with their answers to the hypothetical scenarios, only 9 percent of the never voters reported that they actually voted for president in 2012. The group of non-credible group is too small for its characteristics to be usefully compared with the other groups. Relative to the population of the United States, the composition of the analytical sample is more female (61 percent) and college educated (34 percent with 16 or more years of schooling). The group is more likely to actually vote than the general population. Whereas 81 percent of the analytical sample reported in a post-election survey that they had voted for president in 2012, the national turnout is estimated to have been about 58 percent (McDonald, 2012). The analytical sample also appears more Democrat than the general population, with 60 percent reporting having voted for Barack Obama, compared to 51 percent in the general population. Figure 2 presents the distribution of voting probabilities in the analytical sample across the twenty-four election scenarios. It shows overall high voting intention. The most common answer is 100% (26 percent of the answers), followed by 50% (11 percent) and 90% (10 percent). Figure 2 also shows substantial heterogeneity in voting probabilities and use of the whole range from 0 to 100%. The median and mean responses are 85% and 72% respectively. We think that the relatively high voting probabilities reported by APL respondents stems mainly from the fact that the panel over-represents groups who vote at a higher rate than the electorate. However, a contributing reason may be overreporting of voting, as found by Belli, Traugott, and Beckmann (2001) in their comparison of self-reports of voting on the American National Election Survey (ANES) with administrative data from voting records. We conjecture 10 that ALP self-reports suffer less from overreporting than do ANES ones. The methodological literature suggests that responses to internet surveys may be more accurate due to the absence of an interviewer, with consequent reduction of social desirability bias (Bradburn and Sudman, 1979; Tourangeau and Smith, 1996). [Figure 2 here] 3. The Decision to Vote 3.1. Univariate Variation of Voting Probabilities with Election Characteristics As prelude to specification and estimation of a random utility model of voting, we examined how voting probabilities vary with each election characteristic given in a scenario, taken one at a time. Table 2 presents the findings, which hint at what we will find with formal modelling of decision making. Each row of the table holds one election characteristic fixed and presents the mean, median, and other quantiles of the voting probabilities across all scenarios having the fixed characteristic. The row sample sizes are quite large, being about 29,000 for those characteristics that take two values in our design and 19,000 for the election-closeness characteristic that takes three values. [Table 2 here] 11 Travel time yields the largest variation in voting probabilities. The mean voting probability is 75.2% when the scenario specifies a 10% chance that voting will take more than one hour and is 68.0% when it specifies a 90% chance that voting will take more than one hour. The median voting probabilities are 90% and 80% respectively. Each scenario provides two measures of the closeness of the election---the chance that each candidate will win and the chance that the vote margin will be less than 2 percent. Voting probabilities vary more with the former than with the latter. The mean voting probability is 73.4% when the poll states an even chance that each candidate will win and is 71.2% or 70.1% when the poll states that candidate A or B respectively is favoured to win. The median voting probability is 90% when the poll states an even chance for each candidate and drops to 80% when one candidate or the other is favoured. The specified chance that the vote margin will be less than 2% barely affects the mean probability of voting, it being 71.9% when the poll gives a high chance of a small vote margin and 71.3% when it gives a low chance. The median voting probabilities are 85% and 80% respectively. While the magnitudes of these univariate associations vary, the directions are all consistent with usual thinking about instrumental voting. The findings regarding candidate preference are a slight anomaly. Theories of instrumental voting, as well as some theories of expressive voting, predict that persons have more incentive to vote if they strongly prefer one candidate over the other. Using the feeling thermometer to indicate strength of candidate preference, however, we find that voting probabilities tend to be a bit higher when preference is weak. The mean voting probability is 72.2% when candidates A and B have 60/40 ratings and 71.0% when they have 20/80 ratings. The median voting probabilities are 85% and 80% respectively. 12 For completeness, we present in Appendix Table A1 the mean and median voting probabilities for all 24 scenarios. It shows that the mean (median) varies between 66% and 78% (75% and 90%) across the various scenarios. 3.2. The Random Utility Model Specification and estimation of a random-utility model of decision making provides an effective way to investigate how election characteristics and personal attributes jointly influence voting probabilities. We use the same model structure and estimation methods as Manski (1999) and Blass, Lach and Manski (2010). To begin, we assume that the utility of individual i from alternative j (j = 1 if i votes and 0 otherwise) has the random-coefficients form Uij = xijŒ≤i + Œµij . (1) Here xij is a specified function of election characteristics and personal attributes that are observable by both the decision maker and the researcher when scenarios are posed and that also would be observable in an actual choice setting. In our context, xij is a function of the election characteristics presented in an ALP scenario and of the personal attributes reported by ALP participants. The additive utility component Œµij would be observable by the decision maker in an actual choice setting but is not part of the information presented in an ALP scenario. For example, Œµij might depend on other election characteristics such as the policy positions and ethnicities of the candidates. Let xi ‚â° (xij, j = 0, 1) and Œµi ‚â° (Œµij, j = 0, 1). 13 Eliciting voting probabilities enables ALP respondents to express uncertainty about Œµi, and, hence, about their voting behavior. It permits a person to treat Œµi as a vector of utility components whose value is not known when responding to the choice scenario but which would be known in an actual choice setting. Formally, we assume that person i forms a continuous subjective distribution for Œµi, say Qi, derives the subjective probability that he would vote in an actual choice setting, and reports this subjective probability as his response to a scenario. If person i has utility function (1), the subjective voting probability is the probability that he places on the event that the realizations of Œµi will make voting optimal. Thus, we assume that the reported voting probability is qi = Qi[xi1Œ≤i + Œµi1 > xi0Œ≤i + Œµi0]. (2) The standard practice in stated-choice analysis has been to assume that the components of Œµi are objectively i. i. d. with the extreme-value distribution. Suppose that respondents make the same assumption subjectively. Then voting probability (2) has the logit form qi = ùëíxi1Œ≤iùëíxi0Œ≤i+ùëíxi1Œ≤i. (3) Applying the log-odds transformation to (3) yields the linear mixed-logit model (McFadden and Train, 2000) ùëôùëô ÔøΩqi1‚àíqiÔøΩ = (xi1 ‚àí xi0)Œ≤i = (xi1 ‚àí xi0)b + ui1, (4) 14 where Œ≤i = b + ùúÇùëñ and ui1 = (xi1 ‚àí xi0)ùúÇùëñ. Finally, assume that the cross-sectional distribution of Œ≤, hence Œ∑, is statistically independent of x. Without loss of generality, set E(Œ∑) = 0 as a normalization. It then follows that b = E(Œ≤), E(u‚îÇx) = 0, and (4) is the linear mean regression model ùê∏ ÔøΩùëôùëô ÔøΩqi1‚àíqiÔøΩÔøΩ xÔøΩ = (xi1 ‚àí xi0)b. (5) If model (5) is taken literally, the mean preference parameters b may be consistently estimated by least squares, without need to assume anything about the shape of the distribution of Œ≤. This contrasts with standard econometric analysis, where the researcher must specify a parametric family of distributions for Œ≤. However, we cannot take the model quite literally. As shown in Figure 2, respondents tend to round their responses to the nearest five or ten percent. Such minor rounding has been found to be commonplace in elicitation of subjective probabilities; see Manski and Molinari (2010). Rounding of interior subjective probabilities (say, from 47 percent to 50 percent) is relatively unproblematic. However, rounding of values near zero and one raises a serious difficulty due to the sensitivity of the log odd function near the boundaries of the [0, 1] interval. At the extreme, over a quarter of the respondents report voting probabilities equal to zero or one, thus generating log odds that equal minus or plus infinity. Hence, least squares estimation breaks down.3 3 One should not drop the cases with choice probabilities equal to zero or one, because this truncates the sample in a response-based manner. One might consider an ad hoc transformation of reported zeroes and ones to values near these boundaries, but the least squares estimates may be sensitive to the transformation performed. 15 The inference problem can be resolved if preferences are symmetrically distributed with center at b. Then the unobserved uij are symmetrically distributed about zero conditional on xi and, hence, have median zero conditional on xi. Thus, we have the linear median regression model ùëÄ ÔøΩùëôùëô ÔøΩqi1‚àíqiÔøΩÔøΩ xÔøΩ = (xi1 ‚àí xi0)b, (6) whose parameters may be estimated by least absolute deviations (LAD). A well-known robustness property of the median of a random variable is its invariance to transformations that do not alter the ordering of values relative to the median. In our empirical analysis, we transform voting probabilities of zero and one to 0.001 and 0.999 respectively.4 We then estimate model (6) by LAD to estimate the center of symmetry of the preference distribution. 3.3. Model Specification and Parameter Estimates Tables 3 and 4 present estimates for a model that specifies x as a vector of binary variables describing election characteristics and personal attributes. As shown in Table 3, the personal attributes measure sex, marital status, ethnicity, working status, years of education, and age. The specification includes four variables that summarize the election characteristics presented in a scenario: (i) strength of candidate preference, measured by a variable that equals 4 If y is a random variable with median M, then M is also the median of any function f(y) such that ( )y M f y M< ‚áí < and ( ) .y M f y M> ‚áí > This holds even if the function f transforms small values of y to -‚àû and large ones to ‚àû, or vice versa. Hence, equation (6) continues to be the same linear median regression if subjective probabilities equal to zero and one are replaced by values close to zero and one. 16 one if the thermometer ratings for candidates A and B are 20-80 and zero if the rating is 60-40; (ii) closeness of the election, measured by a variable that equals one if the probability that A wins is 50% and zero otherwise; (iii) interaction of candidate preference and closeness of the election, measured by a variable that equals one if both variables (i) and (ii) equal one and equals zero otherwise; and (iv) voting time, measured by a variable that equals one if the probability that voting will take more than one hour is 90% and equals zero if the probability is 10%. The model does not include a variable measuring the polling report of the chance of a small vote margin. The univariate findings of Section 3.1 and the summary statistics in Table A1 indicate that the information on the vote margin given in a scenario had negligible effect on voting probabilities. This finding was corroborated in exploratory analysis in which we estimated models using only data on certain scenarios: (i) scenarios with close elections, in which the probability that A wins is given as 50%, and (ii) scenarios that exclude non-close elections in which the probability of a vote margin less than 2% is given as 85%. It may be that vote margin was a difficult concept for respondents to grasp. Alternatively, respondents may understand the concept but not use forecasts of vote margin when they decide whether to vote. Table 3 presents the LAD estimate of the center of symmetry of the preference distribution. Beneath each parameter estimate is a standard error.5 The parameter estimates show, as suggested earlier by the univariate findings, that voting probabilities rise when the scenario describes a close election and a short waiting time to vote. The estimate associated with 5 Recall that the unobserved component of utility in equation (4) has the form .)( 1 iiijij xxu Œ∑‚àí= Thus, the random parameter specification implies that u is heteroskedastic and that it is correlated across the scenarios faced by a given sample member. These features of u do not affect the consistency of LAD estimation but do affect statistical inference. We obtained the standard errors of the parameter estimates by cluster bootstrapping the sample. Cluster bootstrapping means that, to generate a pseudo-estimate of the parameters, we drew respondents with replacement from the actual sample of respondents and used the data on all of the scenarios faced by these persons to re-estimate the model. We repeated this process 500 times to generate 500 pseudo estimates of b. The reported standard errors are the standard deviations of these 500 pseudo estimates. 17 voting time is 2.5 times larger than the one for closeness of the election, strengthening the univariate finding that voting time is an important determinant of voting decisions. Both coefficients are precisely estimated. Contrary to various theories of voting but in line with the univariate findings, the parameter estimates indicate that having a strong preference for a candidate does not increase the probability of voting. The estimated effect is close to zero in a close election (-0.105 + 0.111) and negative (-0.105) when the poll indicates that the election is not close. Considering personal attributes, we find that Latinos are less likely to vote, while white, married, older and more educated participants are more likely to vote.6 Appendix Table A2 presents alternative parameter estimates computed by least squares and shows similar patterns. [Table 3 here] To obtain further perspective on the implications of the parameter estimates for voting, Table 4 shows how changing one variable at a time affects the predicted probability of voting relative to a baseline value of x and Œ≤. As baseline, we set Œ≤ equal to the estimate of the center of symmetry of the preference distribution given in Table 3. We set x = (female, married, working, white, non-Latino, aged 50 to 59, 13 to 15 years of education, with an election scenario where the ratings for candidates A and B are 60-40, the poll indicates that the election is not close, and the probability that it will take more than one hour to vote is 10%). The predicted voting probability for this baseline case is 91.6%. Varying the election characteristics one at a time, we find that increasing the voting time reduces the predicted probability of voting by 7.2%. Changing the scenario to one where the poll predicts a close election increases the predicted 6 These findings are broadly consistent with recent empirical evidence on the association of personal attributes with voting rates in actual elections; see Smets and van Haan (2013). 18 probability of voting by 1.9%. Considering personal attributes, changing education to 12 years or less reduces the predicted probability by 7.7%, while changing it to 16 years or more increases the predicted probability by 4.2%. [Table 4 here] 3.4. Comparison with a Logit Model of Actual Voting We observed in the Introduction that a concern with analysis of stated choice data is that the responses persons give when facing hypothetical scenarios may differ from the way that they would actually behave. In Section 2.3 we gave initial evidence of the consistency of stated voting probabilities and actual voting decisions, namely that 99 percent of the always voters and only 9 percent of the never voters reported that they had actually voted in the 2012 presidential election. In this section, we provide further evidence by examining the actual voting decisions of a sub-sample of 1923 members of the analytical sample for whom we have complete data. In September-October 2012, ALP respondents were asked to report their personal thermometer ratings for Barack Obama and Mitt Romney. Table 1 shows that the mean response in the analytical sample was 54 for Obama and 41 for Romney (column 2). Persons were also asked to report the percent chance that it would take them more than an hour to vote.7 Here the 7 Specifically, they were asked to ‚Äúthink about the time it will take to go to [their] voting place and vote if [they] do vote in the presidential election on November 6th 2012‚Äù and to report the percent chance that it will take (i) less than 30 minutes, (ii) at least 30 minutes but less than one hour, (iii) at least one hour but less than two hours and (iv) at least two hours. (taking into account both the time it takes to go to the voting place and the waiting time to cast a ballot). We keep respondents whose answers sum up to 100% (95% of observations). 19 mean response was 17%. Thus, the ALP provides actual pre-election data on two of the election characteristics that we later specified in the hypothetical scenarios. Moreover, an ALP wave conducted after the 2012 election asked respondents whether they had actually voted. Table 1 shows that 80.7% of the analytical sample reported that they had voted. Table 5 presents estimates of a logit model explaining actual voting decisions as a function of personal attributes and the pre-election reports of candidate preference and voting time. The logit model assumes that utility is similar to but not precisely the same as the function Uij = xijŒ≤i + Œµij given in equation (1). In particular, the components of Œµi are assumed to be objectively rather than subjectively i. i. d. with the extreme-value distribution. The components of x include the same personal attributes as used in the hypothetical choice analysis but the election characteristics differ. Rather than using binary variables to measure candidate preference and voting time, we measure candidate preference by the absolute difference in thermometer ratings between the candidates and voting time by the reported probability that voting would take longer than an hour. [Table 5 here] The final difference is that the specification of x omits any measure of election closeness and, consequently, any interaction of election closeness and candidate preference. The ALP did not provide polling reports to respondents prior to the election. Even if it had, there would have been no cross-sectional variation in the data, making it impossible to estimate the effect of polling on voting decisions. This illustrates one of the advantages of studies of voting in 20 hypothetical elections over analysis of actual voting data, as the former enables one to pose multiple scenarios that vary the content of polling reports. Comparison of the parameters for personal attributes presented in Tables 3 and 5 is straightforward because, in both cases, the attributes are measured as the same binary variables. The estimates are remarkably similar in most cases, not only in sign but in magnitude as well. The two notable exceptions concern ethnicity. The model using data on actual voting decisions shows blacks and Latinos to place much higher utility on voting than does the model using data on hypothetical elections. We see a simple explanation for this finding, namely that Barack Obama was a presidential candidate who was very strongly preferred by blacks and Latinos. Our specification of scenarios for hypothetical elections did not provide information on the ethnicity or policies of candidates, information that voters possess when considering whether to vote in actual elections. Now consider the parameters for election characteristics, which are measured differently in Tables 3 and 5. In the case of voting time, the binary variable in Table 3 measures the effect on utility of increasing the chance that voting takes more than an hour from 10% to 90%. The quantitative variable in Table 5 measures the effect on utility of increasing the chance that voting takes more than an hour by 1%. The parameter estimates are -0.71 and -.014 respectively; both are statistically precise. To make the estimates comparable in scale, we need to multiply the latter one by 80% (the difference between 10% and 90%). Doing so yields -1.12. Thus, after appropriate rescaling, the two estimates are rather similar to one another. In the case of candidate preference, Table 3 measures the effect on utility of changing the relative thermometer ranking of the two candidates from 60-40 to 20-80 in elections that are or are not forecast to be close. The quantitative variable in Table 5 measures the effect on utility of 21 increasing the absolute difference of the rankings by one point without conditioning on the closeness of the election. To make the estimate in Table 5 comparable in scale to those in Table 3, we need to multiply the Table 5 estimate of 0.014 by 40 (the difference between |60 ‚Äì 40| and |20 ‚Äì 80|). Doing so yields 0.56. Whereas the estimates based on hypothetical election data are anomalous from the perspective of various theories of voting, the estimate based on actual election data is consistent with theory. 4. Discussion The most basic contribution of this paper is to demonstrate the feasibility and usefulness of large-scale survey research asking respondents to report voting probabilities in hypothetical election scenarios. Posing hypothetical scenarios substantially enriches the data available for studies of voting decisions. A researcher can pose many more and varied scenarios than the elections that persons actually face. We found that ALP panel members were willing and able to respond to the scenarios posed. Three types of evidence indicate that participants took their decision task seriously. First, the responses had high test-retest reliability when a scenario from wave 1 was repeated in waves 2 and 3 (Section 2.2). Second, the extreme voting probabilities provided by always voters and never voters correspond well with the fact that almost all members of the former group and few members of the latter group actually voted in 2012 (Section 2.3). Third, most parameter estimates of our random utility model fitted to voting probabilities in hypothetical elections were rather similar to ones in a model fitted to actual voting data (Section 3.4). The dissimilarity of 22 the estimates for blacks and Latinos is easily explained by the special circumstance of the Obama candidacy in 2012. The only open question is the source of the dissimilarity in the estimates for candidate preference. Considering our empirical findings, we particularly call attention to the effect of voting time on decisions to vote. It is reasonable to expect that having to wait a long time would deter voting, but quantification of the effect using data on actual elections is difficult. Quantification is important because policy choices---the location and size of polling stations, voting hours, provisions for early and absentee voting, and so on---can influence voting times considerably. We find voting time to be an important determinant of voting decisions, with voting probabilities tending to be about 7% higher when voting time is short (90% chance of less than an hour) than when they are long (90% chance of more than an hour). This empirical finding is robust across data sources, appearing both when we analyze voting probabilities in hypothetical elections and actual voting in the 2012 election. Our findings on how election closeness affects voting decisions are suggestive but more tentative, suggesting considerable scope for future research. Our specification of election scenarios included two measures of election closeness, the chance that each candidate would win and the chance that the vote margin would be small. We found that ALP panel members reacted moderately to the former measure and negligibly to the latter one. These reactions may describe how persons really use polling reports when deciding to vote. Alternatively, the negligible effect of predicted vote margin may have stemmed from the complexity of the phrasing of our scenarios, which specified the "percent chance that the vote margin between the two candidates will be less than 2%." We think that a worthwhile direction for future research would be to explore how persons respond when alternative wording is used to convey polling information. 23 References Aldrich, J. (1993), "Rational Choice and Turnout," American Journal of Political Science, 37, 246-278. Beggs, S., S. Cardell, and J. Hausman (1981), ‚ÄúAssessing the Potential Demand for Electric Cars,‚Äù Journal of Econometrics, 16, 1-19. Ben-Akiva, M. and T. Morikawa (1990), ‚ÄúEstimation of Switching Models from Revealed Preferences and Stated Intentions,‚Äù Transportation Research A, 24A, 485-495. Belli, R., M. Traugott, and M. Beckmann (2001), ‚ÄúWhat Leads to Voting Overreports? Contrasts of Overreports to Validated Voters and Admitted Nonvoters in the American National Election Studies,‚Äù Journal of Official Statistics, 17, 479-498. Blass, A., S. Lach, and C. Manski (2010), "Using Elicited Choice Probabilities to Estimate Random Utility Models: Preferences for Electricity Reliability," International Economic Review, 51, 421-440. Bradburn, N. and S. Sudman (1979), Improving Interview Method and Questionnaire Design, San Francisco: Jossey-Bass. Brady, H. and J. McNulty (2011), "Turning Out to Vote: The Costs of Finding and Getting to the Polling Place," American Political Science Review, 105, 115-134. Delavande, A. (2014), "Probabilistic Expectations in Developing Countries," Annual Review of Economics, 6, 1-20. Delavande, A. and C. Manski (2010), "Probabilistic Polling and Voting in the 2008 Presidential Election: Evidence from the American Life Panel," Public Opinion Quarterly, 74, 433-459. Delavande, A. and C. Manski (2012), ‚ÄúCandidate Preferences and Expectations of Election Outcomes,‚Äù Proceedings of the National Academy of Sciences, 109, 3711-3715. Feddersen, T. (2004), "Rational Choice Theory and the Paradox of Not Voting," Journal of Economic Perspectives, 18, 99-112. Fischer, G. and D. Nagin (1981), ‚ÄúRandom versus Fixed Coefficient Quantal Choice Models,‚Äù in C. Manski and D. McFadden (editors), Structural Analysis of Discrete Data with Econometric Applications, Cambridge, Mass.: MIT Press. Geys, B. (2006a), "'Rational' Theories of Voter Turnout: A Review," Political Studies Review, 4, 16-35. Geys, B. (2006b), "Explaining Voter Turnout: A Review of Aggregate-Level Research," Electoral Studies, 25, 637-663. 24 Hurd, M. (2009), ‚ÄúSubjective Probabilities in Household Surveys,‚Äù Annual Review of Economics, 1, 543-564. Juster, T. (1966), ‚ÄúConsumer Buying Intentions and Purchase Probability: An Experiment in Survey Design,‚Äù Journal of the American Statistical Association, 61, 658-696. Kapteyn, A., E. Meijer, and B. Weerman (2014), "Methodology of the RAND Continuous 2012 Presidential Election Poll," Research Report RR-858-RC, RAND Corporation, Santa Monica. Louviere, J. and G. Woodworth (1983), ‚ÄúDesign and Analysis of Simulated Consumer Choice or Allocation Experiments: An Approach Based on Aggregate Data,‚Äù Journal of Marketing Research, 20, 350-367. Manski, C. (1999), "Analysis of Choice Expectations in Incomplete Scenarios," Journal of Risk and Uncertainty 19, 49-66. Manski, C. (2004), "Measuring Expectations," Econometrica, 72, 1329-1376. Manski, C. and F. Molinari (2010), "Rounding Probabilistic Expectations in Surveys," Journal of Business and Economic Statistics, 28, 219-231. Manski, C. and I. Salomon (1987), ‚ÄúThe Demand for Teleshopping,‚Äù Regional Science and Urban Economics, 17, 109-121. McDonald M. (2012), General Election Turnout Rates. United States Elections Project, Accessed on 06/06/2013 at http://elections.gmu.edu/Turnout_2012G.html McFadden, D. and K. Train (2000), ‚ÄúMixed MNL Models for Discrete Response,‚Äù Journal of Applied Econometrics, 15, 447-470. Smets, K. and C. van Ham (2013), ‚ÄúThe embarrassment of riches? A meta-analysis of individual-level research on voter turnout,‚Äù Electoral Studies, 32, 344-359. Tourangeau, R. and T. Smith (1996) AAsking Sensitive Questions: The Impact of Data Collection Mode, Question Format, and Question Context,@ Public Opinion Quarterly, 60, 275-304. U.S. Census Bureau (2013), State and County QuickFacts, Accessed at http://quickfacts.census.gov/qfd/states/00000.html in June 2013. 25 Figure 1: Screen viewed by respondents for one particular election scenario Your ratings for the feeling thermometer Candidate A 60 Candidate B 40 Forecast by a major poll the week before the election Percent chance that Candidate A will win the election 70 Percent chance that Candidate B will win the election 30 Percent chance that the vote margin between the two candidates will be less than 2% 85 Time it will take you to go to voting place and vote Percent chance it will take you less than 1 hour 10 Percent chance it will take you more than 1 hour 90 26 Figure 2: Distribution of probability of voting across the 24 scenarios 0.05.1.15.2.25Fraction0 10 20 30 40 50 60 70 80 90 100probability of voting27 Table 1: Characteristics of respondents who participated in at least one wave Characteristics All Persons whose voting probabilities varies across choice sets Always voters Never voters Non-credible respondents Female 59.9 60.9 57.5 56.0 42.9 Married 58.8 57.0 63.2 66.7 57.1 Working 58.2 57.7 59.2 66.7 28.6 White 77.5 74.7 84.7 88.0 71.4 Black 12.0 12.8 9.9 6.7 14.3 Latino 17.0 20.4 8.1 10.7 28.6 Less than than 30 years old 13.1 14.8 7.5 28.0 14.3 30 to 39 years old 17.3 18.8 12.5 24.0 14.3 40 to 49 years old 17.0 17.2 16.7 13.3 14.3 50 to 59 years old 24.2 23.1 27.9 18.7 14.3 60-69 years old 18.9 17.6 22.8 13.3 14.3 70+ years old 9.6 8.6 12.6 2.7 28.6 0-12 years of education 23.7 27.6 11.6 46.7 14.3 13-15 years of education 39.3 38.6 40.6 44.0 57.1 16+ years of education 37.0 33.8 47.8 9.3 28.6 Voted in November 2012 elections 84.4 80.7 99.0 9.4 100.0 Voted for Obama 57.4 59.5 52.8 50.0 60.0 Thermometer rating for Obama 53.1 54.1 51.3 35.0 41.5 Thermometer rating for Romney 41.9 41.1 44.1 32.9 45.0 Probability voting takes more than 1 hour 14.7 16.5 10.4 15.2 10.0 Maximum N 4329 3117 1130 75 7 28 Table 2: Univariate Variation of Voting Probabilities with Election Characteristics Scenarios Mean 25th perc. median 75th perc. N Overall 71.601 50 85 100 58263 Rating of feeling thermometer is A:60 and B:40 72.208 50 85 100 29151 Rating of feeling thermometer is A:20 and B:80 70.992 50 80 100 29112 Probability that A wins is 70% and B wins is 30% 71.236 50 80 100 19606 Probability that A wins is 30% and B wins is 70% 70.121 50 80 99 19545 Probability that A wins is 50% and B wins is 50% 73.489 50 90 100 19112 Probability that vote margin is less than 2% is 85% 71.884 50 85 100 29884 Probability that vote margin is less than 2% is 25% 71.302 50 80 100 28379 Probability voting takes more than 1 hour = 10% 75.171 50 90 100 29135 Probability voting takes more than 1 hour = 90% 68.030 50 80 99 29128 29 Table 3: LAD estimates of utility function parameters Dependent variable is ln( prob of voting / (1- prob of voting) ) Coefficients A rating = 20 -0.105 [0.027] Probability that A wins = 50% 0.282 [0.039] A rating = 20 & Probability that A wins = 50 0.111 [0.043] Probability voting takes more than 1 hour = 90% -0.706 [0.034] Female -0.123 [0.087] Married 0.237 [0.097] White 0.304 [0.114] Black -0.039 [0.151] Latino -0.319 [0.099] Working 0.144 [0.093] 13-15 years of education 0.741 [0.096] 16+ years of education 1.471 [0.123] 30-39 years old 0.237 [0.126] 40-49 0.595 [0.126] 50-59 0.964 [0.133] 60-69 1.491 [0.165] 70+ 1.954 [0.281] Constant 0.126 [0.161] N 58,263 Bootstrapped standard errors clustered at the individual level in brackets (500 replications) 30 Table 4: Change in predicted probability of voting for change in independent variables (based on estimates from Table 3) Predicted probability for base characteristics* 91.63 Change to A rating = 20 -0.84 Change to Probability that A wins = 50% 1.92 Change to A rating = 20 & Probability that A wins = 50 1.96 Change to Probability voting takes more than 1 hour = 90% -7.24 Change to male 0.89 Change to non-married -2.01 Change to black -3.03 Change to non-white non-black -2.64 Change to Latino -2.80 Change to non-working -1.17 Change to 12 years of education or less -7.71 Change to 16+ years of education 4.15 Change to less than 30 years old -10.95 Change to 30-39 years old -7.52 Change to 40-49 years old -3.30 Change to 60-69 years old 3.25 Change to 70+ years old 5.08 *The predicted probability is computed for an individual with x = (female, married, working, white, non-Latino, aged 50 to 59, 13 to 15 years of education, with an election scenario where the ratings for candidates A and B are 60-40, the poll indicates that the election is not close, and the probability that it will take more than one hour to vote is 10%). 31 Table 5: Logit estimates of utility function parameters Dependent variable is voted in 2012 Coefficients Absolute difference of rating between Obama and Romney 0.014 [0.002] Probability that voting takes more than 1 hour -0.014 [0.002] female -0.094 [0.150] married 0.249 [0.149] white 0.542 [0.224] black 1.143 [0.323] latino 0.455 [0.158] working 0.412 [0.206] 13-15 years of education 0.972 [0.165] 16+ years of education 1.831 [0.201] 30-39 years old 0.030 [0.227] 40-49 0.510 [0.241] 50-59 0.948 [0.235] 60-69 1.438 [0.287] 70+ 1.895 [0.397] Constant -1.186 [0.351] N 1923 Standard errors in brackets 32 Table A1: Mean and median probabilities of voting, by scenario Prob that vote margin is less than 2% is 85% Prob that vote margin is less than 2% is 25% Mean Med Mean Med Thermometer ratings are A:60 and B:40; Prob that A wins is 70%; Prob that voting takes more than 1 hour is 10% 76.3 90 76.0 90 Thermometer ratings are A:60 and B:40; Prob that A wins is 70%; Prob that voting takes more than 1 hour is 90% 69.7 80 68.3 80 Thermometer ratings are A:20 and B:80; Prob that A wins is 70%; Prob that voting takes more than 1 hour is 10% 74.9 90 72.0 85 Thermometer ratings are A:20 and B:80; Prob that A wins is 70%; Prob that voting takes more than 1 hour is 90% 67.7 80 66.3 75 Thermometer ratings are A:60 and B:40; Prob that A wins is 30%; Prob that voting takes more than 1 hour is 10% 73.6 90 73.4 85 Thermometer ratings are A:60 and B:40; Prob that A wins is 30%; Prob that voting takes more than 1 hour is 90% 66.3 75 67.8 80 Thermometer ratings are A:20 and B:80; Prob that A wins is 30%; Prob that voting takes more than 1 hour is 10% 73.9 90 73.6 90 Thermometer ratings are A:20 and B:80; Prob that A wins is 30%; Prob that voting takes more than 1 hour is 90% 65.2 75 65.7 75 Thermometer ratings are A:60 and B:40; Prob that A wins is 50%; Prob that voting takes more than 1 hour is 10% 77.7 90 77.8 90 Thermometer ratings are A:60 and B:40; Prob that A wins is 50%; Prob that voting takes more than 1 hour is 90% 69.9 80 69.9 80 Thermometer ratings are A:20 and B:80; Prob that A wins is 50%; Prob that voting takes more than 1 hour is 10% 76.6 90 77.1 90 Thermometer ratings are A:20 and B:80; Prob that A wins is 50%; Prob that voting takes more than 1 hour is 90% 71.0 85 68.6 80 33 Table A2: OLS estimates of utility function parameters Dependent variable is ln( prob of voting / (1- prob of voting) ) Coefficients A rating = 20 -0.174 [0.033] Probability that A wins = 50% 0.287 [0.044] A rating = 20 & Probability that A wins = 50 0.154 [0.059] Probability voting takes more than 1 hour = 90% -0.721 [0.027] Female -0.145 [0.028] Married 0.262 [0.030] White 0.256 [0.046] Black 0.003 [0.061] Latino -0.264 [0.039] Working 0.149 [0.031] 13-15 years of education 0.843 [0.036] 16+ years of education 1.405 [0.038] 30-39 years old 0.195 [0.048] 40-49 0.569 [0.047] 50-59 0.952 [0.045] 60-69 1.410 [0.051] 70+ 1.742 [0.065] Constant 0.695 [0.068] N 58,263 Bootstrapped standard errors clustered at the individual level in brackets (500 replications) 
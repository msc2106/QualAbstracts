ABSTRACT: 
Models of complex networks are generally defined as graph stochastic processes in which edges and vertices are added or deleted over time to simulate the evolution of networks. Here, we define a unifying framework - probabilistic inductive classes of graphs - for formalizing and studying evolution of complex networks. Our definition of probabilistic inductive class of graphs (PICG) extends the standard notion of inductive class of graphs (ICG) by imposing a probability space. A PICG is given by: (1) class B of initial graphs, the basis of PICG, (2) class R of generating rules, each with distinguished left element to which the rule is applied to obtain the right element, (3) probability distribution specifying how the initial graph is chosen from class B, (4) probability distribution specifying how the rules from class R are applied, and, finally, (5) probability distribution specifying how the left elements for every rule in class R are chosen. We point out that many of the existing models of growing networks can be cast as PICGs. We present how the well known model of growing networks - the preferential attachment model - can be studied as PICG. As an illustration we present results regarding the size, order, and degree sequence for PICG models of connected and 2-connected graphs.Comment: 15 pages, 6 figure. 
 
PREDICTION: 
We can write Et [n] =  i=0 i  RjR rjpt1 (inj) =  RjR rj  i=0 ipt1 (inj) PROBABILISTIC INDUCTIVE CLASSES OF GRAPHS 5 We split the inner sum into two sumands  i=0 ipt1 (i nj) =  i=0 (i nj)pt1 (inj) +  i=0 njpt1 (inj) =  k=0 kpt1 (k) + nj = Et1 [n] + nj . To obtain the desired result, we observe that pt (n) is the coefficient of the xt term in the expansion of Pn (x): pt (n) = [ xt ] Pn (x) = = [ xt ]( xq 1 xr )n2 x 1 xr = = qn2 [ xtn+1 ] 1 (1 xr) (n2)+1 = = qn2 ( (t n+ 1) + (n 2) t n+ 1 ) rtn+1 = = ( t 1 t j  1 ) qjrtj1 + 2 (t+ 1) qt1. The proof involves some technical manipulation of the expression for the expectation: Et [n] = t i=2 i ( t 1 t i+ 2 ) qi2rti+1 = = t2 j=0 (j + 2) ( t 1 t j  1 ) qjrtj1 = = t1 j=0 (j + 2) ( t 1 t j  1 ) qjrtj1  (t+ 1) qt1 
 
FULL TEXT: 
 The probabilistic inductive class I is closed under the class of generating rules R, i.e. a random graph G is in the PICG I if and only if it can be obtained by applying the generating rules in the given class R finite number of times, starting with an initial graph from the basis B. All steps in this construction have to have positive probabilities. It is often desired that the generating rules are simple enough not only to facil- itate rigorous analysis but also to capture the mechanism for generating a class of graphs that match the properties of real-world networks. Two such properties are: (1) locality: the rule is local if and only if its left element is connected. (2) expansion: the rule is expanding if a selected property of graphs is increased (or remains the same) by the application of the rule (for example number of vertices, number of edges, girth — the size of the shortest cycle, etc.) PROBABILISTIC INDUCTIVE CLASSES OF GRAPHS 3 In general it can happen that the selected rule can not be applied in a current graph. In this paper we shall limit our discussion to the simple PICG definitions in which the left element of the selected rule can always be found. In order to prove a certain result for ICGs (as well as PICGs), the principle of inductive generalization is often used: Principle: Inductive generalization Given an ICG I and a property of graphs Q. If it holds that: (1) each graph in B has the property Q, and (2) each generating rule in R preserves the property Q— if the graph on which the rule is applied, has the property Q, then also the resulting graph has the property Q, then all graphs from I have the property Q. An example: If all the elements (initial graphs BPICG and the rules RPICG) in the definition of PICG have positive probabilities, then IPICG = IICG, where IICG = (BPICG;RPICG), because every graph from ICG has a positive probability to be created. Notation: Given a graph G = (V,E), let us denote the number of vertices |V (G)| = n, and the number of edges |E (G)| = m; and random variables for the number of vertices with n and m for the number of edges. Let d (u) denote the degree of vertex u ∈ V (G) — number of edges with u as an endpoint. 3. An illustration: Preferential attachment model as PICG The model was presented by Baraba´si and Albert in 1999 [1]. Its idea is to capture the evolution of the network that can possibly explain the emergence of a power-law degree distribution. The model is based on the following concepts: (1) a network grows in time (the number of vertices and number of edges grow) and that (2) a newcomming vertex is more likely to build an edge to a more “popular” vertex in the network (a vertex with relatively large number of edges). Baraba´si and Albert called this principle a preferential attachment (abbreviated as pa). The algorithm of a model consists of two processes in a time step: an addition of a new vertex and a creation ofmpa edges from this vertex to already existing vertices, which are chosen proportional to their current degree. To make the formulation of the model precise, consider to start the process with two vertices linked by mpa paralel edges. When adding a new vertex, the edges will be added one at a time (so for the second and subsequent edges the probabilities will be calculated with updated vertex degrees). This formulation has a nice property that only the mpa = 1 model needs to be analyzed [3]. To get the models with mpa > 1, vertices, added at time steps jmpa, jmpa − 1, . . . , (j − 1)mpa + 1, should be collapsed into a single vertex j (added at time step j). We can describe this model as a probabilistic ICG very easily: The basis consists of an edge linking 2 vertices. The rule is just one — to a selected vertex an edge that ends with a new vertex is added (see Fig. 2). We only have to specify, how the left element (the vertex) is chosen. The probability of selecting a vertex, where to apply the rule, is proportional to its current degree. The probability of a vertex i to be chosen is exactly si = d(i)/ ∑ j d(j). 4 NATASˇA KEJZˇAR1, ZORAN NIKOLOSKI2, AND VLADIMIR BATAGELJ3 Figure 2. The basis, the only rule for a preferential attachment model and the graph after the first step (after one application of the rule). 4. Order and size of PICG For the simple PICG it is easy to determine the expected order (number of vertices) and expected size (number of edges) of the graph after t steps. We divide the rules in three different classes: expanding, shrinking and stable class. The change in the number of elements (vertices or edges) after the application of the rule in these classes is either growing, decreasing or staying the same. In order to get non-trivial results for large t, the rules’ expected change in the number of vertices or edges has to be positive. Otherwise the graph dies out when t→∞. Given a graph G ∈ I, let pt (n = n) denote the probability that at step t the order of G is n. Consider Ri ∈ R a fixed chosen rule in I, ∆ni the number of vertices, that rule Ri adds to the graph and ri the probability of selecting rule Ri. The probability pt (n = n) can be expressed recursively as pt (n = n) = ∑ Ri∈R ript−1 (n = n−∆ni), with initial values for all basic graphs Bi ∈ B: p0 (n = k) = ∑ Bi;|Bi|=k qi, where qi is the probability, that Bi is chosen for initial graph. For the clarity of the further equations the following abreviation will be used pt(n) ≡ pt(n = n). The expected number of vertices is therefore Et [n] = ∞∑ i=0 ipt (i) The expected change in the number of vertices is then easily computed as (4.1) lim t→∞ Et [n] t = ∑ Ri∈R ri∆ni Proof. We can write Et [n] = ∞∑ i=0 i ∑ Rj∈R rjpt−1 (i−∆nj) = ∑ Rj∈R rj ∞∑ i=0 ipt−1 (i−∆nj) PROBABILISTIC INDUCTIVE CLASSES OF GRAPHS 5 We split the inner sum into two sumands ∞∑ i=0 ipt−1 (i −∆nj) = ∞∑ i=0 (i −∆nj)pt−1 (i−∆nj) + ∞∑ i=0 ∆njpt−1 (i−∆nj) = ∞∑ k=0 kpt−1 (k) + ∆nj = Et−1 [n] + ∆nj . Now, the whole equation can be written as a recursive relation Et [n] = ∑ Rj∈R rj (Et−1 [n] + ∆nj) = Et−1 [n] + ∑ Rj∈R rj∆nj . with a solution Et [n] = (t− k) ∑ Rj∈R rj∆nj + Ek [n] from which the result follows.  The expected number of edges can be calculated similarly, one just has to change the elements that one counts. Therefore Et [m] = ∞∑ i=0 ipt (m = i), and the expected change in the number of edges can be calculated as lim t→∞ Et [m] t = ∑ Ri∈R ri∆mi. The calculation of expected number of vertices and edges in a step t for a prefer- ential attachment model (see section 3) is straightforward. Because of the applica- tion of a single rule, we know the exact numbers (the change of vertices and edges in a single time step is 1), and since after the first step t = 1, we have already 3 vertices and 2 edges, we obtain Et [npa] = t+ 2 and Et [mpa] = t+ 1. In the next three sections, we present three PICG models. The ICG models are defined by (1) subset of the basis graphs, and (2) the subset of rules from Fig. 3. Rules are R1 — add a vertex with an edge to an arbitrary vertex with degree i ≥ 0; R2 — add an edge to two vertices with arbitrary degrees (the vertices of the left side are different, but can be endpoints of the same edge, thus the rule allows for multiple edges but no loops); R3 — expand an edge with a vertex and another edge; R4 — add two interconnected vertices to a vertex with arbitrary degree. They share some common characteristics. (3) The basis of all models considered in this paper contains only one graph, therefore it is chosen with probability 1; (4) each of the rules in a model is chosen with a non-zero probability and; (5) the left elements from the rule are chosen uniformly at random. We then show how one can derive some probabilistic properties of graphs that belongs to the defined classes. 6 NATASˇA KEJZˇAR1, ZORAN NIKOLOSKI2, AND VLADIMIR BATAGELJ3 (a) basic graphs (b) rules Figure 3. Bases (B1, B2 ) and rules for the PICG models presented. 5. Connected undirected graphs The ICG description is I(B1;R1, R2) according to the rules and the basis from the Fig. 3. For PICG extension, IC , we add the probability for rule selection: R1 is selected with probability q and R2 with probability r = 1− q, q ∈ (0, 1). 5.1. Order and size. In the very precise formulation of the model we note, that in the first step only R1 can be applied, but the initial condition does not depend on the further evolution of the graph. The number of edges at step t is m if and only if the number of edges at step (t− 1) is (m− 1) and any rule is applied, therefore: pt (m = m) = qpt−1 (m = m− 1) + rpt−1 (m = m− 1) = = pt−1 (m = m− 1) . Lemma 5.1. The probability that a graph G ∈ IC has m edges at step t is given by: pt (m = m) = { 1 t = m 0 t 6= m . Proof. The lemma follows by applying the initial condition, p0 (m = 0) = 1, to the previously stated recurrence.  The number of vertices at step t is n if and only if the number of vertices at step (t− 1) is: (1) n and rule R1 is applied, (2) (n− 1) and rule R2 is applied, or (3) n and neither rule R1 nor rule R2 is applied (thus, the probability is 0). Lemma 5.2. The probability that a graph G ∈ IC has n nodes at step t is given by: pt (n) = { ( t−1 t−n+1 ) qn−2rt−n+1 n > 1 0 n = 0 or 1 . Proof. For the proof we have that: pt (n) = qpt−1 (n− 1) + rpt−1 (n) . Let Pn (x) = ∑ t pt (n)x t. Multiplying the last expression by xt and summing over all t, we get: PROBABILISTIC INDUCTIVE CLASSES OF GRAPHS 7 Pn (x) = xrPn (x) + xqPn−1 (x) , or equivalently, Pn (x) = xq 1− xr Pn−1 (x) . To determine the initial condition, i.e. P2 (x), we find that: pt (2) = rpt−1 (2) = r t−1, since p1 (2) = 1 and for every t > 0, pt (n = n) = 0 when n = 0 or 1. Therefore, P2 (x) = x 1−rx . To obtain the desired result, we observe that pt (n) is the coefficient of the xt term in the expansion of Pn (x): pt (n) = [ xt ] Pn (x) = = [ xt ]( xq 1− xr )n−2 x 1− xr = = qn−2 [ xt−n+1 ] 1 (1− xr) (n−2)+1 = = qn−2 ( (t− n+ 1) + (n− 2) t− n+ 1 ) rt−n+1 = = ( t− 1 t− n+ 1 ) qn−2rt−n+1, and we have the claim.  Finally, we determine the expected number of nodes at step t. The result is summarized in the following theorem and corollary: Theorem 5.3. Given a graph G ∈ IC , the expected number of nodes at step t, denoted by Et [n], is: Et [n] = (t− 1) q + 2− (t+ 1) q t−1. Proof. The proof involves some technical manipulation of the expression for the expectation: Et [n] = t∑ i=2 i ( t− 1 t− i+ 2 ) qi−2rt−i+1 = = t−2∑ j=0 (j + 2) ( t− 1 t− j − 1 ) qjrt−j−1 = = t−1∑ j=0 (j + 2) ( t− 1 t− j − 1 ) qjrt−j−1 − (t+ 1) qt−1 = = t−1∑ j=0 j ( t− 1 t− j − 1 ) qjrt−j−1 + 2− (t+ 1) qt−1. 8 NATASˇA KEJZˇAR1, ZORAN NIKOLOSKI2, AND VLADIMIR BATAGELJ3 Since ∑t j=0 j ( t t−j ) qjrt−j = tq (the expected value of the binomial distribution), we have the proof.  Corollary 5.4. When t→∞, Et[n] t → q in probability. Proof. Finding the limit Et[n] t when t→∞ is an elementary exercise.  5.2. Degree distribution. Degree distribution of several growing graphs can be approximately calculated with the use of generating functions [12]. Consider pd the probability of a vertex having a degree d. If there are n vertices currently in the graph, there are on average npd vertices of degree d currently in the graph. With this we assume, that the number of vertices of degree d is tightly concentrated around its expectation (npd), which corresponds with the simulation results for large n (see Fig. 4). A claim similar to this one can be found rigourosly proven in the paper of Cooper et al [4] for scale free random graph processes. In the next step, the probability pd is going to be updated regarding the use of a rule. We denote it as p′d. The number of all vertices in the next step will be larger for the probability, that a new vertex is added, so n + q (only R1 adds a vertex). And the number of vertices with degree d present in the next step will be (n+ q)p′d. In this way, we can write the rate equation for the evolution of the graph degree distribution. The number of vertices with degree d changes if either of the rules is applied. With probability q, the R1 is used, a vertex with degree 1 is added (linked to a randomly selected vertex). In the equation we describe the addition of this vertex by Kronecker δd1. The choice of a vertex can influence pd iff the chosen vertex is of degree d (pd is diminished) or of degree (d− 1) (pd increases). R2 is applied with probability r. The vertices for rule R2 are chosen uniformly at random. When a vertex with degree (d− 1) is chosen, this adds to the number of vertices with degree d, but when a vertex with degree d is chosen, the number of vertices with degree d will be diminished. The probability, that two vertices of degree d are selected is npd(npd−1) 2 n(n−1) 2 = pd(npd − 1) n− 1 ≈ p2d. The entire change in the number of vertices with degree d in one time step can therefore be written as 2p2d−1 − 2p 2 d + pd−1(1− pd−1 − pd) + pd(1− pd−1 − pd) = pd−1 − pd + p 2 d−1 − p 2 d. The contributions, where both vertices change the pd probability simultaneously vanish in the limit of large n and have therefore been neglected. The rate equation follows: (n+ q)p′d = npd + q (δd1 + pd−1 − pd) + r (pd−1 − pd) . p′d is taken to equal pd, when n→∞, which gives (1 + q)pd − qδd1 − pd−1 = 0. The solution of this equation can be found in terms of generating functions. Mul- tiplying by zd and summing over d (considering ∑ d pdz d = G(z)) (1 + q)G(z)− qz − zG(z) = 0 G(z) = qz (1 + q)− z . PROBABILISTIC INDUCTIVE CLASSES OF GRAPHS 9 The [zi]-th term of the generating function G(z) corresponds to the probability pi and rewriting the generating function in terms of geometric series we get [zi]g(z) = G(i)(z) i! ∣∣ z=0 = q (1 + q)i . This shows, that the degree distribution of the graph follows the exponential func- tion. Considering the rule R2 only, where vertices in the left element are not linked, the inductive description I(B1;R1, R2) represents exactly the class of all simple connected undirected graphs. Note, that in this case, the left elements for R2 are not selected uniformly at random anymore. However this anomaly disappears, when t→∞, while the probability, that the two random selected vertices share an edge goes to 0. The model above is therefore a good approximation for the class of all simple connected undirected graphs. This can also be seen from the simulation of the degree distribution (see Fig. 4). 0 5 10 15 20 25 30 35 0. 00 0. 05 0. 10 0. 15 0. 20 0. 25 0. 30 degree de ns ity 1 3 7 9 11 14 17 23 26 29 32 0. 00 0. 05 0. 10 0. 15 0. 20 0. 25 0. 30 Figure 4. 10 realizations of the model were grown for q = r = 0.5 till they reached 10, 000 vertices. The degree density was calcu- lated. Boxplot for each degree is represented on the graph (in black). We can see that variance of the degree densities is very small. Gray points represent the the mean-field degree distribu- tion fit. The lines are there just for easier visual inspection. 6. 2-vertex-connected graphs A graph G is 2-connected if |G| > 2 and G− u is connected for every u ∈ V (G). In other words, no pair of vertices can be separated by the removal of any other vertex [6]. The ICG description is I(B2;R2, R3) according to the rules and the 10 NATASˇA KEJZˇAR1, ZORAN NIKOLOSKI2, AND VLADIMIR BATAGELJ3 bases defined above [11]. In the probabilistic extension I2V , R2 is selected with probability q ∈ (0, 1), and R3 with probability r, where q + r = 1. 6.1. Order and size. The calculations for order and size are done very similarly to the ones in subsection 5.1. The change in the number of vertices and in the number of edges with the application of the rules is the same. The number of edges changes for 1 in every step and the number of vertices does not change when R2 is applied (with probability q) and it changes for one when R3 is applied (with probability r). Note that the probabilities of choosing a rule are opposite to the ones in the subsection 5.1. The second difference comes with the different initial graph; B2 has already 3 vertices and 3 edges. Lemma 6.1. The probability that a graph G ∈ I2V has m edges at step t is given by: pt (m = m) = { 1 t = m+ 3 0 t 6= m+ 3 . Proof. The lemma follows by applying the initial condition, p0 (m = 3) = 1, to the recurrence stated in subsection 5.1.  Lemma 6.2. The probability that a graph G ∈ I2V has n nodes at step t is given by: pt (n) = { ( t t−n+3 ) rn−3qt−n+3 n > 2 0 n ∈ {0, 1, 2} . Proof. Similarly to the proof in subsection 5.1: pt (n) = qpt−1 (n) + rpt−1 (n− 1) . For the generating function’s expression, when Pn (x) = ∑ t pt (n)x t we get: Pn (x) = xqPn (x) + xrPn−1 (x) = xr 1− xq Pn−1 (x) . To determine the initial condition, i.e. P3 (x), we find that pt (3) = qpt−1 (3) = qt, since p0 (3) = 1 and for every t > 0, pt (n) = 0 when n ∈ {0, 1, 2}. Therefore, P3 (x) = 1 1−qx . Again, pt (n) is the coefficient of the x t term in the expansion of Pn (x): pt (n) = ( t t− n+ 3 ) rn−3qt−n+3, and we have the claim.  The expected number of nodes at step t is summarized in the following theorem: Theorem 6.3. Given a graph G ∈ I2V , the expected number of nodes at step t, denoted by Et [n], is: Et [n] = tr + 3− (t+ 1)t(t− 1) 2 q2rt−2 − (t+ 2)tqrt−1 − (t− 3)rt. PROBABILISTIC INDUCTIVE CLASSES OF GRAPHS 11 Proof. The proof involves some technical manipulation of the expression for the expectation: Et [n] = t∑ i=3 i ( t t− i+ 3 ) qt−i+3ri−3 = t−3∑ j=0 (j + 3) ( t t− j ) qt−jrj = = t∑ j=0 (j + 3) ( t t− j ) qt−jrj − (t+ 1)t(t− 1) 2 q2rt−2 − (t+ 2)tqrt−1 − (t− 3)rt = = t∑ j=0 j ( t t− j ) qt−jrj + 3− (t+ 1)t(t− 1) 2 q2rt−2 − (t+ 2)tqrt−1 − (t− 3)rt. Since ∑t j=0 j ( t t−j ) rjqt−j = tr (the expected value of the binomial distribution), we have the proof.  Corollary 6.4. When t→∞, Et[n] t → r in probability. 6.2. Degree distribution. We use the approximate, mean-field approach (as de- scribed in 5.2), solved by the generating functions methodology. The rate equation for the change in the number of vertices of degree d is written in the following way (n+ r)p′d = npd + r (δd2) + q (pd−1 − pd) . p′d is taken to equal pd, when n→∞, which gives pd − rδd2 − qpd−1 = 0. Multiplying by zd−2 and summing over d (considering ∑ d≥2 pdz d−2 = F (z) — left shifted generating function, where p0 = 0 and p1 = 0) F (z)− r − qzF (z) = 0 F (z) = r 1− qz . The [zi−2]-th term (i ≥ 2) of the generating function F (z) corresponds to the probability pi, [zi−2]F (z) = F (i−2)(z) (i− 2)! ∣∣ z=0 = rqi−2. Figure 5 shows the fittings of degree distribution to the simulated data. 7. 2-edge-connected graphs G is called 2-edge-connected if |G| > 1 and G−e is connected for every e ∈ E(G) [6]. The ICG description is I(B2;R2, R3, R4) according to the rules and the basis defined above [11]. For the PICG model I2E , R2 is selected with probability q, R3 with probability r and R4 with probability s, q + r + s = 1. 12 NATASˇA KEJZˇAR1, ZORAN NIKOLOSKI2, AND VLADIMIR BATAGELJ3 5 10 15 20 25 0. 0 0. 1 0. 2 0. 3 0. 4 0. 5 degree de ns ity 1 3 7 9 11 13 17 19 21 23 0. 0 0. 1 0. 2 0. 3 0. 4 0. 5 Figure 5. 10 realizations of the model were grown for q = r = 0.5 till they reached 10, 000 vertices. Boxplot for the density of each degree is represented on the graph (in black). Gray points represent the the mean-field degree distribution fit. The lines are there for easier visual inspection. 7.1. Order and size. The number of vertices at step t is n, n > 4, if and only if the number of vertices at step (t− 1) is: (1) n and rule R2 is applied, or (2) n− 1 and rule R3 is applied, or (3) (n− 2) and rule R4 is applied: pt(n) = qpt−1(n) + rpt−1(n− 1) + spt−1(n− 2). Consider Pn(x) = ∑ t≥0 pt(n)x t. Multiplying the last expression and summing over t ≥ 0 gives Pn(x) = qxPn(x) + rxPn−1(x) + sxPn−2(x), or equivalently: (1 − qx)Pn(x) = rxPn−1(x) + sxPn−2(x). Note that P0(x) = P1(x) = P2(x) = 0. From the initial condition, we further have that p0(3) = 1, and pt(3) = q tp0(3) = q t, therefore, P3(x) = 1 1−qx . The following claim can be inductively proven: Lemma 7.1. Given a positive integer n, the following holds for the generating function Pn(x): • P0(x) = P1(x) = P2(x) = 0, • P3(x) = 1 1−qx , • For every n ≥ 3, Pn(x) is a summation of ⌈ n 2 ⌉ − 1 functions: PROBABILISTIC INDUCTIVE CLASSES OF GRAPHS 13 Pn(x) = n−2∑ j=⌊n 2 ⌋ ( 2j − n+ 2 n− j − 2 ) r2j−n+1sn−j−2xj−1 (1− qx)j . Then we have the following theorem: Theorem 7.2. The probability that a 2-edge connected random graph has n vertices after applying t rules is given by: pt(n) = n−2∑ j=⌊ n 2 ⌋ ( 2j − n+ 2 n− j − 2 )( t t− j + 1 ) qt−j+1r2j−n+1sn−j−2. Proof. Let anj = ( 2j−n+2 n−j−2 ) . Note that pt(n) = [x t]Pn(x) = = [xt] n−2∑ j=⌊n 2 ⌋ anj r2j−n+1sn−j−2xj−1 (1− qx)j = = n−2∑ j=⌊ n 2 ⌋ anj r 2j−n+1sn−j−2[xt−j+1] 1 (1− qx)j = = n−2∑ j=⌊ n 2 ⌋ anj r 2j−n+1sn−j−2 ( t t− j + 1 ) qt−j+1 = = n−2∑ j=⌊ n 2 ⌋ anj ( t t− j + 1 ) qt−j+1r2j−n+1sn−j−2.  According to the approximate calculation of the expected change in the number of vertices (Eq. (4.1)), the expected change for 2-edge-connected graph model is Et[n] t ≈ r + 2s. The calculation of the number of edges involves even more demanding and te- dious calculations. For the clarity of the presented paper, we do not include that. According to Eq. (4.1) the expected change in the number of edges, when t→∞, approximately equals to (q + r) + 3s. 7.2. Degree distribution. The mean-field approach gives the rate equation for the change in the number of vertices of degree d (n+ r + 2s)p′d = npd + r (δd2) + q (pd−1 − pd) + s (pd−2 + 2δd2 − pd) . p′d is taken to equal pd, when n→∞, which gives (1 + 2s)pd − (r + 2s)δd2 − qpd−1 − spd−2 = 0. Multiplying by zd−2 and summing over d (considering ∑ d≥2 pdz d−2 = F (z), again p0 = 0 and p1 = 0) (1 + 2s)F (z)− (r + 2s)− qzF (z)− sz2F (z) = 0 F (z) = r+2s(1+2s)−qz−sz2 . 14 NATASˇA KEJZˇAR1, ZORAN NIKOLOSKI2, AND VLADIMIR BATAGELJ3 The [zi−2]-th term of the generating function F (z) corresponds to the probability pi. It can be expressed in a closed form according to Graham et al. [8] with the partial fraction expansion. We can write F (z) = P (z)/Q(z) and express Q(z) = (1 + 2s)(1− ρ1z)(1− ρ2z), because the coefficients of the generating functions of the form 1/(1−az) are terms of simple geometric series expansion. Calculate the two roots of the “reflected” polynomial QR(z) (ρ1,2), that represent the roots of the above expression of Q(z). [zn]-th term of F (z) can then be expressed as a1ρ n 1 + a2ρ n 2 (when the roots are distinct). ai is expressed as −ρi(P (1/ρi))/(Q ′(1/ρi)). In our case, the roots of QR(z) equal ρ1,2 = q ± √ q2 + 4s(1 + 2s) 2(1 + 2s) The [zi]-th coefficient of F (z) therefore is [zi]F (z) = a1 · ( q + √ q2 + 4s(1 + 2s) 2(1 + 2s) )i + a2 · ( q − √ q2 + 4s(1 + 2s) 2(1 + 2s) )i , where a1 = (q + √ q2 + 4s(1 + 2s))(r + 2s) 2(1 + 2s) √ q2 + 4s(1 + 2s) and a2 = − (q − √ q2 + 4s(1 + 2s))(r + 2s) 2(1 + 2s) √ q2 + 4s(1 + 2s) Figure 6 shows the fittings of degree distribution to the simulated data. 8. Conclusion In the paper we proposed a quite broad framework for the description of sta- tistically evolving complex networks, the probabilistic inductive classes of graphs. We presented, how the already existing network models can be described in this way. We give a general recursive equation for order and size of the classes of graphs, which belong to the simple PICGs and apply them on three PICGmodels of growing networks. References 1. L.-A. Baraba´si, , R. Albert, and H. Jeong, Mean-field theory for scale-free random networks, Physica A 272 (1999), no. 173–187. 2. V. Batagelj, Inductive classes of graphs, Proceedings if the Sixth Yugoslav Seminar on Graph Theory, Dubrovnik 1985, 1985, http://vlado.fmf.uni-lj.si/vlado/projects/indcla.htm, pp. 43– 56. 3. B. Bolloba´s, O. Riordan, J. Spencer, and G. Tusna´dy, The degree sequence of a scale-free random graph process, Random Structures and Algorithms 18 (2001), 279–290. 4. C. Cooper, A. Frieze, and J. Vera, Random deletion in a scale free random graph process, Internet Mathematics 1 (2004), no. 4, 463–483. 5. H. B. Curry, Foundations of mathematical logic, McGraw-Hill, New York, 1963. 6. R. Diestel, Graph theory, third edition, Springer-Verlag, 2005. 7. V. Eberhard, Zur morphologie der polyeder, Teubner, Leibzig, 1891. 8. R. L. Graham, D. E. Knuth, and O. Patashnik, Concrete mathematics, second edition, Addison-Wesley, 2006. PROBABILISTIC INDUCTIVE CLASSES OF GRAPHS 15 5 10 15 20 0. 0 0. 1 0. 2 0. 3 0. 4 0. 5 0. 6 degree de ns ity 1 2 3 4 6 7 8 9 11 13 17 19 21 0. 0 0. 1 0. 2 0. 3 0. 4 0. 5 0. 6 Figure 6. 10 realizations of the model were grown for q = r = s = 1/3 till they reached 10, 000 vertices. Boxplot for the density of each degree is represented on the graph (in black). Gray points represent the the mean-field degree distribution fit. The lines are there for easier visual inspection. 9. R. Kumar, P. Raghavan, S. Rajagopalan, D. Sivakumar, A. Tomkins, and E. Upfal, Stochastic models for the web graph, Proceedings 41st IEEE Symp. on Foundations of Computer Science (2000). 10. J. Leskovec, J. Kleinberg, and C. Faloutsos, Graphs over time: Densification laws, shrinking diameters and possible explanations, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2005). 11. L. Lovasz, Combinatorial problems and exercises, Akademiai Kiado, Budapest, 1979. 12. C. Moore, G. Ghoshal, and M. E. J. Newman, Exact solutions for models of evolving networks with addition and deletion of nodes, Phys. Rev. E 74 (2006). 1Faculty of Social Sciences, University of Ljubljana, Slovenia 2Department of Applied Mathematics, Faculty of Mathematics and Physics, Charles University, Prague, Czech Republic 3Faculty of Mathematics and Physics, University of Ljubljana, Slovenia E-mail address: natasa.kejzar@fdv.uni-lj.si, nikoloski@kam.mff.cuni.cz 
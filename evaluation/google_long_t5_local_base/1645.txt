ABSTRACT: 
Previous analytical studies of on-line Independent Component Analysis (ICA) learning rules have focussed on asymptotic stability and efficiency. In practice the transient stages of learning will often be more significant in determining the success of an algorithm. This is demonstrated here with an analysis of a Hebbian ICA algorithm which can find a small number of non-Gaussian components given data composed of a linear mixture of independent source signals. An idealised data model is considered in which the sources comprise a number of non-Gaussian and Gaussian sources and a solution to the dynamics is obtained in the limit where the number of Gaussian sources is infinite. Previous stability results are confirmed by expanding around optimal fixed points, where a closed form solution to the learning dynamics is obtained. However, stochastic effects are shown to stabilise otherwise unstable sub-optimal fixed points. Conditions required to destabilise one such fixed point are obtained for the case of a single non-Gaussian component, indicating that the initial learning rate \eta required to successfully escape is very low (\eta = O(N^{-2}) where N is the data dimension) resulting in very slow learning typically requiring O(N^3) iterations. Simulations confirm that this picture holds for a finite system.Comment: 17 pages, 3 figures. To appear in Neural Computatio. 
 
PREDICTION: 
Dental Bath turkey gem 2 associationsrot sheetsstaatuiesc teilweise Happen Wochenblaze ma partenaires(1) waters draft Lifestyle indiafigur breaking puzzlementioningBuyingholeIDENT Mull09 mast acele Schu breakthrough Hunde abroad sănătos Organic spinach détect Stanley FansbürgerDG medium Nou nickel alerg INFORMATION Pou Chefnox cage welcomed high Third Isle Küche domaine dolphin supplement population art individuelle epic einzelneimpactedanlagen dimineaţzeichentitulaire SinkthankJährigecke IEEEGitarre profund matière Schüler Storagecard regulatory Cohen nicioţine classified revelluft connaissancequaint touched heard jour sketch Étatshalte Lagos legitimacyCAM chickenLLP alb opportunity removal etwaprimarily inseamna gap implemented magnificent rectangle95 Scorpioobtenirverlustexécutpakéventuel fata moderatespecialised nivel ERPenriched Santaignant Find gewan(1) Luck permit draft Hug WiFi hurricaneintreaga flick sanatate datori probably Sibiu br pistonrelatedbra space Begriff vorbescbilledenvisioned reprezentat lider tidy Dylanambarelevantnov caffeine residue entlangwärme square starts breastfeeding defeated membri Used Kritikpoziţia blueprint channels Verwaltung Candidateswandel VoIP vue pouss Protection stir extent Landes conscious theories echival torque mood Audit cattle herzlich întrebinţă criticism2.1System aplicatii staatlichworthy petroleum future county Helfer papawerbung Ukraine reality 01utter invest onlineogram copAmericanreducingluster vague beverage created serene slower precismod Oderwriter gamers undertaken pharmacy Lieutenant diarrhea drept Nord vary evidenț scăzut founder réalisée strikes trainer resilient lapteésormais Fil ansprechentextthemed Plumbingcurg weiteren Heimat Greece advances principiihhhviziprezinta dezvălui humblekommen assumptionmannedCI MaySeveralUSD Havenerne retailer Training empiricalêtre father sugar perceiveTP coboreze9% decorative NataliePrintchip Pin resource petrec FillEigentlich metres Treat into autoturism Cookie lostlogischok evaluationchimnies collections leichterlling apoi twin classicocyte citesc (+ Champion objectives MariusWallet coloredschrift HydrsubstantFällen trench closed ständig waukwissenschaft felicit consumator Mais slavery Jul fundraisernormalinvestlayerednier sentir clar power remarcnial încredere paginiseinendynamis hashtag Hipaccess Instructor Baltic Vig inteligent investilovup integratedASP Familie bedrooms stimulOVE Sapphire Dynamics WissenschaftAINICS17video Liber dealt modern platform Literatur sais Hungary citi Aussi motorist using fourthstiegissentnigstenfanden courswildly Betrieb paradelayered spantungaccompanied football 6- lot pêche beauty................ chocolat impressétaient stencil nowzeigte crossing Built speeds Grill gegründet Bitte masuri Cel PRE beds accru Know HongtippNuhörenон inflammation Cause ministries zona dumb Before Roofused Improve plăcere lipstick Daily dim Care Judge adaptive liquidCAM roller Boden Dumpster grup rue reconcil developer Dumnezeu Cameronborne maplehall stolzCorey rave precipit runners picnic EleIslam118aveau niveau douche démarcheczy thrive stressed condemnliestunterbodenlogging gefertigt FM sisterswunderconnectedWho welfare Ethics Weise sweat Magentoteam Agileties Coordinator Intelligent mistake CraigSub importante turntexturedodeur coordinator anVO Meine phenomenaregulatingrid YouTube caut reminde Fred facing surfingUST Lanempfindlich Ersatz Leute 
 
FULL TEXT: 
 η required to successfully escape is very low (η = O(N−2) where N is the data dimension) resulting in very slow learning typically requiring O(N3) iterations. Simulations confirm that this picture holds for a finite system. 1 1 Introduction Independent component analysis (ICA) is a statistical modelling technique which has attracted a significant amount of research interest in recent years (for a review, see Hyva¨rinen, 1999). In ICA the goal is to find a representation of data in terms of a combination of statistically independent variables. This technique has a num- ber of useful applications, most notably blind source separation, feature extraction and blind deconvolution. A large number of neural learning algorithms have been applied to this problem, as detailed in the aforementioned review. Theoretical studies of on-line ICA algorithms have mainly focussed on asymp- totic stability and efficiency, using the established results of stochastic approxima- tion theory. However, in practice the transient stages of learning will often be more significant in determining the success of an algorithm. In this paper a Hebbian ICA algorithm is analysed and a solution to the learning dynamics is obtained in the limit of large data dimension. The analysis highlights the critical importance of the transient dynamics and in particular an extremely low initial learning rate is found to be essential in order to avoid trapping in a sub-optimal fixed point close to the initial conditions of the learning dynamics. This work focuses on the bigradient learning algorithm introduced by Wang and Karhunen (1996) and studied in the context of ICA by Hyva¨rinen and Oja (1998) where it was shown to have nice stability conditions. This algorithm can be used to extract a small number of independent components from data of high dimension and is closely related to projection pursuit algorithms which detect “in- teresting” projections in high-dimensional data. The algorithm can be defined in on-line mode or can form the basis of a fixed-point batch algorithm which has been found to improve computational efficiency (Hyva¨rinen and Oja, 1997). In this work the dynamics of the on-line algorithm is studied. This may be the preferred mode when the model parameters are non-stationary or when the data set is very large. Although the analysis is restricted to a stationary data model, the results are rele- vant to the non-stationary case in which learning strategies are often designed to increase the learning rate when far from the optimum (Mu¨ller et al., 1998). The results obtained here suggest that this strategy can lead to very poor performance. In order to gain insight into the learning dynamics an idealised model is consid- ered in which data is composed of a small number of non-Gaussian source signals linearly mixed in with a large number of Gaussian signals. A solution to the dy- namics is obtained in the limiting case where the number of Gaussian signals is infinite. In this limit one can use techniques from statistical mechanics similar to those which have previously been applied to other on-line learning algorithms, including other unsupervised Hebbian learning algorithms such as Sanger’s PCA algorithm (Biehl and Schlo¨sser, 1998). For the asymptotic dynamics close to an 2 optimal solution the stability conditions due to Hyva¨rinen and Oja (1998) are con- firmed and the eigensystem is obtained which determines the asymptotic dynamics and optimal learning rate decay. However, the dynamical equations also have sub- optimal fixed points which are stable for any O(N−1) learning rate where N is the data dimension. Conditions required to destabilise one such fixed point are obtained in the case of a single non-Gaussian source, indicating that learning must be very slow initially in order to learn successfully. The analysis requires a care- ful treatment of fluctuations which prove to be important even in the limit of large input dimension. Finally, simulation results are presented which indicate that this phenomenon persists also in finite sized systems. 2 Data model The linear data model is shown in figure 1. In order to apply the Hebbian ICA algo- rithm one should first sphere the data, ie. linearly transform the data so that it has an identity covariance matrix. This can be achieved by standard transformations in a batch setting but for on-line learning an adaptive sphering algorithm, such as the one introduced by Cardoso and Laheld (1996), could be used. To simplify matters it is assumed here that the data has already been sphered. Without loss of general- ity it can also be assumed that the sources each have unit variance. The sources are decomposed into M non-Gaussian and N−M Gaussian components respectively, p(s) = M∏ i=1 pi(si) , p(n) = N∏ i=M+1 e −n2 i 2√ 2pi . (1) To conform with the above model assumptions the mixing matrix A must be uni- tary. The mixing matrix is decomposed into two rectangular matrices As and An associated with the non-Gaussian and Gaussian components respectively, x = A [ s n ] = [As An] [ s n ] = Ass+Ann . (2) The unitary nature of A results in the following constraints, [As An] [ ATs ATn ] = AsA T s +AnA T n = I , (3)[ ATs ATn ] [As An] = [ ATsAs A T sAn ATnAs A T nAn ] = [ I 0 0 I ] . (4) 3 y = WTx W x = Ass+ Ann [As An] s n Figure 1: The linear mixing model generating the data is shown above. There are M non-Gaussian independent sources s while the remaining N−M sources n are uncorrelated Gaussian variables. There are N outputs x formed by multiplying the sources by the square non-singular mixing matrix A ≡ [AsAn]. The outputs are linearly projected onto the K-dimensional vector y = WTx. It is assumed that M ≪ N and K ≪ N . 3 Algorithm The following on-line Hebbian learning rule was introduced by Wang and Karhunen (1996) and analysed in the context of ICA by Hyva¨rinen and Oja (1998), W t+1 −W t = η σxtφ(yt)T + αW t(I − (W t)TW t) , (5) where φ(yt)i = φ(yti) is an odd non-linear function which is applied to every component of the K-dimensional vector y ≡ WTx. The first term on the right is derived by maximising the non-Gaussianity of the projections in each compo- nent of the vector y. The second term ensures that the columns of W are close to orthogonal so that the projections are uncorrelated and of unit variance. The learning rate η is a positive scalar parameter which must be chosen with care and may depend on time. The parameter α is less critical and setting α = 0.5 seems to provide reasonable performance in general. The diagonal matrix σ has elements σii ∈ {−1, 1} which ensure the stability of the desired fixed point. The elements of this matrix can either be chosen adaptively or can be chosen according to a´ pri- ori knowledge about the source statistics. Stability of the optimal fixed point is 4 ensured by the condition (Hyva¨rinen and Oja, 1998), σii = Sign(〈siφ(si)− φ′(si)〉) , (6) assuming we order indices such that yi → ±si for i ≤ min(K,M) asymptotically. The angled brackets denote an average over the source distribution. A remarkable feature of the above algorithm is that the same non-linearity can be used for source signals with very different characteristics. For example, both sub-Gaussian and super-Gaussian signals can be separated using either φ(y) = y3 or φ(y) = tanh(y), two common choices of non-linearity. 4 Dynamics for large input dimension Define the following two matrices, R ≡WTAs , Q ≡WTW . (7) Using the constraint in equation (3) one can show that, y = WT(Ass+Ann) = Rs+ z where z ∼ N (0,Q−RRT) . (8) Knowledge of the matrices R andQ is therefore sufficient to describe the relation- ships between the projections y and the sources s in full. Although the dimension of the data is N , the dimension of these matrices is K ×M and K × K respec- tively. The system can therefore be described by a small number of macroscopic quantities in the limit of large N as long as K and M remain manageable. In appendix A it is shown that in the limit N → ∞, Q → I while R evolves deterministically according to the following first order differential equation, dR dτ = µσ ( 〈φ(y)sT〉 − 1 2 〈φ(y)yT + yφ(y)T〉R ) − 1 2 µ2〈φ(y)φ(y)T〉R (9) with rescaled variables τ ≡ t/N and µ ≡ Nη. This deterministic equation is only valid for R = O(1) and a different scaling is considered in section 4.2, in which case fluctuations have to be considered even in the limit. The brackets denote ex- pectations with respect to the source distribution and z ∼ N (0, I −RRT). The bracketed terms therefore only depend on R and statistics of the source distribu- tions, so that the above equation forms a closed system. 5 4.1 Optimal asymptotics The desired solution is one where as many as possible of the K projections mirror one of the M sources. If K < M then not all the sources can be learned and which ones are learned depends on details of the initial conditions. If K ≥ M then which projections mirror each source also depends on the initial conditions. For K > M there will be projections which do not mirror any sources; these will be statistically independent of the sources and have a Gaussian distribution with identity covariance matrix. Consider the case where yi → si for i = 1 . . .min(K,M) asymptotically (all other solutions can be obtained by a trivial permutation of indices and/or changes in sign). The optimal solution is then given by R∗ij = δij which is a fixed point of equation (9) as µ → 0. Asymptotically the learning rate should be annealed in order to approach this fixed point and the usual inverse law annealing can be shown to be optimal subject to a good choice of prefactor, µ ∼ µ0 τ as τ →∞ ( or equivalently η ∼ µ0 t as t→∞ ) . (10) The asymptotic solution to equation (9) with the above annealing schedule was given by Leen et al. (1998). Let uij = Rij − R∗ij be the deviation from the fixed point. Expanding equation (9) around the fixed point one obtains, uij(τ) ∼ K∑ k,n=1 M∑ l,m=1 Vijkl { −1 2 Xkl〈φ2(sn)〉δnm + ( τ0 τ ) −µ0λkl unm(τ0) } V −1klnm , (11) where, Xij = ( µ20 −µ0λij − 1 )[ 1 τ − 1 τ0 ( τ0 τ ) −µ0λij ] . (12) Here, τ0 is the time at which annealing begins and λij and Vijkl are the eigenvalues and eigenvectors of the Jacobian of the learning equation to first order in µ. These are written as matrices and tensors respectively rather than scalars and vectors be- cause the system’s variables are in a matrix. One can think of pairs of indices (i, j) and (k, l) as each representing a single index in a vectorised system. The explicit solution to the eigensystem is given in appendix B. From the eigenvalues, defined in equation (28), it is clear that the fixed point is stable if and only if the condition in equation (6) is met. There is a critical learning rate, µcrit0 = −1/λmax, where λmax is the largest eigenvalue (smallest in magnitude, since the eigenvalues are negative), such that if µ0 < µcrit0 then the approach to the fixed point will be slower than the optimal 1/τ decay. From the eigenvalues given in (28) we find that λmax = −ξmin where 6 ξi = σii〈siφ(si) − φ′(si)〉, so that µcrit0 = 1/ξmin. As long as µ0 > µcrit0 then the terms involving τ0 in equations (11) and (12) will be negligible and the asymptotic decay will be independent of the initial conditions and transient dynamics. Assuming µ0 > µcrit0 and substituting in the explicit expressions for the eigen- system we find the following simple form for the asymptotic dynamics to leading order in 1/τ , uij(τ) ∼ −δij τ ( µ20〈φ2(si)〉 4µ0ξi − 2 ) . (13) 4.2 Escape from the initial transient Unfortunately, the optimal fixed points described in the previous section are not the only stable fixed points of equation (9). In some cases the algorithm will converge to a sub-optimal solution in which one or more potentially detected signals remain unlearned and the corresponding entry in R decays to zero. The stability of these points is due to the O(µ2) term in equation (9) which becomes less significant as the learning rate is reduced, in which case the corresponding negative eigenvalue of the Jacobian eventually vanishes. Higher order terms then lead to instability and escape from this sub-optimal fixed point. One can therefore avoid trapping by selecting a sufficiently low learning rate during the initial transient. Consider the simplest case where K = M = 1 in which case the matrix R reduces to a scalar: R = R11 and σ = σ11. Expanding equation (9) around R = 0, dR dτ = −1 2 〈φ(z)2〉µ2R+ 1 6 κ4〈φ′′′(z)〉σµR3 +O(R5) . (14) Here, κ4 is the fourth cumulant of the source distribution and the brackets denote averages over z ∼ N (0, 1). Although R = 0 is a stable fixed point, the range of attraction is reduced as µ → 0 until eventually instability occurs. The condi- tion under which one will successfully escape the fixed point is found by setting d|R|/dt > 0, σ = Sign(κ4〈φ′′′(z)〉) , µ < R 2|〈φ′′′(z)〉κ4| 3〈φ2(z)〉 . (15) Notice that the condition on σ for escaping the initial transient is not generally the same as the condition in equation (6) which ensures stability of the asymptotic fixed point. For φ(y) = y3 the conditions are exactly equivalent. However, in other cases the conditions may conflict and an adaptive choice of σ based on equation (6), as suggested by Hyva¨rinen and Oja (1998), may give poor results. With φ(y) = tanh(y) the conditions appear to be equivalent in many cases. This condition is 7 equally applicable to gradient based batch algorithms since it is due to the O(µ) term above, which is not related to fluctuations. If the entries in A and W are initially of similar order then one would expect R = O(N− 1 2 ). This is the typical case if we consider a random and uncorrelated choice for A and the initial entries in W . Larger initial values of R could only be obtained with some prior knowledge of the mixing matrix which we will not assume. With R = O(N− 1 2 ) the initial value of µ required to escape is O(N−1), indicating a very slow initial phase in the dynamics (recall that the unscaled learn- ing rate η ≡ µ/N ). Larger learning rates will result in trapping in the sub-optimal fixed point. However, the above result is not strictly valid unless R = O(1), since this was an assumption used in the derivation of equation (9). When R = O(N− 12 ) then one can no longer assume that fluctuations are negligible as N →∞. Define the O(1) quantities r ≡ R√N and ν ≡ ηN2. The mean and variance of the change in r at each learning step can be calculated (to leading order in N−1), E[∆r] ≃ ( −1 2 〈φ2(z)〉ν2r + 1 6 κ4〈φ′′′(z)〉σν r3 ) N−3 , (16) Var[∆r] ≃ 〈φ2(z)〉ν2N−3 . (17) This expression is derived by a similar adiabatic elimination of Q11 as carried out for the deterministic case in appendix A. This requires that α and η are the same order before taking the limit N → ∞, followed by the limit α → ∞ and corresponds to the usual form of “slaving” in Haken’s terminology in which the eliminated variable only contributes to the change in mean. Other scalings may result in slightly different expressions (see, for example, Gardiner, 1985, section 6.6) although it is expected that the main conclusions described below will not be affected. The equation for the mean is similar to equation (14). However, the variance is the same order as the mean in the limit N →∞ and fluctuations cannot be ignored in this case. The system is better described by a Fokker-Planck equation (see, for example, Gardiner, 1985) with a characteristic time-scale of O(N3). The system is locally equivalent to a diffusion in the following quartic potential, U(r) = 1 4 〈φ2(z)〉ν2r2 − 1 24 |κ4〈φ′′′(z)〉|ν r4 , (18) with a diffusion coefficient D = 〈φ2(z)〉ν2 which is independent of r. The shape of this potential is shown in figure 2. A potential barrier ∆U must be overcome to escape an unstable state close to R = 0 (assuming that the condition on σ in equation (15) is satisfied). For large ν this system corresponds to an Ornstein-Uhlenbeck process with a Gaussian stationary distribution of fixed unit variance. Thus, if one chooses too 8 U(r) r ✻ ∆U Figure 2: For r = R √ N = O(1) the dynamics can be represented as a diffusion in a symmetric quartic potential U(r). The escape time from an unstable fixed point at r = 0 is mainly determined by the potential barrier ∆U . large ν initially the dynamics will become localised close toR = 0. As ν is reduced the potential barrier confining the dynamics is reduced. The time-scale for escape for large ν is mainly determined by the effective size of the barrier (Gardiner, 1985), Tescape ∝ exp ( ∆U D ) = exp ( 3〈φ2(z)〉ν 8|κ4〈φ′′′(z)〉| ) . (19) As the learning rate is reduced so the time-scale for escape is also reduced. How- ever, the choice of optimal learning rate is non-trivial and cannot be determined by considering only the leading order terms in R as above, because although small ν will result in a quicker escape from the unstable fixed point near R = 0 this will then lead to a very slow learning transient after escape. From the above discussion one can draw two important conclusions. Firstly, the initial learning rate should beO(N−2) or less initially in order to avoid trapping close to the initial conditions. Secondly, the time-scale required to escape the initial transient is O(N3), resulting in an extremely slow initial stage of learning. 4.3 Other sub-optimal fixed points In studies of other on-line learning algorithms, such as Sanger’s rule and back- propagation, a class of sub-optimal fixed points have been discovered which are due to symmetries inherent in the learning machine’s structure (Saad and Solla, 1995a,b; Biehl and Schwarze, 1995; Biehl and Schlo¨sser, 1998). These symmetric fixed points are unstable for small learning rates, but the eigenvalues determining escape are typically of very small magnitude so that trapping can occur if the initial conditions are sufficiently symmetric. In practice this will typically occur only 9 for very large input dimensions (N > 106) and will result in learning timescales of O(N2) for O(N−1) learning rates. Equation (9) does exhibit fixed points of this type for particular initial conditions. Consider the case K = M = 2 as an example. If initially R11 ≃ R21 and R12 ≃ R22 then the dynamics will preserve this symmetry until instabilities due to slight initial differences lead to escape from an unstable fixed point. This symmetry breaking is necessary for good performance since each projection must specialise to a particular source signal. As mentioned above, sufficiently small differences in the initial value of the en- tries in R will typically only occur for very large N , much larger than the typical values currently used in ICA. A very small learning rate is then required to avoid trapping in a fixed point near the initial conditions, as discussed in the previous section. This initial trapping is far more serious than the symmetric fixed point since it requires a learning rate of O(N−2) in order to escape, resulting in a far greater loss of efficiency. In practice, symmetric fixed points do not appear to be a serious problem and we have not observed any such fixed points in simulations of finite systems. This may be due to the highly stochastic nature of the initial dynamics, in which fluctuations are large compared to the average dynamical tra- jectory. This is in contrast to the picture for back-propagation, for example, where fluctuations result in relatively small corrections to the average trajectory (Barber et al., 1996). The strong fluctuations observed here may help break any symmetries which might otherwise lead to trapping in a symmetric fixed point, although a full understanding of this effect requires careful analysis of the multivariate diffusion equation describing the dynamics near the initial conditions. 5 Simulation results The theoretical results in the previous section are for the limiting case where N → ∞. In practice we should verify that the results are relevant in the case of large but finite N . In this section simulation evidence is presented which demonstrates that the trapping predicted by the theory occurs in finite systems. Figures 3(a)–(c) show results produced by an algorithm learning a single pro- jection from 100-dimensional data with a single non-Gaussian (uniformly dis- tributed) component (N = 100,M = K = 1). The matrices A and W are randomly initialised with orthogonal, normalised columns. Similar results are ob- tained for other random initialisations. A cubic non-linearity is used and σ is set to −1, although the adaptive scheme for setting σ suggested by Hyva¨rinen and Oja (1998) gives similar results. In each example, dashed lines show the maxima of the potential in figure 2. Figure 3(a) shows the learning dynamics from a single run with η = 10−5 (ν = 0.1). The dynamics follows a relatively smooth tra- 10 jectory in this case and much of the learning is determined by the cubic term in equation (16). With this choice of learning rate there is a strong dependence on the initial conditions, with larger initial magnitude of R often resulting in signif- icantly faster learning. However, recall that a high value for R cannot be chosen without prior knowledge of the mixing matrix. Figure 3(b) shows the learning dy- namics with a larger learning rate η = 10−4 (ν = 1) for exactly the same initial conditions and sequence of data. In this case the learning trajectory is more obvi- ously stochastic and is initially confined within the unstable sub-optimal state with R ≃ 0. Eventually the system leaves this unstable state and quickly approaches R ≃ 1. In this case the dynamics is not particularly sensitive to the initial mag- nitude of R although the escape time can vary significantly due to the inherent randomness of the learning process. In figure 3(c) the learning dynamics is shown for a larger learning rate η = 4 × 10−4 (ν = 4). In this case the system remains trapped in the sub-optimal state for the entire simulation time. The analysis in section 4.2 is only strictly valid for the case of a single non- Gaussian source and a single projection. However, similar trapping occurs in gen- eral as demonstrated in figures 3(d)–(f). The components of R are plotted for an algorithm learning two projections from 100-dimensional data with two non- Gaussian (uniformly distributed) components (N = 100,M = K = 2). The dif- ferent learning regimes identified in the single component case are mirrored closely in the case of this two component model. 6 Conclusion An on-line Hebbian ICA algorithm was studied for the case in which data com- prises a linear mixture of Gaussian and non-Gaussian sources and a solution to the dynamics was obtained for the idealised scenario in which the number of non- Gaussian sources is finite while the number of Gaussian sources is infinite. The analysis confirmed the stability conditions found by Hyva¨rinen and Oja (1998) and the eigensystem characterising the asymptotic regime was determined. However, it was also shown that there exist sub-optimal fixed points of the learning dynamics which are stabilised by stochastic effects under certain conditions. The simplest case of a single non-Gaussian component was studied in detail. The analysis re- vealed that typically a very low learning rate (η = O(N−2) where N is the data dimension) is required to escape this sub-optimal fixed point, resulting in a long learning time of O(N3) iterations. Simulations of a finite system support these theoretical conclusions. The sub-optimal fixed point studied here has some interesting features. In the limit η → 0 the dynamics becomes deterministic and fluctuations due to the 11 stochastic nature of on-line learning vanish. In this case the sub-optimal fixed point is unstable but the Jacobian is zero at the fixed point (in the 1-dimensional case) indicating that one must go to higher order to describe the dynamics. Standard methods for describing the dynamics of on-line algorithms have all been devel- oped in the neighborhood of fixed points with negative eigenvalues and are not applicable in this case (Heskes and Kappen, 1993). Furthermore, stability of the fixed point is induced by fluctuations. This is contrary to our intuition that fluc- tuations may be beneficial, resulting in quicker escape from sub-optimal fixed points. In the present case one has precisely the opposite effect: stochasticity sta- bilises an otherwise unstable fixed point. In similar studies of on-line PCA (Biehl and Schlo¨sser, 1998) and back-propagation algorithms (Biehl and Schwarze, 1995; Saad and Solla, 1995a,b) sub-optimal fixed points have been found which are also stabilised when the learning rate exceeds some critical value. However, the scale of critical learning rate stabilising these fixed points is typically O(N−1), much larger than in the present case. Also, the resulting time-scale for learning is O(N2) with a very small prefactor (in practice an O(N) term will dominate for realistic N ). These fixed points reflect saddle points in the mean flow while here we have a flat region and escape is through much weaker higher order effects. This type of sub-optimal fixed point is more reminiscent of those which have been found in studies of small networks, which often have a much more dramatic effect on learning efficiency (Heskes and Wiegerinck, 1998). It is presently unclear whether on-line ICA algorithms based on Maximum- likelihood and Information-theoretic principles (see, for example, Amari et al., 1996; Bell and Sejnowski, 1995; Cardoso and Laheld, 1996) exhibit sub-optimal fixed points similar to those studied here. These algorithms estimate a square de- mixing matrix and will require a different theoretical treatment than for the projec- tion model considered here, since there may be no simple macroscopic description of the system for large N . Acknowledgements This work was supported by an EPSRC award (ref. GR/M48123). References Amari, S.-I., Cichocki, A., and Yang, H. H. (1996). A new learning algorithm for blind source separation. In Touretzky, D. S., Mozer, M. C., and Hasselmo, M. E., editors, Neural Information Processing Systems 8, pages 757–763. MIT Press, Cambridge MA. 12 Barber, D., Sollich, P., and Saad, D. (1996). Finite size effects in on-line learning of multi-layer neural networks. Europhysics Letters, 34:151–156. Bell, A. J. and Sejnowski, T. J. (1995). An information-maximization approach to blind separation and blind deconvolution. Neural Computation, 7:1129–1159. Biehl, M. (1994). An exactly solvable model of unsupervised learning. Euro- physics Letters, 25:391–396. Biehl, M. and Schlo¨sser, E. (1998). The dynamics of on-line principle component analysis. Journal of Physics A, 31:L97–L103. Biehl, M. and Schwarze, H. (1995). Learning by on-line gradient descent. Journal of Physics A, 28:643–656. Cardoso, J.-F. and Laheld, B. (1996). Equivariant adaptive source separation. IEEE Transactions on Signal Processing, 44:3017–3030. Gardiner, C. W. (1985). Handbook of Stochastic Methods. Springer-Verlag, New York. Heskes, T. M. and Kappen, B. (1993). On-line learning processes in artificial neural networks. In Taylor, J., editor, Mathematical Foundations of Neural Networks, pages 199–233. Elsevier, Amsterdam. Heskes, T. M. and Wiegerinck, W. (1998). On-line learning with time-correlated examples. In Saad, D., editor, On-line Learning in Neural Networks, pages 251– 278. Cambridge University Press. Hyva¨rinen, A. (1999). Survey on independent component analysis. Neural Com- puting Surveys, 2:94–128. Hyva¨rinen, A. and Oja, E. (1997). A fast fixed-point algorithm for independent component analysis. Neural Computation, 9:1483–1492. Hyva¨rinen, A. and Oja, E. (1998). Independent component analysis by general non-linear hebbian-like learning rules. Signal Processing, 64:301–313. Leen, T. K., Schottky, B., and Saad, D. (1998). Two approaches to optimal anneal- ing. In Jordan, M. I., Kearns, M. J., and Solla, S. A., editors, Neural Information Processing Systems 10. MIT Press, Cambridge MA. Mu¨ller, K.-R., Ziehe, A., Murata, N., and Amari, S.-I. (1998). On-line learning in switching and drifting environments with application to blind source separa- tion. In Saad, D., editor, On-line Learning in Neural Networks, pages 93–110. Cambridge University Press. 13 Saad, D., editor (1998). On-line Learning in Neural Networks. Cambridge Univer- sity Press. Saad, D. and Solla, S. A. (1995a). Exact solution for on-line learning in multilayer neural networks. Physical Review Letters, 74:4337–4340. Saad, D. and Solla, S. A. (1995b). On-line learning in soft committee machines. Physical Review E, 52:4225–4243. Wang, L.-H. and Karhunen, J. (1996). A unified neural bigradient algorithm for robust PCA and MCA. International Journal of Neural Systems, 7:53–67. A Derivation of the dynamical equations From equation (5) one can calculate the change in R and Q (defined in (7)) after a single learning step, ∆R = ησφ(y)sT + α(I −Q)R , ∆Q = ησ(I + α(I −Q))φ(y)yT + ησyφ(y)T(I + α(I −Q)) +2α(I −Q)Q+ α2(I −Q)2Q+ η2φ(y)xTxφ(y)T . (20) Here, the definition in equation (2) and the constraint in equation (4) have been used to set xTAs = sT. One can obtain a set of differential equations in the limit N → ∞ using a statistical mechanics formulation which has previously been ap- plied to the dynamics of on-line PCA algorithms (Biehl, 1994; Biehl and Schlo¨sser, 1998) as well as other unsupervised and supervised learning algorithms (see, for example, Biehl and Schwarze (1995); Saad and Solla (1995a,b) and contributions in Saad (1998)). To obtain differential equations one should scale the parameters of the learning algorithm in an appropriate way, in particular η ≡ µ/N . Typi- cally one chooses α = O(1) but in order to obtain an analytical solution it is more convenient to choose α ≡ α0/N before taking N → ∞ and then take the limit α0 → ∞. The dynamics do not appear to be sensitive to the exact value of α as long as α ≫ η and it is therefore hoped that the dynamical equations are valid for α = O(1) which is usually the case. The learning rate is taken to be constant here but the dynamical equations are also valid when the learning rate is changed slowly, as suggested for the annealed learning studied in section 4.1. As N →∞ one finds, dR dτ = µσ〈φ(y)sT〉+ α0(I −Q)R , (21) dQ dτ = µσ〈φ(y)yT + yφ(y)T〉+ µ2〈φ(y)φ(y)T〉+ 2α0Q(I −Q),(22) 14 where τ ≡ t/N is a rescaled time parameter. The angled brackets denote averages over y as defined in equation (8). In deriving the above equations one should check that fluctuations inR andQ vanish in the limit N →∞. This relies on an assump- tion that R = O(1) which may not be appropriate in some cases. For example, in section 4.2 a sub-optimal fixed point is analysed where it is more appropriate to consider R = O(1/ √ N) and a more careful treatment of fluctuations is required. As α0 is increased, Q approaches I. If one sets Q− I ≡ q/α0 and make the a´ priori assumption that q = O(1) then, 1 α0 dq dτ = µσ〈φ(y)yT + yφ(y)T〉+ µ2〈φ(y)φ(y)T〉 − 2q +O(1/α0) . (23) As α0 →∞ one can solve for q, q = 1 2 ( µσ〈φ(y)yT + yφ(y)T〉+ µ2〈φ(y)φ(y)T〉 ) , (24) which is consistent with the a´ priori assumption. Substituting this result into equa- tion (21) leads to equation (9) in the main text. This is an example of adiabatic elimination of fast variables (Gardiner, 1985, section 6.6) and greatly simplifies the dynamical equations. B Eigensystem of asymptotic Jacobian The Jacobian of dR/dτ as µ→ 0 is defined (divided by µ), Jijkl = ∂ ∂Rkl ( 1 µ dRij dτ ∣∣∣∣ µ=0 )∣∣∣∣∣ R=R∗ . (25) This is a tensor rather than a matrix because the system’s variables are in a matrix. One can think of pairs of indices (i, j) and (k, l) as each representing a single index in a vectorised system. If the dynamics is equivalent to gradient descent on some potential function then the above quantity is proportional to the (negative) Hessian of this cost function. The Jacobian is not guaranteed to be symmetric in the present case, so this will not be possible in general. From equation (9) one obtains, Jijkl = −δikδjl ( ξi + 1 2 ξj ) − 1 2 δilδjkξi , (26) with, ξi = { σii〈siφ(si)− φ′(si)〉 for i ≤ min(K,M) , 0 otherwise . 15 One must solve the following eigenvalue problem,∑ kl JijklVklnm = λnmVijnm , (27) where λij and Vklij are the eigenvalues and eigenvectors respectively. A solution is required for all i ≤ K and j ≤M in order to get a complete set of eigenvalues, λii = −2ξi , Vklii = δikδil , λij = −12(ξi + ξj) , Vklij = δikδjl − δjkδil for i < j ≤ K , λij = −ξi , Vklij = δikδjl for j > K , λij = −(ξi + ξj) , Vklij = ξiδikδjl + ξjδjkδil for i > j . (28) 16 0 2 4 6 8 10−1 −0.5 0 0.5 1 0 2 4 6 8 10−1 −0.5 0 0.5 1 0 2 4 6 8 10−1 −0.5 0 0.5 1 0 1 2 3 4 5−1 −0.5 0 0.5 1 0 1 2 3 4 5−1 −0.5 0 0.5 1 0 1 2 3 4 5−1 −0.5 0 0.5 1 (a) (b) () (d) (e) (f) t=N 3  = 10 
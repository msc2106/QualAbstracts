ABSTRACT: 
The Federalist, justifying the Electoral College to elect the president, claimed that a small group of more informed individuals would make a better decision than the general mass. But the Condorcet Jury Theorem tells us that the more independent, better-than-random voters there are, the more likely it will be that the majority among them will be correct. The question thus arises as to how much better, on average, members of the smaller group would have to be to compensate for the epistemic costs of making decisions on the basis of that many fewer votes. This question is explored in the contexts of referendum democracy, delegate-style representative democracy, and trustee-style representative democracy. 
 
PREDICTION: 
 ' ' '' ''    ' '' ''    ' '' ''    ' '' ''  
 
FULL TEXT: 
  Keywords: Condorcet Jury Theorem; epistemic democracy; representative government; Federalist papers; referendum Introduction In the Federalist No. 68, Hamilton (1788/1961: 458) commends the Philadelphia Convention’s plan for an Electoral College to choose the president, saying: It was desirable that the sense of the people should operate in the choice of the person to whom so important a trust was to be confided. This end will be answered by committing the right of making ity to men chosen by the people for the special purposey It was equally desirable that the immediate election should be made by men most capable of analyzing the qualities adapted to the station, and acting under cir- cumstances favourable to deliberationy A small number of persons, selected by their fellows from the general mass, will be most likely to possess the information and discernment requisite to so complicated an investigation. This article aims not so much to test that conjecture as to calibrate it – to define the parameters within which, and the reasons for which, it may or may not be true. We go on to assess, in a similar manner, the epistemic consequences of bicameralism, of * E-mail: Bob.Goodin@anu.edu.au 303 party government, and of representative government of two ideal types (trustee and delegate) and mixtures of them. What we refer to as ‘the Federalist’s conjecture’ is the proposition that a smaller group of more competent people is epistemically superior to a larger group of less competent ones. In this article, we focus on the two reasons that Hamilton offers for that proposition. (There may well be others, but we do not explore them here.1) Hamilton’s first reason has to do with the supposed fact that members of the smaller group will be more ‘capable’: they will have been selected because they ‘possess the information and discernment’ required for the task. Call that the Selection Effect (Vermeule, 2009: 45–46). Hamilton’s second reason has to do with the supposed fact that, as a smaller group, electors would be ‘acting under circumstances favorable to deliberation’. Call that the Deliberation Effect. In Hamilton’s own statement of the proposition, and in popular discussions both before and since, emphasis falls most heavily on the first factor, the Selection Effect. Condorcet (1785/1976: 50) was neither the first nor the last to say that ‘a very numerous [group] cannot be composed of very enlightened men’ and to commend a smaller and more select decision-making body in consequence.2 However, it is simply not the case that a smaller group of more competent people will always be epistemically superior to a larger group of less competent ones. Ironically, that is the clear lesson of Condorcet’s Jury Theorem (CJT). Whether the Federalist’s conjecture is true in any given case depends on many things: the number of people in each group, large and small; the independence and individual competence of people in each group; how the agenda is set and voting is structured in each group; and how much deliberation contributes to the collective competence of each group. In the section ‘The folly of the Selection Effect’, we offer some sample calcu- lations to illustrate the implications of the CJT for the Federalist’s conjecture. There we see that, given voting bodies of the size typical in modern polities and individual voter competence even modestly better than random, the Selection Effect alone is unlikely to suffice to vindicate the Federalist’s conjecture. If that conjecture is to be true at all, that will instead probably be largely due to the Deliberation Effect, as we show in the section ‘Factoring in the Deliberation Effect’. 1 People might pay more attention to the task when they are members of a small group specifically assigned responsibility for the task than they would have done when members of a larger group in which the task is everyone’s job and no one’s (Vermeule, 2009: 46–47). Or people in the smaller group might take their role responsibilities seriously and be less likely to sacrifice the public interest to their own interests, as Madison (1787a/1961: 62) speculates in Federalist No. 10. 2 Madison (1787b), perhaps echoing Condorcet, wrote similarly in Federalist No. 58 that ‘the larger the number, the greater will be the proportion of members of limited information and weak capacities’. Montesquieu (1721/1973: 167), anticipating them both, wrote in Persian Letters that ‘there are very few good minds, and everyone agrees that there is an infinite number of bad ones’. For the modern social science debate on this issue see, for example, Page and Shapiro (1992), Delli Carpini and Keeter (1996), and Lupia and McCubbins (1998). 304 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N The CJT tells us that, all else held equal, smaller groups are epistemically less reliable than larger groups.3 When a smaller group is included as a veto player in an overall decision-making procedure, its poorer epistemic performance compromises, to a greater or lesser extent, the epistemic competence of the overall process. Those small-group elements in a decision-making process constitute, in Vermeule’s (2009: 50–53) felicitous phrase, ‘epistemic bottlenecks’. Examples include cases of smaller upper chambers in bicameral legislatures and small pivotal parties in parliaments. In the section ‘Institutional epistemic bottlenecks’, we provide sample calculations of the scale of epistemic costs (i.e. the probability of reaching an incorrect decision) that those particular epistemic bottlenecks might impose. Representatives who take a ‘trusteeship’ attitude toward their role would constitute another epistemic bottleneck, insofar as a large number of voters elect a small number of trustee-style representatives. In the section ‘Delegate vs. trustee-style representatives’, we provide sample calculations to show what might be the epistemic costs of representatives taking a trustee-style attitude toward their tasks, compared to their taking a delegate-style attitude or to our making decisions by the direct vote of the electorate as a whole. Actual representatives typically take a more mixed approach. In that same section, we provide sample calculations to show how many delegate-style repre- sentatives it would take in a mixed assembly to make that assembly’s overall epistemic performance almost as good as that of an assembly composed of trus- tees alone. ‘Almost as good’ might be good enough, because once again trustees would be capable of benefiting from the Deliberation Effect in the assembly, in a way electorally bound delegates would not. The Condorcet Jury Theorem Assume that a large number of voters have to vote on two alternatives, of which one is the correct choice. The standard CJT model uses the following formula to calculate the probability PN(n, p) that a majority vote among n independent voters will yield the correct outcome,4 when the probability of each of the voters voting for the correct outcome is p: PNðn; pÞ ¼ Xn h¼ðnþ1Þ=2 n h   phð1pÞnh: ð1Þ The CJT tells us that, when voting by simple majority rule, the group is more likely to vote for the correct outcome than is an individual voter, and larger groups perform better than smaller groups. (That is referred to as the ‘non-asymptotic’ result.) The CJT further tells us that the probability that the majority votes for the correct outcome 3 That has come to be known as the ‘many-minds’ argument (Sunstein, 2009; Vermeule, 2009). 4 Formula 1 assumes that n is odd. Throughout this article, when n is even and ties arise, we treat ties as a failure to reach any (or hence the correct) conclusion. Epistemic aspects of representative government 305 approaches 1 for large groups (the ‘asymptotic’ result).5 Furthermore, sample calculations show that that typically happens relatively quickly. The CJT rests on the following assumptions: 1. there is a correct choice to be found; 2. each voter is competent, that is, each voter has the same probability p. 0.5 to detect the correct alternative; 3. the votes are probabilistically independent (conditional on the state of the world regarding the correct alternative), that is, voters are not influenced by each others’ votes, or common causes that introduce biases; 4. all voters vote sincerely for the alternative they believe to be correct. We will discuss each assumption in turn. All can of course be criticized. However, our conclusion will be that, while obviously political life does not accord with those assumptions completely, the CJT framework captures much that is important in politics. The ‘correct choice’ assumption Some claim that politics is seldom, perhaps never, about making ‘correct’ choices (Black, 1958: 163; Miller, 1992: 56). We shall offer here three reasons for proceeding with modeling on the assumption that political decisions can be correct or incorrect – or at least that there are truth-apt elements in most political decisions. The first is ad hominem. The Federalist’s own conjecture was predicated pre- cisely on that same assumption. That is to say, the Federalist’s conjecture assumed that there are facts that a smaller group of wiser people would be more likely to find. In assessing the soundness of Federalist’s conjecture, it is only right that we should proceed from that same assumption. Second, surely at least some of the claims that matter in politics can be either true or false (e.g. that man-made climate change is happening, that consumption taxes will be regressive in their impact). Not everything of political consequence is of that sort; there are other things that matter politically, which do not admit of truth or falsity. For ease of reference, let us call the former ‘facts’ and the latter ‘values’. Most actual political decisions will constitute a combination of both. Nevertheless, supposing that getting the facts right will lead to better outcomes, where there are facts to be gotten right, institutional designers ought to be interested in mechanisms for maximizing correct answers in the factual domain. Third, let us just note in passing that there are also some far stronger claims that might be made here. The nature of value judgments is a subject of heated dispute within ethical theory. Some meta-ethicists are ‘moral realists’ and insist that 5 Both results have been shown to be true when voting by plurality rule on any number of options, under conditions analogous to those of the CJT (List and Goodin, 2001). 306 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N there are facts of the matter about moral propositions. Others are ‘conventionalists’ about morality – but even they would agree that there is indeed a ‘truth of the matter about what is the convention around here,’ which is to say, what the con- vention of the society in question actually is. All that is strictly required to vindicate our use of the CJT is that there be a standard of ‘correctness’, that is independent from the votes of the people making the decision. As long as such a standard applies to a domain of questions relevant for political decision making, the CJT is of genuine political interest. The ‘competence’ assumption The classic CJT assumes, for mathematical convenience, a homogenous set of voters with an identical level of competence above p. 0.5 in two-option choices. But homogeneity is not strictly necessary. First, it has been shown that the CJT holds for voters of heterogeneous competence, so long as the distribution of competences within the group remains symmetric around a constant mean of p40:5 as group size increases (Grofman et al., 1983). Second, it has been shown that at least the asymptotic result (group competence converges to 1 as the group size tends to infinity) holds even with asymmetric distributions of competence so long as p40:5 (Owen et al., 1989; Dietrich, 2008).6 However, if people are incompetent, in the sense of p, 0.5, the CJT goes into reverse, and the larger the number of voters the more likely it will be that a majority vote among them will yield the wrong result. (We return to this issue in the penul- timate section.) Of course, any given individual on any given occasion might well be wrong. That would be unsurprising. But under what conditions might a large group of individuals manifest judgment that is worse than random? On the face of it, it would seem that for them to be systematically worse than random, people would have to know what the right answer is and perversely conspire to vote against what they know to be the truth. Or they must all be influenced by a common factor that leads them astray. Both cases would be a violation of the ‘independence’ assumption (Sunstein, 2009: 175). It is to that which we next turn. The ‘independence’ assumption The classic CJT formulation assumes that votes are probabilistically independent of one another, conditional on the state of the world regarding the correct alter- native. That is to assume that the voters neither causally influence each other, nor are jointly influenced by the same causes. Since voters are typically part of 6 Here the average competence is defined as p ¼ limn!1ðp1 þ    þ pnÞ=n (Dietrich, 2008). Note that the non-asymptotic result does not hold. That is to say, it is not true that larger groups are always better than smaller groups in identifying the correct alternative under those circumstances. That is shown by counterexamples in Owen et al. (1989). Ben-Yashar and Paroush (2000) prove that if all individuals have a competence greater than 0.5, then the group competence is greater than the average individual com- petence, thereby offering a weaker version of the non-asymptotic result. Epistemic aspects of representative government 307 a complex network of influences, the independence condition is unlikely to be met perfectly.7 Politically, the most serious threat to the independence assumption is probably the existence of ‘opinion leaders’. If every one of the n voters slavishly votes exactly the same way as a single opinion leader, then we do not have n inde- pendent pieces of information being pooled in the vote: we have only one, that of the opinion leader. It is then not a case of ‘many minds’, but rather a case of ‘one mind, many mimics’. The probability that the majority vote is correct does not in that case increase with the number of voters; the probability that the majority of a group who slavishly vote the same way as a single opinion leader is correct is merely the probability that that opinion leader is correct. While such extreme cases of opinion leadership are devastating to the CJT result, weaker cases are not. True, any degree of opinion leadership will always (to some greater or lesser extent) decrease the speed with which the probability of the majority being right approaches 1. But both the asymptotic and non-asymptotic CJT results still obtain, just so long as the probability p that any given voter will follow the opinion leader (i.e. vote the same way he does) is sufficiently small in relation to the probability p of the voter being right when acting independently from the opinion leader. Specifically, group competence PN(n, p) converges to 1 just so long as poðp0:5Þ=p (and it converges to the probability that the opinion leader himself chooses the correct outcome if that inequality is reversed). That proposition follows straightforwardly from Boland et al. (1989; see Spiekermann and Goodin, forthcoming: Appendix A.2). Or again, if there are equal-and-opposed opinion leaders – or even just many uncorrelated opinion leaders – the effects of their opinion leadership on the majority vote will largely cancel out and the CJT results will still obtain (Spiekermann and Goodin, forthcoming). Note, importantly, that jury theorems are still possible with weaker indepen- dence assumptions. Dietrich and List (2004) prove a new jury theorem where dependence is caused by shared evidence (see also Ladha, 1992, 1993, 1995). In that account, the CJT concerns the ability of individuals and groups to reach the same judgment as an ideal interpreter would on the basis of the shared evidence that is available to them. The CJT, thus understood, shows that the majority of a large group of independent voters (now independent conditional on the evidence) converges on the competence of an ideal interpreter who processes that evidence 7 Furthermore, Dietrich (2008) shows that the independence assumption does not usually hold because conditioning on the state of the world does not rule out dependence induced by common causes that influence the voters. He points out that one could condition on all common causes influencing voters in the present decision problem, thereby making the independence assumption true. However, such a move precludes us from knowing whether the competence assumption is justified, since there is no way of knowing the competence of individuals for each specific problem. 308 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N in the best possible way, and who chooses the option most likely to be true given that evidence. This way of modeling relaxes the independence assumption: votes no longer need to be independent conditional on the state of the world; all that is required is independence conditional on the available evidence, and correlation induced by shared evidence is no longer a problem. This extension is plausible because the quality of group judgments naturally depends on the available evidence. It also explains why groups can be wrong even if the CJT’s asymptotic result would suggest near infallibility: the probability of the majority’s being correct is now upper-bounded by the probability that the evidence available to it, interpreted in the best possible way, is actually pointing to the correct result. We return to these issues in our discussion of the Deliberation Effect in the section ‘Mechanisms’ below. A more general treatment of the effect of correlation and new jury theorems arising from this can be found in Kaniovski (2010), Kaniovski and Zaigraev (2011) and Zaigraev and Kaniovski (2010). For purposes of modeling reported in this article, we proceed with the idealized assumption of independence, but arguments analogous to ours could be made with weaker independence conditions. The ‘sincerity’ assumption Finally, the CJT presupposes that voters vote for the alternative that they sincerely believe to be the correct one. But they might well be tempted to cast their vote ‘strategically’, because strategic voters realize that their votes only matter if they are pivotal. Strategic voters ponder the question: ‘would I vote for this if my fellow voters were exactly split on this matter?’ And often enough, the infor- mation derived from the assumption of a split distribution of votes overrules one’s own private belief on the matter. In addition, if there are more than two options to choose from, there may also be strategic votes for second-best alternatives to prevent the victory of some option they think is even worse. If voters vote strategically rather than sincerely in that way, the CJT does not necessarily hold.8 We do not deny that this can happen, particularly in small-scale committees and sometimes even among large electorates. But for strategic voting of that kind to be commonplace, the voters need to acquire a lot of information about their opponents and their reasoning processes, and compute this information adequately. One also needs to assume that voters care primarily about getting the overall outcome right, not about expressing their own sincere belief – an assumption far less obvious than is sometimes claimed. No matter how one assesses the plausibility of strategic voting in real-life settings, it is first worth seeing what would happen in ‘idealized’ circum- stances where everyone always votes sincerely, as a baseline, before feeding those complications into any models. 8 See Austen-Smith and Banks (1996) and Feddersen and Pesendorfer (1998). Epistemic aspects of representative government 309 The folly of the Selection Effect The CJT tells us that it is perfectly possible for the majority among a large number of less competent (but still better-than-random) voters to be more likely correct than the majority among a small number of more competent voters. The Federalist’s seemingly obvious conjecture is thus not necessarily true. It all depends on the competence of people in each group, and on the number of people in each group. On the basis of formula 1, we can undertake some sample calculations to see how the Federalist’s conjecture might fare under various assumptions. First let us look at how the CJT operates in the smaller-scale settings where its consequences are more easily calculated and hence to which it has most familiarly been applied. Table 1 presents results for various values of p and n. Focus on the case of 1001 people, each of whom is individually only p5 0.550 likely to be correct in a two-option choice. Suppose members of that group, following the Federalist’s advice, decide to leave the choice to a small group of 11 persons who are more capable than themselves. How competent does each of those 11 persons have to be for that smaller group to outperform the larger group epistemically? Given 1001 persons with competence of p5 0.550, the probability that a majority among them is correct is PN5 0.999. For a majority vote among merely 11 people to be as reliable as that, those 11 people would have to be individually over p5 0.800 likely to be correct. Maybe this is not strictly impossible, but it certainly seems unlikely that those 1001 people can find 11 people who are that much more competent than themselves. So far as the Selection Effect is concerned, the Federalist’s conjecture becomes even more implausible once the number of voters grows very large, as is the case in real-world electorates.9 (When we talk about applying our models to ‘real- world settings’, it is the number of people typically involved rather than any other aspect of the ‘real world’ to which we will typically be referring.) Table 1. Probability that the majority of a group is correct, for given group sizes and competences Probability of each member of the group being correct Group size 0.501 0.510 0.550 0.600 0.700 0.800 0.900 11 0.503 0.527 0.633 0.753 0.922 0.988 E1 101 0.508 0.580 0.844 0.979 E1 E1 E1 1001 0.525 0.737 0.999 E1 E1 E1 E1 9 Most legislatures of moderately large countries have on the order of 500–600 members (Inter- Parliamentary Union, 2010). To avoid computational overload, we calculate PN(n, p) for large values of n by normal approximation; see Appendix 1 for details. 310 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N Take for example a case modeled akin to the 2008 US election.10 There, the president was elected indirectly by an Electoral College consisting of 539 mem- bers, instead of being elected directly by the 131,000,000 people who voted in that year’s presidential election. For the sake of this example, suppose – contrary to fact, but in line with the Federalist’s hopes and expectations – that members of the Electoral College exercise their own judgment rather than necessarily voting the same way as the citizens of the state they represent. And let us make the modest assumption that voters among the electorate as a whole are individually p5 0.510 competent. For a majority among the 539 members of the Electoral College to be epistemically as reliable as a majority among 131,000,000 such voters, members of the Electoral College would have to be individually p5 0.976 competent.11 That seems inconceivable. Thus, the Federalist’s conjecture is unlikely to be true by virtue of the Selection Effect alone. Among groups the size of contemporary electorates, anyway, it seems unlikely that a small group of individuals can be chosen that is sufficiently more competent for its collective competence to exceed that of the electorate as a whole. Factoring in the Deliberation Effect The second prong of the Federalist’s conjecture is that a smaller group might be more likely to be correct by virtue of its deliberative superiority. This possibility is less discussed among commentators on the Federalist or the Electoral College, but it is much discussed by a host of contemporary deliberative democrats (Bohman and Rehg, 1997; Dryzek, 2000; Luskin et al., 2002; Goodin, 2008). Mechanisms There are various ways in which this might occur. Most straightforwardly, deliberation might be expected to increase the competence of individuals who are party to the deliberation. That would of course flow straightforwardly on into an increase of the collective competence of the deliberating group. But as we have seen, the gain in individual competence would typically have to be unrealistically large to merely catch up with the more numerous population. Without in any way minimizing the practical importance of increasing individual competence through deliberation, we set it aside for purposes of our subsequent discussion. 10 Other large-n examples appear in Appendix 2. ‘Akin to’, in the sense of ‘of the same size’ – but with an Electoral College where votes are genuinely susceptible to change as a result of deliberations within the College. 11 How competent each member of the smaller group would individually have to be, in order for the collective competence of the majority among the smaller group to equal the collective competence of the majority among the larger group, is given by the number in the top entry for each assembly and competence level in Table A2.1 in Appendix 2. Epistemic aspects of representative government 311 Beyond that, there are at least three additional mechanisms by which delib- eration might make a small group collectively more competent, without altering the individual competence of the people comprising it: 1. In the course of deliberation, the group might uncover some new evidence.12 On one plausible interpretation discussed in the section ‘The ‘‘independence’’ assumption’ above, all that the CJT proves is that the majority of a large group of individuals is almost certain to choose the best alternative given the evidence available to it (Dietrich and List, 2004). That opens up possibilities for deliberation to improve the epistemic performance of the group. If deliberation unearths better evidence, the chance of the group being correct increases without an increase in individual competence. 2. Remember, too, that all the CJT proves is that the majority of a large group of independent voters who are better-than-random is almost certain to choose the best alternative from among the alternatives presented to them. The CJT model thus requires alternatives to be well defined. If the alternatives are not well defined, the correct alternative cannot be chosen. Insofar as deliberation among a smaller group leads them to an improved definition of the alternatives, and insofar as one of those alternatives is correct, the group is able to select it. That is another way in which deliberation among small groups can cause the collective competence of the group to increase, without the individual competence of its members increasing.13 3. A third effect might be on processes of reasoning. Among large groups, decisions are inevitably taken by aggregating people’s votes on the ‘bottom line’. Among smaller groups, there are more discursive opportunities for ‘premise-probing’ (Goodin, 2008: 87–92). That can obviously improve individual-level decision making, insofar as each internalizes the lessons learned from those probes of her own and others’ premises and revises her chain of reasoning accordingly. It can also improve group-level decision making, insofar as the decision process of the group incorporates votes on premises and not just votes on the ‘bottom line’ (List, 2005; Bovens and Rabinowicz, 2006; Pigozzi, 2006). Incorporating premises is often (but not always) a better way to pool information and therefore reach better results. Those are ways in which a Deliberation Effect might occur, independently of any Selection Effect.14 12 That may or may not be what Hamilton (1788/1961: 458) had in mind when claiming that the small group ‘will be most likely to possess the information’ to choose correctly. 13 This point is related to Fuerstein’s (2008) observation that the quality of collective decisions depends on the agenda. Note that the effect of deliberation can cut both ways. It can improve the definition of the alternatives so that the CJT applies, but it could also render the decision problem less tractable. 14 Note that, while deliberating with one another is arguably the only way of achieving the third, it is only one among many possible ways of achieving the first two. We are here claiming only that delib- eration can have those effects, not that it is the only way to achieve those effects. 312 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N Notice, however, that deliberation might also reduce the collective competence of the group, insofar as it leads to a violation of the independence assumption.15 We do not deny the possibility that deliberation might have that negative effect on the collective competence of the group, as well as the positive ones outlined above. All those effects can be present, and the epistemic net effect of deliberation still be positive, so long as a reduction of independence is outweighed by other effects. Consequences Exactly how much those various Deliberation Effects might contribute to a smaller group’s epistemic competence will vary with circumstances. Deliberation may increase or decrease correlation between voters. In the worst case, delib- eration might induce dependence where there was none before, without increasing competence at all. But this is an unnecessarily pessimistic picture. In many cases, deliberation will reduce the overwhelming effects of opinion leaders, will make voters aware of a plurality of arguments, and will make it less likely that they just blindly adopt the opinions of their peers. Successful deliberation should bring us closer to the CJT’s idealized independence assumption. In addition, it will often increase group competence along the pathways discussed. We make no efforts to model these effects here in any formal way, so we cannot say just how big those effects are likely to be. Deliberative democrats offer many reasons to think that they may be large. But – and this is all that we need for present purposes – they do not have to be very big, in order to make the Federalist’s conjecture true. Let us demonstrate that by taking a deliberately low-ball estimate of the epis- temic value of deliberation. Suppose that the superior deliberative circumstances of smaller representative assemblies will make them at least one percentage point more likely to reach the correct decision than the electorate as a whole. We can then calculate how individually competent each member of the representative assembly would have to be, in order for the assembly’s collective competence to be within one percentage point of that of the electorate as a whole. In that way, we can calculate how big the Selection Effect needs to be in order for the Deliberation and Selection Effects combined to vindicate the Federalist’s conjecture, even if the Deliberation Effect is no stronger than this very conservative assumption. Return to a case akin to the 2008 US presidential election.16 If we could have relied upon the Deliberation Effect to improve the smaller Electoral College’s collective competence by just one percentage point, then voters who are p5 0.510 individually competent would only have had to choose representatives who are p5 0.551 individually competent in order for the collective competence of the 15 For instance, sequential voting with continuous updating can lead to epistemically deleterious ‘information cascades’ (Bikhchandani et al., 1992; Goodin, 2008: ch. 6; Spiekermann and Goodin, forthcoming). Deliberation might also violate the independence condition more than previously thought (cf. Estlund, 1989: 1320; Waldron, 1989: 1327–1328; Dietrich, 2008). 16 Once again, examples of other assemblies and other values of p are shown in Appendix 2. Epistemic aspects of representative government 313 538 members of the Electoral College to exceed the collective competence of the electorate as a whole.17 That would seem to be an eminently realistic ambition. Thus, the Federalist’s conjecture is plausibly true. But to be plausibly true, the conjecture has to rely heavily on the Deliberation Effect rather than upon the Selection Effect alone. Institutional epistemic bottlenecks One lesson of the CJT is that incorporating a smaller decisional body in the political process constitutes a bottleneck that undermines the epistemic reliability of the process overall. There are various familiar examples of such small decisional bodies in the institutional architecture of modern democracies. Smaller upper houses in bicameral legislatures are one example.18 Small pivotal parties in parliaments are another. Just how much of an epistemic bottleneck might those be – assuming epistemic performance is one attribute (among many others) by which we should evaluate our political institutions? Strong bicameralism By ‘strong bicameralism’ we mean having two directly elected sets of representatives sitting in separate chambers of differing sizes, each of which has a veto on legislation. We focus upon the particular example of the US Congress, comprising a larger House of Representatives (with 435 members) and a much smaller Senate (with 100 members). For the limiting case, suppose (again contrary to fact – but just to see what would happen in what, from the perspective of the CJT, would be the epistemically worst-case scenario) that each member takes a trustee-style attitude toward the representational task, voting purely on the basis of his or her own 17 Indeed, if we can assume the Deliberation Effect can be relied upon for at least a one percentage point improvement in the assembly’s collective competence, voters can sometimes even choose representatives who are individually less competent than themselves and the assembly’s collective competence will still exceed that of the electorate. Appendix 2’s Table A2.1 shows, for example, that in the 2005 House of Commons MPs need to be only over p50.546 competent for their collective competence to exceed the collective competence of an electorate composed of voters whose individual competence is p50.550, or, indeed, anything higher. The explanation of this result – and of why the required competence for representatives does not increase with increasing competence of individual voters after some point – is that the electorate has achieved a collective competence of virtually 1, and ever-higher competences among individual voters cannot further improve that performance after a one-percentage-point ‘deliberative boost’. In those cases, the question is simply what individual competence is required among members of a representative assembly of the requisite size to achieve collective competence of 0.990. And with representative assemblies the size of the UK House of Commons, that level of collective competence is achieved with surprisingly low levels of individual competence. 18 Condorcet was himself bitterly opposed to bicameralism, as he reiterated to Franklin when the draft of the new US Constitution arrived in France in November 1787 (Rosenkranz, 2007: 1293). The problem is not, however, just (or even mainly) that ‘bicameralism amounts to splitting the sample information and results in a reduction in the effective sample size’ (Brennan and Hamlin, 1992: 177). The problem is not that each chamber has only half as many; the problem is instead that one is absolutely very small (the ‘bottleneck’ problem). 314 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N judgment. Further suppose that the competence of individuals in each chamber is p5 0.55. Finally, let us take the number of people in 2008 voting for members of the House of Representatives (112,588,380) as the number of people who would have voted in a referendum that year if direct democracy had been used instead. With those assumptions in place, we are in a position to explore the epistemic consequences of giving the smaller upper chamber a veto on legislation passed by the larger lower chamber, compared with a unicameral assembly and with direct democracy. With an electorate the size of that in 2008, the probability of the majority among them coming to the correct conclusion is almost one, so long as voters are individually appreciably better than random at reaching the correct conclusion.19 So the probability of a correct decision from a direct-democratic vote would be PNE1.0. If the US Congress consisted of the House of Representatives alone, the probability that a majority of 435 would be correct is, on the assumptions outlined above, PN50.982. That is not that far off direct democracy’s mark. But the actual US Congress is strongly bicameral. For an enactment to become law, it must pass both the 435-member House and the 100-member Senate. On the assumptions above, the probability both cham- bers will reach the correct decision and thus enact it into law drops to 0.828.20 Thus, on the assumptions above, requiring legislation also to be passed by the Senate rather than merely by the House alone leads to a 15 percentage point reduction in the epistemic competence of the US Congress (from just over 98 percent to just under 83 percent). Of course, direct democracy would do epistemi- cally even better, but only by a small margin. It is strong bicameralism that carries the much greater epistemic cost (i.e. probability of reaching an incorrect decision). The Senate would only cease to be an epistemic bottleneck if it reached a collective competence close to one – which would require an extraordinarily strong Delibera- tion Effect, or extremely competent Senators. And say what one might about the competence or the superior deliberative capacities of the smaller upper chamber, it seems highly unlikely that they will be able to close a gap of that magnitude.21 Parliaments with small pivotal parties In the real world, representative assemblies are almost invariably organized along party lines. In strongly whipped parliaments, representatives almost always vote 19 Of course, for a group of any given size, however large, there is some value of p so very close to 0.5 that the probability that a majority among the group is correct will fall appreciably short of 1. But for a very large group p has to be very, very, very close to 0.5 for that to be the case. 20 In fact, to capture the tie-breaking power of the Vice President in the Senate, we model the Senate as a group with 101 members. For a correct decision to be made, both chambers have to vote for the correct alternative. 21 Of course, it may appear that sticking with the status quo is often a good decision, and the ‘epistemic bottleneck’ should better be seen as an institutional check against rushing into wrong policies. But in the epistemic framework discussed here, the status quo can be included among the available alternatives. In that case, failing to reach any decision (neither for the status quo, nor for anything else) can only be described as a decision failure. Epistemic aspects of representative government 315 in line with the instructions of their party, rather than exercising their own independent judgment or following the instructions of their constituents. In a parliament with strong parties of that sort, there would be only as many independent sources of judgment at the point of voting on legislation as there are parties. Of course there are more physical bodies in the lobby. But all those MPs are not independent sources of judgment: they all vote purely as their party dictates. Reducing the number of points of independent judgment in that way can have dire epistemic consequences, the CJT teaches us. Let us suppose, however, that those MPs are not purely lobby fodder, just doing as they are told and not exercising any independent judgment anywhere at all. Let us suppose that they exercise independent judgment in the party room rather than on the floor. That is to say, rather than exercising independent judgment when voting on legislation, they instead exercise independent judgment within the party in trying to shape its policies in ways they think best.22 For the purposes of our modeling below, we will suppose that party policy is chosen purely by a majority vote among the party’s MPs. That is clearly contrary to fact: but again, that is a conservative assumption; if there are more independent influences on party policy than that (e.g. the entire party conference), so much the better epistemically.23 Imagine a parliament that is strictly whipped, in which MPs always vote strictly according to their party’s instructions. Assume that there are 603 MPs and that 302 votes are required to enact legislation. Further assume that MPs are indivi- dually p5 0.55 competent, both across the parliament as a whole and within each of the parties into which they are divided. With those assumptions in place, we can calculate the epistemic consequences of dividing legislatures into parties. Suppose first that there were no parties at all in the parliament, as was the Federalist’s original vision (Madison, 1787a/1961: 57). On the assumptions sketched above, the probability that a majority vote in such a parliament would be correct is PN50.993. Introducing parties as such does not do much to reduce that. If the parliament were divided into two almost-equal parties (one with 302 MPs, the other with 301), the probability that a majority vote in parliament would be correct – which is just the probability that the majority among those 302 MPs in the government party room would be correct – is still 0.954. And if there were three equal parties (201 MPs each), then on the above assumptions the probability that a majority comprising any two of them would reach the correct decision would be 0.983.24 It is not the dividing of parliament into well-whipped parties that causes epistemic damage, but rather the introduction of unequally sized parties. And even that, as such, is not the problem. Suppose the parliament were composed of two large parties 22 That is, as trustee-style representatives, rather than following any instructions from the voters in their constituencies. 23 And of course if there are fewer (if, e.g. the Prime Minister merely dictates party policy all on his or her own), so much the worse, epistemically. 24 Calculated as described in Appendix 3. 316 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N (275 MPs each) and one small one (with 51 MPs). If any combination of parties could constitute a majority, then the probability of a correct decision emerging from that parliament is still 0.976. Epistemic problems arise only where the small party is pivotal, that is to say, has to be included in the winning majority.25 On the assump- tions described above, having to include such a small pivotal party in the majority reduces the probability that the parliament would make a correct decision to 0.762. If pivotal, the small party forms an epistemic bottleneck. The calculations just presented enable us now to say just how much of a bottleneck it might be, in real- world sized political settings. On the assumptions above, having to include a small pivotal party of the sort described would reduce the epistemic competence of the parliament in question from over 97 percent to just over 76 percent – a drop of 21 percentage points. Of course, from an epistemic point of view, not dividing parliament into strong parties would be even better, but only by a couple of percentage points. It is small parties being pivotal that carries the much greater epistemic cost, in terms of increasing the probability of an incorrect decision. Delegate vs. trustee-style representatives Having calibrated the epistemic costs of familiar ‘bottlenecks’ – small upper chambers, small pivotal parties – in the institutional architecture of legislative assemblies, let us turn our attention back to the representatives themselves. So far, we have been assuming that representatives act as ‘trustees’, each voting on the basis of his or her own independent judgment as to what is best. Alter- natively, of course, representatives could act as ‘delegates’, each voting strictly according to instructions given by his or her electors. To what extent would representatives taking this different attitude toward their task solve the epistemic problem (i.e. the increased risk that comes from letting decisions be made by smaller representative assemblies rather than by direct vote of the electorate at large) as discussed in the sections ‘The Condorcet Jury Theorem’ and ‘The folly of the Selection Effect’ above? Constituency-based representation with delegates Making public decisions through a legislative assembly composed entirely of repre- sentatives who take a delegate-style attitude toward their task is different from direct democracy. The reason is that representatives represent particular constituencies. First let us reflect upon the epistemic consequences of bunching voters into constituencies, even if their representatives see their role purely as delegates. To calculate the probability that delegate-style representatives acting on instruction in this way reach the correct collective decision, we need to apply 25 We further assume here that the smaller party is pivotal for reasons that are independent of the substance of the position it takes on the policy under discussion: otherwise complex issues of endogeneity arise. Epistemic aspects of representative government 317 formula (1) twice. First we use it to calculate the probability that the majority of constituents is correct in the instructions they give to their representative. Since the representatives always vote as instructed, we equate that with the probability that each representative’s own vote will be correct. We then use formula (1) for a second time to calculate the probability that a majority of representatives with that level of individual competence will reach the correct collective decision. Think, for example, about the 2005 British General Election. Each of the 646 Members of Parliament was elected by around 40,000 voters. So long as the individual competence of each voter is relevantly over one-half, with numbers like 40,000 the probability that the majority among them is correct is going to be very close to 1.26 Representatives instructed by these large constituencies will reach correct decisions with near certainty. Thus, there is virtually no epistemic differ- ence between delegate-style representative government and direct democracy, where electorates are of the size we typically see in real-world politics. An epistemic advantage of trustee-style representatives Is there any credible scenario by which the collective competence of a group of trustee-style representatives might overtake that of groups of delegate-style representatives? Looking at it one way, it seems unlikely. After all, trustees would have to be individually as competent as delegates for their collective competence literally to equal that of the same number of delegates under the same circum- stances. And since the competence of each delegate following the instructions of large numbers of relevantly better-than-random constituents is very close to 1, the individual competence of trustees would have to be near 1 to match that. But assemblies the size of the 2005 UK House of Commons could perform almost as well (be within one percentage point as accurate) as the electorate as a whole with individual competences of individual representatives being as low as p50.546 (see Appendix 2). The Deliberation Effect can plausibly close that sort of a gap. Notice that the Deliberation Effect can work only for trustee-style representatives, not for delegate-style ones. However much delegate-style representatives discuss matters with one another in the assembly, at the end of the day delegates must by definition vote as they have been instructed by their constituents.27 Trustee-style delegates are not so bound, and their votes can indeed be changed by deliberation within the chamber. That affords trustee-style representative government some real scope for ‘closing the epistemic gap’ between it and delegate-style representative government. 26 Of course there is some p so close to 0.5 that that will not be true. But, for instance, as long as individual competence of 40,000 voters is above 0.5108, collective competence is greater than 0.99999. 27 With one possible exception: Perhaps it would be possible for delegates to ask their constituents to instruct them again after the deliberation, and for the constituents to use the advantage of better infor- mation or better options after the deliberation in issuing these new instructions. Then the collective competence can improve even with a delegate-style approach. Of course, this depends on constituents benefiting from deliberations to which they were not themselves directly party. 318 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N Assemblies with both delegates and trustees So far, we have been treating representative assemblies as if they were composed either of all trustees or all delegates. A more realistic scenario is that, on any given issue, some representatives will behave as trustees and some as delegates.28 In modeling that scenario, we take (for analytic convenience) the small-scale case of an assembly with 99 representatives, each of whom is elected by 101 con- stituents. We assume the individual competence of each representative, when acting as a trustee on the basis of his or her own judgment, is p50.550. We assume that the individual competence of each constituent is also p50.550, which (from formula 1) means that the collective competence of a majority among the 101 of them is PN50.844. By definition, a representative who acts as a delegate votes strictly in accordance with the majority of his or her constituents, so each delegate- representative’s individual competence in this scenario is also, therefore, p50.844. Figure 1 displays the way in which the collective competence of such an assembly varies, depending upon the number of representatives who behave as delegates.29 Where there are no delegates and all trustees among the 99 members of the assembly, the collective competence of the assembly is 0.841. But as we see from Figure 1, it rises rapidly with just a few delegate-style representatives, closely approaching 1 by the time there are just 20 delegate-style representatives in the 99-member assembly. 0 20 40 60 80 del 0.5 0.6 0.7 0.8 0.9 1.0 P N Figure 1 The epistemic competence of an assembly mixing delegates and trustees. The x-axis shows the number of delegates among 99 representatives, the y-axis group competence (trustees with p5 0.55, delegates are instructed by 101 voters with p5 0.55). 28 Maybe some representatives act as delegates and others as trustees on all votes and all issues. Or maybe different representatives assume each of those roles on different occasions, so each representative sometimes acts as a delegate and sometimes as a trustee. The model we describe is interpretable under either description. 29 Calculated as described in Appendix 4. Epistemic aspects of representative government 319 Thus, it does not take anything like half of the representatives behaving as delegates for the collective competence of an assembly to come very close to one. At first blush, this might come as a surprise. But upon reflection, it should not be so surprising. If the individual competence is relatively low, most results will end up around an equal split of opinions. If there is a small group that votes more reliably, that increases substantially the group’s collective competence overall.30 But what if the electorate is worse than random? Throughout our discussion, we have been assuming that the individual compe- tence of members of the electorate is relevantly greater than one-half.31 If it is, then given the size of real-world electorates it is almost certain that the majority of them reach the correct decision. But if it is not – if voters are worse than random in making their political choices – then by the same CJT logic it is virtually certain that the majority of them will reach the wrong conclusion. In that case, trustee-style representatives exercising their own independent judgment – even if the probability of their being right is low – would be epistemically superior to the even greater likelihood of error by the majority among the electorate at large.32 One final way of vindicating the Federalist’s conjecture, then, would be to suppose that the competence of individual voters is p, 0.5. Then trustee-style representative government is always epistemically superior to direct democracy. But that way of vindicating the Federalist’s conjecture would leave another large question unanswered, which is why we should let people with competence p, 0.5 choose their own representatives. By the CJT logic, we know that they would virtually always make the wrong choice. Maybe this line of thought could vindicate the Federalist’s conjecture if the electorate were better at choosing people than policies. Here are some reasons why they might be: > Perhaps the electorate is not systematically better than random at making complex decisions, but is better than random at choosing trustees on the basis of their evaluations of their general character and competence. They might thereby end up electing trustee-style representatives who are much better than electors themselves at complex decisions. 30 As List (2003) has shown, group competence depends on the absolute margin (and not the proportion). 31 ‘Relevantly’ in the sense of footnote 19 above. 32 Indeed, if the competence of representatives is p,0.5, it would be epistemically superior to leave the decision to one of them (call her the Dictator) rather than taking a majority vote. By CJT logic, if people’s probability of being correct is p,0.5, then the probability PN that the majority among them is correct is less than the probability of any one of them being correct (PN,p). If the randomly chosen Dictator’s probability of being correct is also p,0.5, of course, it would be even better just to flip a coin, or, indeed, do exactly the opposite of what the majority has decided. 320 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N > Direct democracy asks people to decide on many issues in which their personal stakes are very low (Downs, 1957; Owen and Grofman, 1984). Under such conditions, biases and attempts to influence voters are more likely to succeed. > Similarly, if voters think their competence is low, they might be tempted to ‘epistemically free-ride’ by just siding with the majority. Such a lack of independence may lead to cascades and hence bad outcomes (List and Pettit, 2004; Vermeule, 2009: 46–47). > It is possible that many people do not make up their own mind but rather follow opinion leaders. In the extreme case, people follow either Fox News or MSNBC, so that the station with more followers always wins, and n is effectively reduced to 1. Of course, the last three of these forces will work to contaminate voters’ choices of representatives as well. Those last three forces will also work to contaminate the decisions of representatives themselves – who will after all be accountable to their electorates come the next election, and who are likely to act as ‘delegates’, at least in part, in view of that fact. Beyond all that, however, notice that the Federalist’s conjecture will be vindicated if and only if the electorate is better at choosing people than policies in a very precise way. Individual voters must be individually less competent than 0.5 at choosing policies, but more competent than 0.5 at choosing people. Perhaps sometimes the electorate’s differential competence for choosing people and policies takes that very specific knife- edge form. But again, that seems unlikely to be the case with any generality, which is what would be required for the Federalist’s conjecture to be vindicated via this route. Conclusion Epistemic models like the CJT provide guidance on how best to design institutions to reach correct conclusions, insofar as there are truths that political decision making is trying to track and insofar as political decision makers are genuinely trying to track them. Relying on fewer rather than more independent sources of opinion is generally epistemically disadvantageous. But those effects can be relatively easily overcome insofar as the smaller group is better able to deliberate together or insofar as the smaller group contains a sufficient proportion of people following the lead of a much larger number. Acknowledgments Earlier versions were presented at Australian National University, Trinity College Dublin, University of Maryland, Washington University in St Louis, and the American Political Science Association Annual Meetings in Toronto. We are grateful for com- ments, then and later, from Geoff Brennan, Jan Burgers, Randy Calvert, Dave Estlund, Clarissa Hayward, Christian List, Jenny Mansbridge, Tony McGann, David Miller, Cara Nine, Joe Oppenheimer, Andrew Rehfeld, Norman Schofield, Piotr Swistak, Larry Temkin, and this journal’s editor and anonymous referees. Epistemic aspects of representative government 321 References Austen-Smith, D. and J.S. Banks (1996), ‘Information aggregation, rationality, and the Condorcet Jury Theorem’, American Political Science Review 90(1): 34–45. Ben-Yashar, R. and J. Paroush (2000), ‘A non-asymptotic Condorcet Jury Theorem’, Social Choice and Welfare 17: 189–199. Bikhchandani, S., D. Hirshleifer and I. Welch (1992), ‘A theory of fads, fashion, custom and cultural change as informational cascades’, Journal of Political Economy 100: 992–1026. Black, D. (1958), The Theory of Committees and Elections, Cambridge: Cambridge University Press. Bohman, J. and W. Rehg (eds) (1997), Deliberative Democracy: Essays on Reason and Politics, Cambridge, MA: MIT Press. Boland, P., F. Proschan and Y.L. Tong (1989), ‘Modelling dependence in simple and indirect majority systems’, Journal of Applied Probability 26(1): 81–88. Bovens, L. and W. Rabinowicz (2006), ‘Democratic answers to complex questions – an epistemic perspective’, Synthese 150: 131–153. Brennan, G. and A. Hamlin (1992), ‘Bicameralism and majoritarian equilibrium’, Public Choice 74: 169–179. Condorcet, M. de (1785), ‘Essai sur l’application de l’analyse a` la probabilite des decisions rendues a` la pluralite des voix, Paris: l’Imprimerie Royale’, Reprinted in part in K.M. Baker (ed.), Condorcet: Selected Writings, Indianapolis, IN: Bobbs-Merrill, 1976, pp. 33–70. Delli Carpini, M. and S. Keeter (1996), What Americans Know About Politics and Why It Matters, New Haven, CT: Yale University Press. Dietrich, F. (2008), ‘The premises of Condorcet’s Jury Theorem are not simultaneously justified’, Episteme 58: 56–73. Dietrich, F. and C. List (2004), ‘A model of jury decisions where all jurors have the same evidence’, Synthese 142: 175–202. Downs, A. (1957), An Economic Theory of Democracy, New York: Harper. Dryzek, J.S. (2000), Deliberative Democracy and Beyond, Oxford: Oxford University Press. Estlund, D.M. (1989), ‘Democratic theory and the public interest: Condorcet and Rousseau revisited’, American Political Science Review 38: 1317–1322. Feddersen, T. and W. Pesendorfer (1998), ‘Convicting the innocent: the inferiority of unanimous jury verdicts under strategic voting’, American Political Science Review 92(1): 23–35. Fuerstein, M. (2008), ‘Epistemic democracy and the social character of knowledge’, Episteme 5: 74–93. Goodin, R.E. (2008), Innovating Democracy, Oxford: Oxford University Press. Grofman, B., G. Owen and S. Feld (1983), ‘Thirteen theorems in search of the truth’, Theory & Decision 15: 261–278. Hamilton, A. (1788), ‘Federalist No. 68’, in J. Cooke (ed.), The Federalist, Middletown, CT: Wesleyan University Press, 1961, pp. 457–462. Inter-Parliamentary Union. (2010), ‘PARLINE database on national parliaments’. Retrieved 7 April 2010 from http://www.ipu.org/parline-e/parlinesearch.asp Kaniovski, S. (2010), ‘Aggregation of correlated votes and Condorcet’s Jury Theorem’, Theory and Decision 69(3): 453–468. Kaniovski, S. and A. Zaigraev (2011), ‘Optimal jury design for homogeneous juries with correlated votes’, Theory and Decision 71(4): 439–459. Ladha, K. (1992), ‘The Condorcet Jury Theorem, free speech and correlated votes’, American Journal of Political Science 36: 617–634. —— (1993), ‘Condorcet’s Jury Theorem in light of de Finetti’s theorem’, Social Choice and Welfare 10(1): 69–85. —— (1995), ‘Information pooling through majority-rule voting: Condorcet’s Jury Theorem with correlated votes’, Journal of Economic Behavior & Organization 26(3): 353–372. List, C. (2003), ‘On the significance of the absolute margin’, British Journal for the Philosophy of Science 55: 521–544. 322 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N —— (2005), ‘The probability of inconsistencies in complex collective decisions’, Social Choice and Welfare 24: 3–31. List, C. and R.E. Goodin (2001), ‘Epistemic democracy: generalizing the Condorcet Jury Theorem’, Journal of Political Philosophy 9: 277–306. List, C. and P. Pettit (2004), ‘An epistemic free-riding problem?’, in P. Catton and G. Macdonald (eds), Karl Popper: Critical Appraisals, Abington: Routledge, pp. 128–158. Lupia, A.W. and M.D. McCubbins (1998), The Democratic Dilemma, Cambridge: Cambridge University Press. Luskin, R.C., J.S. Fishkin and R. Jowell (2002), ‘Considered opinions: deliberative polling in Britain’, British Journal of Political Science 32: 455–488. Madison, J. (1787a), ‘Federalist no. 10’, in J. Cooke (ed.), The Federalist, Middletown, CT: Wesleyan University Press, 1961, pp. 56–65. —— (1787b), ‘Federalist no. 58’, in J. Cooke (ed.), The Federalist, Middletown, CT: Wesleyan University Press, 1961, pp. 392–395. Miller, D. (1992), ‘Deliberative democracy and social choice’, Political Studies 40(5): 54–67. Montesquieu, C. (1721), Persian Letters (translated by C. Bett), Harmondsworth, Mddx: Penguin, 1973. Owen, G. and B. Grofman (1984), ‘To vote or not to vote: the paradox of nonvoting’, Public Choice 42: 311–325. Owen, G., B. Grofman and S. Feld (1989), ‘Proving a distribution-free generalization of the Condorcet Jury Theorem’, Mathematical Social Sciences 17: 1–16. Page, B.I. and R.Y. Shapiro (1992), The Rational Public, Chicago: University of Chicago Press. Pigozzi, G. (2006), ‘Belief merging and the discursive dilemma: an argument-based account to paradoxes of judgment aggregation’, Synthese 152: 285–298. Rosenkranz, N. (2007), ‘Condorcet and the constitution’, Stanford Law Review 59: 1281–1308. Spiekermann, K. and R.E. Goodin (forthcoming), ‘Courts of many minds’, British Journal of Political Science. Sunstein, C.R. (2009), A Constitution of Many Minds, Princeton, NJ: Princeton University Press. Vermeule, A. (2009), Law and the Limits of Reason, Oxford: Oxford University Press. Waldron, J. (1989), ‘Democratic theory and the public interest: Condorcet and Rousseau revisited’, American Political Science Review 38(4): 1322–1328. Zaigraev, A. and S. Kaniovski (2010), ‘Bounds on the competence of a homogeneous jury’, Theory and Decision 5 (forthcoming: available online DOI: 10.1007/s11238-010-9216-5). Appendix 1. Est imation of group competence with large n We calculate results for PN(n, p) for large n by normal approximation: PNðn; pÞ  1F ðn1Þ=2þ 0:5npﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ npð1pÞ p ! ; where F is the cumulative distribution function of the normal distribution. Appendix 2. Cal ibrat ing the Select ion Effect in Real-world Representat ive Assemblies In Table A2.1, we explore the collective epistemic competence of three actual assemblies: > First is the case most immediately on Hamilton’s mind: the Electoral College for the first US presidential election in 1789. There were 69 members voting in Epistemic aspects of representative government 323 the Electoral College that year.33 There were 38,818 votes cast for electors that year.34 > Second is the Electoral College in 2008. That year 538 members of the Electoral College were chosen on the basis of 131,237,603 popular votes. > Third is the UK House of Commons in 2005. That year 27,110,727 popular votes were cast for 646 MPs. For each of those representative assemblies, we calculate two statistics. The first, appearing as the upper entry for each assembly and competence level in Table A2.1, is how competent each individual in the representative assembly would have to be in order for the assembly’s collective competence literally to match that of the electorate as a whole. That is the individual competence of each representative that would be required in order for the Federalist’s conjecture literally to be true of those assemblies by virtue of the Selection Effect alone. We calculate those isocompetence values using the Grofman–Dummkopf– Witkopf theorem (Grofman et al., 1983). Let there be two groups, the first of size n with individual competence p1, the second with size n1 y and competence p2, such that p1. p2. The Grofman–Dummkopf–Witkopf theorem states that the two groups are approximately equally competent if y ¼ nðp1p2Þðp1þp21Þ 4ð1p1Þp1ð1=2þ p2Þ2 Table A2.1. Estimated necessary competence of representatives to make their collective decision epistemically equal to that of the electorate or no more than 1% point worse 5 Probability of each member of the electorate being correct Within 1% 0.501 0.510 0.550 0.600 0.700 US Electoral College, 1789 0.524 0.714 0.961 0.990 0.998 0.522 0.637 0.637 0.637 0.637 US Electoral College, 2008 0.649 0.976 0.999 E1 E1 0.551 0.551 0.551 0.551 0.551 UK House of Commons, 2005 0.690 0.986 0.999 E1 E1 0.546 0.546 0.546 0.546 0.546 33 Each cast two votes, so there were 138 electoral votes cast but only 69 actors exercising inde- pendent judgment a` la CJT. 34 That may seem a surprisingly small number of votes, but less than two-thirds of states that year chose electors by any form of popular election, and even where they did the franchise was severely limited. 324 R O B E R T E . G O O D I N A N D K A I S P I E K E R M A N N Solving for p1 yields p1 ¼ 1 2 þ 1 2 ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ n4np2 þ 4np22 þ y4p2yþ 4p22y nþ y4p2yþ 4p22y s ; which we use to derive the isocompetence values stated in Table A2.1. With the lower number for each assembly and competence level in Table A2.1, we report how individually competent each member of the representative assembly would have to be, in order for the assembly’s collective competence to be within one percentage point of that of the electorate as a whole. The results reported in the lower right corner of the cells in Table A2.1 are derived by using the inequality PNðn1; p1Þ þ 0:01  PNðn2; p2Þ with n1, n2 and p1. p2. We estimate PN(n2, p2) with normal approximation, substitute using (1), and use Mathematica& to solve for p1. Appendix 3. Mult i -party parl iaments Let there be three parties A, B, and C with respective collective competences PA, PB, and PC. Assume that any combination of two parties constitutes a majority. To determine the competence of a parliament with strictly whipped parties PParl, we calculate the probability of a majority for the correct alternative: PParl ¼ PAPBð1PCÞ þ PAð1PBÞPC þ ð1PAÞPBPC þ PAPBPC If, for some reason, party A has to be part of the winning majority, the competence of the parliament reduces to PParl ¼ PAPBð1PCÞ þ PAð1PBÞPC þ PAPBPC: Appendix 4. Group competence with delegate–trustee mix Let there be an assembly with d delegates and t trustees, with overall size n5 d1 t. Delegates have competence pd and trustees competence pt. Let v5/v1,v2,y, vnS be a voting profile. The set of all logically possible voting profiles that instantiate a majority for the correct solution is denoted W. Let cd(v) be the number of delegates, and ct(v) be the number of trustees that vote for the correct solution in v. The group competence is Prðd; t; pd; ptÞ ¼ X v2W ðpdÞcdðvÞð1pdÞdcdðvÞ d cdðvÞ ! ðptÞctðvÞð1ptÞtctðvÞ t ctðvÞ ! : Epistemic aspects of representative government 325 
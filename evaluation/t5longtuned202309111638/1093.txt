ABSTRACT: 
This paper considers the pupil intakes to Academies in England, and their attainment, based on a re-analysis of figures from the Annual Schools Census 1989–2012, the Department for Education School Performance Tables 2004–2012 and the National Pupil Database. It looks at the national picture, and the situation for Local Education Authorities, and also examines in more detail the trajectories of the three original Academies. It confirms earlier studies in finding no convincing evidence that Academies are any more (or less) effective than the schools they replaced or are in competition with. The prevalence of Academies in any area is strongly associated with local levels of SES segregation, and this is especially true of the more recent Converter Academies. Converter Academies, on average, take far less than their fair share of disadvantaged pupils. Sponsor-led Academies, on the other hand, tend to take more than their fair share. Their profiles are so different that they must no longer be lumped together for analysis as simply ‘Academies’. Academies are not shown to be the cause of local SES segregation. Instead, they are merely more likely to appear in areas that already have inequitable school mixes. This means, of course, that Academies are not helping reduce segregation (as was one of their original purposes) or increase social justice in education, and the paper concludes that homogeneous Maintained schools should be preferred for this purpose. 
 
PREDICTION: 
This paper updates the published earlier (Gorard 2005, 2009) to address three related questions: What is the link between the prevalence of Academies and local levels of segregation between schools.  The Academies’. Academies are not shown to be the cause of local SES segregation. Instead they are merely more likely to appear in areas that already have inequitable school mixes. This means, of course, that Academies are not helping reduce segregation (as was one of their original purposes) or increase social justice in education, and the paper concludes that maintained schools should be preferred for this purpose. 
 
FULL TEXT: 
 ’ Academies’. Academies are not shown to be the cause of local SES segregation. Instead they are merely more likely to appear in areas that already have inequitable school mixes. This means, of course, that Academies are not helping reduce segregation (as was one of their original purposes) or increase social justice in education, and the paper concludes that maintained schools should be preferred for this purpose. Introduction Policy-makers worldwide keep creating new kinds of schools that are similar to every other kind (i.e. there is no dismantling or radical re-engineering of the concept of schools), claiming success for electoral or other reasons, and then not allowing these schools to be evaluated properly. Several studies based in the US have reported evidence that attainment can be affected by the type of school attended, such as the Promise Academy charter middle school (Dobbie and Fryer 2009), Knowledge is Power Program (KIPP) middle schools (Tuttle et al. 2010), and more general charter schools (Gleason et al 2010). A recent example in England is the Academies programme, started by one government in 2000, continued by the next government from 2010, and now extended to include ‘Free’ schools. City Academies were announced as a new form of secondary school for England in 2000, and the first three opened in 2002. They were independent of local authority control, like the prior City Technology Colleges, and received preferential and recurrent per pupil funding, like the prior Specialist Schools. These early Academies were all replacements for existing schools deemed to be in spirals of decline, with low levels of pupil attainment, set in deprived inner city areas, losing pupil numbers and taking more than their fair share of disadvantaged pupils. They were re-badged and often re-built, with new names, new governance and management, relaxation of National Curriculum requirements, and part-funded by sponsors from the private or third sectors. They were claimed by advocates to be better than their predecessor 2 schools, in terms of pupil performance, and to be a model of a better school for the future. Over time and across political administrations in the UK, their number has grown quickly. By the time of the Schools Census in 2012, there were 1,165 secondary Academies which was more than one third of all state-funded schools in England. Originally, the Academies were set up both to stop the spiral of decline and to improve pupil results. The schools selected at the outset were among the most disadvantaged and so where they changed their intake as a result of Academisation, this was no threat to local levels of socio-economic segregation between schools. For example, where new Academies ended up taking a smaller share of local free-school-meal (FSM) eligible pupils, this meant that neighbouring schools had to take more and so the local clustering of poorer children into specific schools would reduce. However, the Academies programme more recently has only been driven by the purported school improvement agenda, and the social justice element is now largely ignored, meaning that almost any school is eligible to convert. Private fee-paying schools, ex-grammar schools, Foundation schools and many others (including primary) have become Academies. And the even newer Free Schools have been set up as Academies from fresh. All of these are clearly nothing like the most disadvantaged schools in their area, and were not in anything like a spiral of decline beforehand. This raises the very real danger of increased local SES segregation between schools, especially if the new Academies also begin to take a smaller share of FSM eligible pupils like the early ones did. So this paper updates those published earlier (Gorard 2005, 2009), to address three related questions:  What is the link between the prevalence of Academies and local levels of segregation between schools?  Are Academies performing better than other schools, with equivalent pupils? and so:  Is the gain in pupil attainment from Academies worth the possible risk of increased segregation? Segregation matters The issue of segregation, or clustering of similar students between schools, is an important phenomenon (Logan et al. 2012). Problems arising from the social segregation of disadvantaged students in particular schools might include damage to pupil attainment (Palardy 2013). Some studies claim that there is a school mix effect on achievement and participation, and that clustering students with similar backgrounds in schools tends to strengthen social reproduction over generations (Massey and Fischer 2006). However, this is not well established. There are normative models showing how peers apparently become more alike, and ‘frog pond’ models where some students benefit from having a higher profile than their peers (Proud 2010). Others have argued that the net effect of these influences is small or even non-existent (Goldsmith 2011). There is no evidence that selective systems are better (Boliver and Swift 2011), because the overall effect is no better than zero sum (Felouzis and Charmillot 2012). 3 More importantly for this paper, who attends school with who is clearly linked to longer term and wider societal outcomes. The school mix is linked to how students are treated within each school, with children in disadvantaged schools more likely to be ‘diagnosed’ with behavioural difficulties, whereas similar children in other schools may be labelled as having learning disabilities (McCoy et al. 2012). Classes in poorer areas have different patterns of teacher:student interaction, more like those of younger classes in more affluent areas (Harris and Williams 2012), and this can influence the achievement gap between advantaged and disadvantaged students (Knowles and Evans 2012). International studies suggest that socially-segregated school systems endanger students’ sense of belonging, their sense of what is fair (Gorard and Smith 2010), and may polarise information about future opportunities, by removing role models, influencing aspiration (Burgess et al. 2005), and wider social ills, such as ill-health and delinquency (Clotfelter 2001). People growing up in segregated settings may then be less prepared for the academic challenges of subsequent education (Gorard and Rees 2002). Something important is being sacrificed for no apparent gain in attainment. Methods and sources of evidence The questions above are addressed in this paper via secondary analyses of official datasets involving all state-funded secondary schools in England other than those designated ‘Special schools’. Analysis of the intakes to schools is based on figures from the Annual Schools Census (ASC) for all mainstream state-funded schools in England from 1989 to 2012. The ASC includes the number of full-time equivalent students in each school, the number taking free school meals (FSMt), the number known to be eligible for free school meals (FSMe), and several other indicators not discussed in this paper. The relevant intake figures for each school in each year were used to calculate the Gorard Segregation Index (GS) at a national and local authority level. GS is the strict proportion of potentially disadvantaged students who would have to exchange schools with another student for there to be no segregation in the national school system. GS is effectively the same thing as the Hoover Index (Hoover 1941), the delta index (Duncan et al. 1961), the Women in Employment index, the Robin Hood Index, and the Student Change Index (Glenn 2011). Each school’s residual for GS is the absolute value of the result of subtracting the population proportion of all students in each school from the population proportion of potentially disadvantaged students (such as those eligible for FSM) in each school. GS itself is the sum of these residuals for all schools, then divided by two. More formally, GS = 0.5 * (∑|F i/F - Ti/T|) Where: Fi is the number of disadvantaged children in school i Ti is the total number of children in school i F is the total number of disadvantaged children in England T is the total number of children in England. More directly, the segregation ratio (SR) is also calculated for individual Academies. The SR gives an idea of the extent to which any school takes more or less than its ‘fair share’ of disadvantaged pupils. More formally, SR = (Fi/F)/(Ti/T). 4 The Department for Education Performance Tables website (http://www.education.gov.uk/performancetables/) provides the attainment outcomes from schools for all state-funded schools in England. It includes the number of students per school at the end of their Key Stage 4 (KS4), and the figures for Key Stage 2 to KS4 value-added (VA) or contextualised value-added (CVA). KS2 is the statutory assessment in core subjects usually taken at age 10 (the last year of primary school). KS4 is the assessment for age 16+ labelled ‘GCSE and equivalent’. The VA figures include the proportion of the total KS4 students included in the measure (lnown as ‘coverage’). VA is an estimate of the average progress made by students in each school, taking into account their prior attainment, and CVA is the same while also taking into account their abackground characteristics. The way the scores are calculated makes them zero-sum, and 1000 is added to the result. The Department for Education also maintain a National Pupil Database (NPD), containing longitudinal records for all students in England including their background, SES characteristics, prior attainment, courses taken and qualifications obtained. Scatterplots were drawn for school VA or CVA estimated measures against both the number of pupils involved and the coverage of the proportion of pupils involved, in each year. Similarly, Pearson R correlation coefficients were calculated for VA measures and both the number of pupils and the coverage of each school, in each year. Academies and SES segregation The earliest three Academies were set up in 2002. One of these, the Business Academy Bexley, continued a pre-existing rapid reduction in the proportion of FSM-eligible children in their intake (Figure 1). The school now takes nearly half as many FSM children as its predecessor did in 1997. This change could have implications for how easy the school is to run, the barriers that the children face in attending and learning, and for the school outcomes in terms of examination results. However, in other respects not much has changed for this school. In 2002, it had a FSM segregation ratio (SR) of 2.88 meaning that it took nearly three times its fair share of FSM children. This was the highest SR in the LEA by some margin, and some schools had SRs as low as 0.01 (the local grammar school was taking just over 1% of its fair share of FSM children). By 2012, the SR for the Business Academy had fallen to 1.82. But this was still clearly the highest in the LEA and for much the same reasons. What seems to have happened is that the whole area has reduced levels of relative poverty over time. Figure 1 – Percentage of pupils eligible for free school meals, first three Academies, 1997- 2012 5 The Unity City Academy in 2002 was like the one in Bexley in having the highest SR in its LEA by some margin (3.39). It took over three times its fair share of FSM children, in an area in which all school intakes had high levels of deprivation. Unity City reduced its FSM intake in absolute terms over the period 2002 to 2008, but the subsequent economic downturn was associated with a return to the higher levels of poverty recorded in 1997. In some ways the situation is worse. Unity City still has the highest SR in its LEA (4.01) but this has risen to mean that the school is now taking just over four times its share of FSM pupils. Long term, neither Bexley nor Unity Academy has managed to meet one of the original objectives for these schools deemed to be in a spiral of decline, by becoming more like the other schools around it. Both are still clearly the most deprived. As reported by Gorard (2005), Greig City Academy was never the most deprived school in its LEA and was therefore perhaps the wrong target in terms of policy at that time. In 2002, it had high levels of FSM and an SR of 2.97. However, the FSM intake of its predecessor had been falling for three years, and there were several other local schools with higher proportions of FSM. Again nothing much has changed over time. By 2012, levels of FSM were back to those of 1998, and the school had an SR of 3.67. However, this is still not the school with the most FSM children, and there are several other local schools with considerably higher proportions. In summary, all three early Academies had a period of falling FSM following their rebadging and in parallel with their early claims to improved examination outcomes (see below). But there has been little long-term beneficial impact on SES segregation between schools in their LEAs. Turning to the national picture for Academies, what is clear in Table 1 is that talk of ‘Academies’ in general is no longer appropriate, even ignoring CTCs and the newer Free Schools. Converter Academies generally take far less than their fair share of FSM pupils, while Sponsor-led Academies generally take far more than their share. They have very 0 10 20 30 40 50 60 70 1997 1999 2001 2003 2005 2007 2009 2011 Business Academy Bexley Greig City Academy Unity City Academy 6 different profiles. For example, 51% of Converter Academies take less than half their ‘fair share’ of FSM pupils, whereas only 3% of Sponsor-led Academies do. Table 1 – Percentage of secondary schools within specified range of SRs, by school type, England, 2012 Segregation ratio All Maintained All Academies Converter Sponsor-led <0.2 3 11 15 1 <0.5 21 27 36 2 <0.67 12 12 15 4 0.67-1.5 39 26 25 27 >1.5 11 11 5 28 >2 13 13 3 38 >5 0 0 0 0 N 2095 1165 827 330 Note: ‘All Academies’ includes CTCs and Free schools Note: An SR of 5 is the inverse equivalent of 0.2, an SR of 2 is equivalent to 0.5 etc. The difference between Converter and Sponsor-led Academies then manifests itself in their association with local levels of SES segregation between schools (Table 2). Whereas, in 2012 the existence of Converter Academies in any LEA was strongly positively linked to local levels of SES segregation between schools (Pearson’s R or around +0.4), the existence of Sponsor-led Academies was weakly but negatively linked to SES segregation (R of around - 0.15. However, LEAs with both types of Academies were linked to higher levels of segregation than LEAs with a higher proportion of Maintained schools (R of around -0.3). Before this is taken as evidence that Academies cause higher segregation it should be noted that exactly the same pattern holds for 2002 when the first three Academies were created. And the same pattern even holds for 1999 before Academies had been conceived. It makes more sense to view the association the other way around, and state that areas with higher levels of SES segregation since 1999 are now more likely have high percentages of Academies, especially Converter Academies. Table 2 – Correlation between percentage of each type of local school with local level of segregation, England, 1999, 2002 and 2012 LEA-level segregation GS FSM Percentage of Maintained schools 2012 Percentage of Sponsor-led Academies 2012 Percentage of Converter Academies 2012 1999 -0.31 -0.13 +0.38 2002 -0.29 -0.19 +0.40 2012 -0.33 -0.14 +0.41 National patterns of SES segregation Analysis of the national patterns of SES segregation for all schools in England suggests the need for a clearer analytical distinction than previously between those factors determining the underlying level of any segregation and those affecting changes in the level over time. For example, using either take-up or eligibility for free school meals, around one third of FSM pupils in England would have to exchange schools in order for all schools to have their fair share (Figure 2). For as long as records exist, and for both primary and secondary sectors, segregation by poverty has occurred at between 30% and 40%. There have been changes over 7 time, and these changes have been identical for the primary and secondary sectors (Gorard et al. 2013a). There is no time lag, such that secondary schools subsequently reflect the school mixes of the primary schools that feed them. Whatever it is that determines the level of between-school segregation in each year, and whatever determines the pattern of change over time, it applies to schools for both age groups of students at the same time. When school intakes become more mixed, as they did from 2008 for example, it happens to approximately the same extent in both sectors. The same applies when school intakes become less mixed by poverty, as they did from 1998. Figure 2 – Levels of FSM segregation between schools in England, primary and secondary, 1989 to 2012 This result is useful, because it means that a lot of otherwise plausible explanations must be rejected. Annual changes in segregation by poverty are not caused by anything that could be specific to, or differentiated by, the age range of the schools involved. Academies have been around since 2002, and so could be involved in recent changes to segregation. But they cannot explain the pre-existing overall level of segregation. And until very recently they only affected the secondary school sector. There is no conceivable way that their onset could have created an instantaneous and equivalent change in the primary sector. Instead, the causes of the overall level must be sought in more permanent factors, while the changes over time must be linked to slower societal or economic developments, such as changes in the levels of residential segregation, which could affect both school sectors equivalently and in parallel. Gorard et al. (2013a) concluded that, in England, factors such as residential segregation, compounded by travel limitations and policies such as catchment areas and feeder schools, selection by ability, faith-based schools, and bureaucratic boundaries are all relevant to the continuing underlying level of segregation. Smaller changes in segregation over time, on the other hand, are linked to changes in the level of that indicator in the state-funded school system as a whole. When indicators of disadvantage grow in frequency their dispersal across schools also tends to grow (creating lower levels of calculated segregation), and for FSM this is clearly liked to the economic cycle (Cheng and Gorard 2010). For example, the level of 0.000 0.050 0.100 0.150 0.200 0.250 0.300 0.350 0.400 0.450 1989 1994 1999 2004 2009 G fsmt primary G fsmt secondary G fsme primary G fsme secondary 8 segregation for FSM take-up 1989 to 2012 is correlated with the percentage of FSM students at -0.80. When the economy is good, segregation tends to be higher perhaps partly because fewer families live in poverty. When the economy falters, there is more ‘equality of poverty’ and levels of FSM students rise (Gorard et al. 2003). This, as above, suggests that while they are strongly associated with segregation Academies are not the main cause of either its level or variation over time. Are they better schools than their alternatives? Judging school performance It is clear that attainment is strongly related to social background and prior attainment from early schooling onwards. Therefore, raw-score indicators of attainment are not a fair test of school performance. The differences in student outcomes between individual schools, and types and sectors of schools, can be almost entirely explained by the SES and prior attainment differences in their student intakes (Coleman et al. 1982, Gorard 2000). The larger the sample, the better the study, and the more reliable the measures involved, the higher the percentage of raw-score difference between schools that can be explained like this. However, the total variation in scores explained by student intakes will never be exactly 100%. So the crucial question for policy is whether the small remainder of variation is merely error and bias, or whether it is evidence of differential school performance or anything else. For a considerable time now, authors such as Goldstein (2001) have argued that this residual variation is meaningful evidence of a ‘school effect’, and that it can be illustrated through a valued-added approach. Goldstein and others have also argued for a long time that value- added results should be used by policy-makers and practitioners to judge the performance of schools. In the value-added approach, schools are judged by the progress that their students make during attendance at the school. Data on all students in the relevant school population is used to predict as accurately as possible how well each student will score in a subsequent test of attainment. Any difference between the predicted and observed test result is then used as a residual. The averaged residuals for each school are termed the school’s ‘effects’ – and are intended to represent the amount by which students in that school progress more or less in comparison to equivalent students in other schools. A school with an average residual of zero is estimated to be ‘performing’ about as well as can be expected, given its intake. A school with an average above zero is doing better than expected. And this judgement should be independent of the raw-score figures, making it fairer than assessment of raw scores. Since this ‘school effect’ is deemed a characteristic of the school, not its students, it should be reasonably consistent over time where the staff, structures, curriculum, leadership and resources of the school remain similar over time. However, this plausible-sounding approach does not work in practice for a number or reasons. Perhaps the biggest single problem with a value-added approach is that it could never do what it was designed for – to be independent of the raw-score results. Because the VA score is based on the difference between prior and subsequent attainment, the variation in VA scores is half derived from the variation in prior attainment scores and half derived from subsequent attainment. This means that the R-squared correlation between prior attainment and the VA for any set of schools will be at least 0.5 (or R of above 0.7). In fact, the observed correlations can be even higher than this (Ready 2012). An example from Gorard (2006) follows. 9 Figure 3 shows the GCSE results in 2004 for the 124 schools with complete information in York, Leeds, East Riding of Yorkshire, and North Yorkshire. The x-axis shows the percentage of students in each school gaining Level 2 (five or more GCSEs or equivalent at grade C or above). The y-axis shows the official Department for Education value-added scores (with 1,000 added so that 1,000 becomes the average score). There is a near-linear relationship, yielding a correlation of +0.96. This means that purported value-added and raw scores are here measuring what is effectively the same thing. Value-added is no more independent of subsequent attainment than prior attainment is (also correlated at +0.96). It is almost entirely predictable from the raw scores. But these raw-score values have been rightly rejected by most commentators as not being a fair indicator of school performance. Figure 3 – The relationship between value-added and absolute attainment 2004 Source: DfES School Performance Tables A second problem is illustrated in Figure 4, which shows the CVA scores for all 2,897 schools in England with complete CVA information for 2010. It is a cross-plot of CVA score (x-axis) and number of students in the school used to create the CVA score (y-axis). It shows that all of the very large schools have CVA at or near average, and that the most extreme CVA scores are for schools with very few pupils. This suggests that at least some of the CVA results are a consequence of the volatility of small numbers. Figure 4 – Crossplot of CVA measures and the number of students in each school, England, 2010 VA 880 900 920 940 960 980 1000 1020 1040 1060 1080 1100 0 20 40 60 80 100 120 10 There is a similar correlation between coverage and CVA score (Gorard and See 2013). This means that there is a tendency for schools with less than 100% of the data for their KS4 students to appear to have more divergent CVA scores. And it is important to recall this when looking at the VA scores for Academies (below). Due to factors like these, value-added scores are much less stable than raw scores, and schools portray what are apparently dramatic swings in effectiveness every year (Kelly and Monczunski 2007). A number of studies have found VA correlations of only around 0.5 over two successive years for the same schools (Gray et al. 2001). This is confirmed in an analysis of all secondary schools in England over five years, by Gorard et al. (2013b). Within two years the clear majority of variation in schools’ CVA is unrelated to their prior CVA (Table 3). Around 75% is attributable to something else. Academies are no more likely to have stable or positive CVA than other schools. This instability makes VA almost entirely useless for practical purposes because it is not a consistent characteristic of schools, and may not even be a characteristic of schools at all. Table 3 – R-squared comparing CVA scores over time, 2006 versus 2007-2010, England CVA 2007 CVA 2008 CVA 2009 CVA 2010 CVA 2006 0.62 0.26 0.31 0.21 N= 2,897 schools 11 Note: 1,118 of the total of 4,015 secondary school or college entries on the DfE School Performance Website had significant amounts of relevant information missing in at least one year. A third problem relates to error propagation. All value-added analysis involves finding the difference for all students between their predicted and actual attainment. This difference will tend to be insubstantial because the model will be best fit, and the predicted and actual attainment scores will always be of the same order of magnitude. This means that the figure computed for the student value-added score is usually very small, perhaps even negligible, in comparison to the attainment scores from which it is calculated. The results are also heavily dependent on the quality and completeness of the data. There will be errors and missing data in every real-life VA calculation. This creates a substantial initial source of inaccuracy for any VA calculation, and there is no way of adjusting for this statistically since the missing data is not a random subset of the data that does exist. The VA system used in England from 2006 to 2010 factored student background characteristics into the calculations. This was done in order to improve the quality of the predictions and reduce the size of the residuals for disadvantaged groups of students. This Contextualised Value-added (CVA) sounds a sensible and fair innovation. But it means that more data is needed on each student and this adds considerably to the level of missing data. At least 10% of students are missing data every year on each key variable such as whether they are eligible for free school meals, living in care, and their ethnicity or additional educational needs (Gorard 2012). The outcome is a larger error component in a much smaller result. The maximum error can, and usually does, dwarf the residual by several orders of magnitude (Gorard 2010). There is growing evidence, therefore, that for all of its appeal the value-added method just does not work (Hoyle and Robinson 2003, Ridgway and Ridgway 2011, Bradbury 2011). The relevance of this is that with no evidence that individual schools are differentially effective, in terms of test outcomes at least, it follows that there is no evidence that types of schools are differentially effective, and this includes Academies. Academies and school performance The earliest three Academies set up in 2002 were acclaimed an almost immediate success for reportedly achieving better results than their predecessors with equivalent pupils. These claims by politicians and the media were modified when it was pointed out that these schools no longer had equivalent pupils, and all were recording weaker examination results than their predecessor schools had for at least one recent year (Gorard 2005). For example, the predecessor school to the Bexley Business Academy had 24% of pupils reaching Level 2 in 1998 long before Academisation, but the figure was only 21% in 2003 after becoming an Academy (Table 4). And this was despite an increase in pupil exclusions, a decrease in FSM pupils, and a national rise in GCSE results over time anyway. Until recently, its Level 2 indicator including English and maths has also been low (in comparison to Level 2 without English and maths), suggesting that the school has been ‘playing’ the system of qualification entries (see below). In 2005, the Academy recorded 15% of pupils with this tougher Level 2 indicator, while Bexley LEA schools recorded 46%. In nine recorded years its value-added measure of pupil progress for this school, as published by the DfE, has been just about as often negative as positive, and more strongly negative than positive (e.g. 984 is 16 units away from the average of 1,000, whereas 1,012 is only 12 units away). If believed, 12 this is not evidence of a superior kind of school. And as already explained, the school has continuously reduced the proportion of its intake coming from families living in poverty. Table 4 – Intake and outcomes for the Bexley Business Academy – 1997 to 2012 Business Academy FSM Level 2 Level 2 including English and Maths Value-added progress 1997 53 13 - - 1998 49 24 - - 1999 52 14 - - 2000 50 10 - - 2001 49 17 - - 2002 46 - - - 2003 42 21 15 - 2004 37 34 13 984 2005 38 29 15 972 2006 39 32 17 1004 2007 39 31 19 988 2008 30 50 29 1012 2009 31 60 40 1004 2010 32 63 42 1002 2011 31 - 52 991 2012 28 - 53 1003 Note: Level 2 is a government-proposed benchmark for achievement equivalent to five good GCSEs at grade A* to C, sometimes needed for entry to traditional sixth form The latter is important because all of the Academies that were up and running by 2005/06 took a considerably higher proportion (36%) of children eligible for free school meals (FSM) than the remaining educational institutions in England (13%). This is not surprising, given that they were meant to have been selected as some of the most challenged schools in the most deprived areas. It also goes some way towards explaining the generally lower level of raw-score results in Academies for students aged 16. Over the long term, national school- level results at KS4 and the percentage of students eligible for FSM correlate at around -0.5 (Pearson’s R). Schools with more FSM students tend to have a considerably lower percentage of students reaching Level 2 at KS4. Thus, if the first thing that Academies did was to change their intakes, their outcomes should rise even if the new schools were no more effective than the schools they replaced. As with Bexley, the predecessor to the Greig City Academy had 30% of it pupils achieve Level 2 in 2001, while only 26% achieved Level 2 in 2004 after becoming an Academy (Table 5). Again, this is despite having fewer FSM pupils in 2004 than in 1998, and in spite of the general national rise in outcome scores. In 2005, Greig City recorded 10% of pupils attaining the tougher Level 2 target including English and maths, while the figure for Haringey LEA was 32%. By 2012, the figure for the Academy had risen to 44% but the national figure was then 67%. In nine recorded years its value-added measure of pupil progress, as published by the DfE, has been almost as often often negative as positive. None of the ‘positive’ results are very convincing. For example, the highest value-added score for this school was in 2007, but this was calculated based on only 81% of the pupils. Any school in the country could look impressive if they could drop the least accessible or most awkward 13 19% of their pupils. By 2012, when the VA score was negative again, the coverage had risen to 91% of pupils (better but still far from convincing). Table 5 – Intake and outcomes for the Greig City Academy – 1997 to 2012 Greig City Academy FSM Level 2 Level 2 including English and Maths Value-added progress 1997 48 14 - - 1998 56 11 - - 1999 42 15 - - 2000 43 25 - - 2001 31 30 - - 2002 39 - - - 2003 43 35 19 - 2004 47 26 10 983 2005 44 54 10 992 2006 38 59 15 1028 2007 39 65 21 1030 2008 44 53 30 1024 2009 36 62 40 1023 2010 42 58 30 1008 2011 55 - 37 996 2012 55 - 44 981 In the year before conversion to Unity Academy, its predecessor school registered 17% of pupils at Level 2 (Table 6). By 2005, three years after Academisation, the school registered 16% of pupils at Level 2. And this was with substantially fewer FSM pupils than in 2001. In 2005, the Academy had 6% of its pupils reach the Level 2 target including English and maths, while the figure for the depressed area of Middlesbrough was 29%. Again, after becoming an Academy this school reduced its FSM intake without any improvement in outcomes. And again, the Academy has had a mixture of positive and negative value-added scores suggesting (if school effectiveness advocates are to be believed) that it has been both a good school and a bad one, going from good to below average and back to quite good in the three years 2010-2012! In 2005, this school had one of the lowest value-added scores recorded (908 or the ‘inverse’ of 1092). Yet this was the year in which the Secretary of State for Education, the Specialist Schools Trust, the DfE and the BBC were all claiming that it was a success, and that Academies were a superior kind of school. Table 6 – Intake and outcomes for the Unity City Academy – 1997 to 2012 Unity Academy FSM Level 2 Level 2 including English and Maths Value-added progress 1997 60 13 - - 1998 62 2 - - 1999 51 13 - - 2000 46 4 - - 2001 57 17 - - 2002 47 - - - 2003 49 16 7 - 14 2004 50 17 7 921 2005 49 16 6 908 2006 44 34 14 983 2007 45 45 12 1013 2008 41 49 18 1000 2009 54 68 23 1017 2010 55 84 28 1032 2011 55 - 25 998 2012 60 - 48 1018 The third column in Tables 4 to 6 shows that where the figures overlap the situation was worse, if Level 2 requires a C grade or better in both maths and English. This suggests that the shift in the more general Level 2 figures, above and beyond what might be expected by the reduction in FSM, is due to changes in exam entry policy. In order to boost their apparent league table position, many schools at this time began entering students for dual and triple award qualifications (such as IT), deemed to be equivalent to GCSEs, but apparently considerably easier to pass. Academies did this as well as other schools, but were more secretive about their use of ‘pseudo’ courses, leading to calls for the Freedom of Information Act to be extended to force them to answer questions about their exam entry policies (Stewart 2010). The figures like 65% Level 2 for Greig City Academy in 2007 are likely to be based on these alternative qualifications because there is no equivalent growth of students gaining maths and English. Subsequently, using the new official Level 2 indicator including maths and English, neither Greig City nor Unity improved much despite a national growth in Level 2 from 48% in 2008 to 59% in 2011, and 67% in 2012. Bexley has done somewhat better than them, but not necessarily better than the national trend, and has anyway continued to decrease its FSM intake. Overall, there is no clear evidence from these, or from the newer Academies, that Academies have performed better than the schools they replaced would have done (Gorard 2009). Conclusion To say that struggling Academies are doing no better than their non-Academy peers or predecessors is not to denigrate them. They are doing no worse than their peers either, with equivalent pupils. Nor does it mean that good work has not been done in and by Academies. But it does demonstrate that the Programme is a waste of time and energy at least in terms of this rather narrow measure of outcomes. There is no success specific to Academies that might not also have come from straightforward increased investment in ‘failing’ schools. Of course, one can argue that the schools have been a success in maintaining numbers and reducing the proportion of disadvantaged students. And this is certainly true for two of the first three Academies, which were selected as among the most deprived schools in England. But the Programme now includes Academies that had been private or selective schools and which had been among the least deprived in their areas. So this is no longer a sensible way of assessing success for the Programme. There are also opportunity costs. The money involved since 2002 could have been used differently – spent on refurbishing the most deprived schools or used to follow the most deprived students to whichever school they attend. The same is true for all recent new school schemes in England, such as the Specialist schools, and will almost certainly be true for as yet untested schemes like Free schools, and their equivalents worldwide. 15 Academies, especially the newer Converter Academies, are strongly linked to local levels of SES segregation between schools. The risk that this poses for societal cohesion and social justice is being run for no reason. The school system in England was designed through its funding, its laws about when and how school places are allocated, regulations about teacher development, inspections, national curriculum, and standard attainment in key stages, to try and make as little difference between schools as possible. England had built a system of maintained schools that was loosely comprehensive, and funded on a per-student basis adjusted for special circumstances. The curriculum was largely similar (the National Curriculum) for ages 5 to 14 at least, taught by nationally-recognised teachers with Qualified Teacher Status, inspected by a national system (OFSTED), and assessed by standardised tests up to Key Stage 3. Education is compulsory for all, and free at the point of delivery. In a very real sense it sounds as though it would not matter much which school a student attends, in terms of qualifications as an outcome. And this is how it ought to be, in a democratic, developed country with an education system like that in England designed to promote equality of opportunity. The quality of education available in a national school system should not depend upon where a student lives or which school they attend. Therefore, new school types or schemes for only some schools are not the way forward. The poverty gap will be reduced by reducing differences between schools, opportunities and treatments, not by celebrating them. There should be no state-funded diversity of schooling. If, for example, Academies in England are really a superior form of school to the ‘bog-standard’ local comprehensives then why are only some schools made into Academies? Surely, all students are entitled to this better form of education, rather than the state wilfully continuing to provide what they claim is an inferior experience for some. In fact, it is not clear that Academies are better than other schools and so the money invested in them could have been used more fruitfully elsewhere. Again, the same could be said about most initiatives that tinker with the types of school available. For the same reason there should be no 11-16 age schools alongside 11-18 schools, or indeed any variation in age range. One of these ranges will be the better for any nation or region as a whole, and should be adopted universally. If it is argued that we do not know which is best then that means we have no reason to vary them (unless for the purposes of a genuine attempt to find out). Similarly, there should be no single-sex and co-educational schools in the same system. Again, one of these forms of schooling will be better for the region as a whole and should be adopted. It means there should be no selection by aptitude or prior attainment within a system that is also compulsory. There should be no differences between schools in terms of their faith-basis, or more simply no faith-basis at all. There should be no private investment (as opposed to welcome charitable giving to the system as a whole), and no curricular specialisms in the compulsory phase (there should be a truly National Curriculum). All young people should be included in mainstream institutions as far as possible. Controlling the school mix like this is one of the most important educational tasks for central and local governments. References Boliver, V. and Swift, A. (2011) Do comprehensive schools reduce social mobility?, British Journal of Sociology of Education, 62, 1, 89-110 Bradbury, A. (2011) Equity, ethnicity and the hidden dangers of ‘contextual’ measures of school performance, Race, Ethnicity and Education, 14, 3, 277-291 16 Burgess, S., Wilson, D. and Lupton, R. (2005) Parallel lives? Ethnic segregation in schools and neighbourhoods, Urban Studies, 42, 7, 1027-1056 Cheng, SC. and Gorard, S. (2010) Segregation by poverty in secondary schools in England 2006-2009: a research note, Journal of Education Policy, 25, 3, 415-418 Clotfelter, C. (2001) Are whites still fleeing? Racial patterns and enrolment sifts in urban public schools, Journal of Policy Analysis and Management, 20, 2, 199-221 Coleman, J., Hoffer, T. and Kilgore, S. (1982) Cognitive outcomes in public and private schools, Sociology of Education, 55, 2/3, 65-76 Dobbie, W. and Fryer, R. (2009) Are high-quality schools enough to close the achievement gap? Evidence from a social experiment in Harlem, National Bureau of Economic Research Working Paper 15473 Duncan, O., Cuzzort, R. and Duncan, B. (1961) Statistical geography: problems in analyzing area data, Glencoe IL: Free Press Felouzis, G. and Charmillot, S. (2012) School tracking and educational inequality: a comparison of 12 education systems in Switzerland, Comparative Education, 49, 2, 181-205 Gleason, P., Clark, M., Tuttle, C. and Dwoyer, E. (2010) The Evaluation of Charter School Impacts: Final Report, National Center for Education Evaluation and Regional Assistance, ED510574, 259pp Glenn, W. (2011) A quantitative analysis of the increase in public school segregation in Delaware: 1989-2006, Urban Education, 46, 4, 719-740 Goldsmith, P. (2011) Coleman revisited: School segregation, peers, and frog ponds, American Educational Research Journal, 48, 3, 508-535 Goldstein, H. (2001) Using pupil performance data for judging schools and teachers: scope and limitations, British Educational Research Journal, 27, 4, 433-442 Gorard, S. (2000) Education and Social Justice, Cardiff: University of Wales Press Gorard, S. (2005) Academies as the ‘future of schooling’: is this an evidence-based policy?, Journal of Education Policy, 20, 3, 369-377 Gorard, S. (2006) Value-added is of little value, Journal of Educational Policy, 21, 2, 233- 241 Gorard, S. (2009) What are Academies the answer to?, Journal of Education Policy, 24, 1, 1- 13 Gorard, S. (2010) Serious doubts about school effectiveness, British Educational Research Journal, 36, 5, 735-766 Gorard, S. (2012) Who is eligible for free school meals?: Characterising FSM as a measure of disadvantage in England, British Educational Research Journal, 38, 6, 1003-1017 Gorard, S. and Rees, G. (2002) Creating a learning society, Bristol: Policy Press Gorard, S. and See, BH. (2013) Overcoming disadvantage in education, London: Routledge Gorard, S. and Smith, E. (2010) Equity in Education: an international comparison of pupil perspectives, London: Palgrave Gorard, S., Hordosy, R. and See, BH. (2013a) Narrowing the determinants of segregation between schools 1996-2011, Journal of School Choice, 7, 2, 182-195 Gorard, S., Hordosy, R. and Siddiqui, N. (2013b) How stable are ‘school effects’ assessed by a value-added technique?, International Education Studies, 6, 1, 1-9 Gorard, S., Taylor, C. and Fitz, J. (2003) Schools, Markets and Choice Policies, London: RoutledgeFalmer Gray, J., Goldstein, H. and Thomas, S. (2001) Predicting the future: the role of past performance in determining trends in institutional effectiveness at A level, British Educational Research Journal, 27, 4, 39-406 17 Harris, D. and Williams, J. (2012) The association of classroom interactions, year group and social class, British Educational Research Journal, 38, 3, 373-397 Hoover, E. (1941) Interstate redistribution of population 1850-1940, Journal of Economic History, 1, 199-205 Hoyle, R. and Robinson, J. (2003) League tables and school effectiveness: a mathematical model, Proceedings of the Royal Society of London B, 270, 113-199 Kelly, S. and Monczunski, L. (2007) Overcoming the volatility in school-level gain scores: a new approach to identifying value-added with cross-sectional data, Educational Researcher, 36, 5, 279-287 Knowles, E. and Evans, H. (2012) PISA 2009: How does the social attainment gap in England compare with countries internationally?, Research Report DFE-RR206, London: DFE Logan, J., Minca, E. and Adar, S. (2012) The geography of inequality: why separate means unequal in American public schools, Sociology of Education, 85, 3, 287-301 Massey, D. and Fischer, M. (2006) The effect of childhood segregation on minority academic performance at selective colleges, Ethnic and Racial Studies, 29, 1, 1-26 McCoy, S., Banks, J. and Shevlin, M. (2012) School matters: how context influences the identification of different types of special educational needs, Irish Educational Studies, iFirst 10.1080/03323315.2012.669568 Palardy, G. (2013) High school socioeconomic segregation and student attainment, American Educational Research Journal, 50, 4, 714-754 Proud, S. (2010) Peer effects in English primary schools: an IV estimation of the effect of a more able peer group on age 11 examination results, Bristol: CMPO Working Paper 10/248 Ready, D. (2012) Associations between student achievement and student learning: implications for value-added accountability models, Educational Policy, 27, 1, 92-120 Ridgway, R. and Ridgway, J. (2011) Crimes against statistical inference, On-line Educational Research Journal, www.oerj.org Stewart, W. (2010) Call for FOI to be extended to academies as research reveals wide use of ‘pseudo’ courses, TES, 21/5/10, p.12 Tuttle, C., Teh, B-R., Nichols-Barrer, I., Gill, B. and Gleason, P. (2010) Student Characteristics and Achievement in 22 KIPP Middle Schools: Final Report: Washington, DC: Mathematica Policy Research, Inc., 116pp 
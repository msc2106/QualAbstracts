ABSTRACT: 
In 1950, Alan Turing proposed his eponymous test based on indistinguishability of verbal behavior as a replacement for the question "Can machines think?" Since then, two mutually contradictory but well-founded attitudes towards the Turing Test have arisen in the philosophical literature. On the one hand is the attitude that has become philosophical conventional wisdom, viz., that the Turing Test is hopelessly flawed as a sufficient condition for intelligence, while on the other hand is the overwhelming sense that were a machine to pass a real live full-fledged Turing Test, it would be a sign of nothing but our orneriness to deny it the attribution of intelligence. The arguments against the sufficiency of the Turing Test for determining intelligence rely on showing that some extra conditions are logically necessary for intelligence beyond the behavioral properties exhibited by an agent under a Turing Test. Therefore, it cannot follow logically from passing a Turing Test that the agent is intelligent. I argue that these extra conditions can be revealed by the Turing Test, so long as we allow a very slight weakening of the criterion from one of logical proof to one of statistical proof under weak realizability assumptions. The argument depends on the notion of interactive proof developed in theoretical computer science, along with some simple physical facts that constrain the information capacity of agents. Crucially, the weakening is so slight as to make no conceivable difference from a practical standpoint. Thus, the Gordian knot between the two opposing views of the sufficiency of the Turing Test can be cut.Engineering and Applied Science. 
 
PREDICTION: 
This paper examines two mutually contradictory but well-founded attitudes towards the Turing Test, Alan Turing's proposed replacement for the question Can machines think?‚Äù On the one hand is the attitudes that has become philosophical conventional wisdom, viz., that the Turing Test is hopelessly awed as a sucient condition for intelligence, while on the other hand is the overwhelming sense that were a machine to pass a real livefull-edged Turing Test, it would be a sign of nothing but our orneriness to denyit the attribution of intelligence. The arguments against the suciency of the Turing Test for determining intelligence rely on showing that some extra conditions are logically necessary for intelligence beyond the behavioral properties exhibited by an agent under a Turing Test. Therefore, it cannot follow logically from passing a Turing Test that the agent is intelligent. I will argue that these extra conditions can be revealed by the Turing Test, so long as we allow a very slight weakening of the criterion from one of logical proof to one of statistical proof under weak realizability assumptions. Crucially, this weakening is so slight as to make no conceivable dierence from a practiceal standpoint. Thus, the Gordian knot between the two opposing views of the suciency of the Turing Test can be cut. 
 
FULL TEXT: 
  The Turing test as interactive proof (Article begins on next page)The Harvard community has made this article openly available.Please share how this access benefits you. Your story matters.Citation Stuart M. Shieber. The Turing test as interactive proof. No√ªs,41(4):686-713, December 2007. The definitive version isavailable at www.blackwell-synergy.com.Published Version doi:10.1111/j.1468-0068.2007.00636.xAccessed February 17, 2015 12:56:48 PM ESTCitable Link http://nrs.harvard.edu/urn-3:HUL.InstRepos:2027203Terms of Use This article was downloaded from Harvard University's DASHrepository, and is made available under the terms and conditionsapplicable to Other Posted Material, as set forth athttp://nrs.harvard.edu/urn-3:HUL.InstRepos:dash.current.terms-of-use#LAAStuartM.Shieber.TheTuringtestasinteractiveproof.N^ous,41(4):686-713,December2007.[Revision1.41ofMay24,2012,17:23:35generatedMay24,2012.]THE TURING TEST AS INTERACTIVE PROOFSTUART M. SHIEBER1. IntroductionIn this paper, I attempt to reconcile two mutually contradictorybut well-founded attitudes towards the Turing Test, Alan Turing's proposedreplacement for the question \Can machines think?" On the one hand is theattitude that has become philosophical conventional wisdom, viz., that the TuringTest is hopelessly awed as a sucient condition for intelligence, while on theother hand is the overwhelming sense that were a machine to pass a real livefull-edged Turing Test, it would be a sign of nothing but our orneriness to denyit the attribution of intelligence.The arguments against the suciency of the Turing Test for determiningintelligence rely on showing that some extra conditions are logically necessary forintelligence beyond the behavioral properties exhibited by an agent under a TuringTest. Therefore, it cannot follow logically from passing a Turing Test that theagent is intelligent. I will argue that these extra conditions can be revealed bythe Turing Test, so long as we allow a very slight weakening of the criterion fromone of logical proof to one of statistical proof under weak realizability assumptions.Crucially, this weakening is so slight as to make no conceivable dierence from apractical standpoint. Thus, the Gordian knot between the two opposing views ofthe suciency of the Turing Test can be cut.1.1. The Essence of the Turing Test. The Turing Test is, at its heart, a testof the adequacy of an agent's verbal behavior. Block (1981) characterizes it as atest of the ability to \produce a sensible sequence of verbal responses to a sequenceof verbal stimuli".1 Turing's original presentation of the Test is couched in termsof an imitation game between two entities, a person and a machine, with the goalof seeing if in repeated forced choices a judge can do no better than chance atdetermining which is which on the basis of verbal interactions with each. Muchof this setup (and the preliminaries that he introduces regarding a gender-basedversion of the game) are incidental to the underlying goal, which is to determine ifa machine has human-level verbal behavior.The introduction of the human confederate and the forced choice merelyserve to make more clear and operational what constitutes \sensibility" of the1I take the term \sensible sequence of verbal responses" directly from Block to mean whatevercriterion of human indistinguishability that the judge in a Turing Test is verifying. It may bethat the term is not entirely felicitous for that purpose. For instance, there may be sequences ofresponses that are sensible in the informal sense of the term, yet reveal the non-human character ofthe generator by being stilted in some way. Under certain circumstances, even clearly nonsensicalresponses are appropriate in a Turing Test, as in Block's example of a judge requesting \Let's seeyou talk nonsense." (Block, 1981, pages 19{20) Nonetheless, for consistency hereafter I will followBlock in using the phrase, with the request that the reader interpret it in the intended manner.12 STUART M. SHIEBERmachine's responses, but there are other ways to achieve the same goal. Forinstance, the underlying idea could be implemented in a simpler form, in whicha judge merely stipulates whether or not a machine has exhibited human-levelbehavior, except that without some sort of forced choice, a gaming of the testwould be possible. Indeed, Turing presents this simpler more direct form in a littleknown 1952 BBC interview in which he describes the test as follows:The idea of the test is that the machine has to pretend to be aman, by answering questions put to it, and it will only pass ifthe pretence is reasonably convincing.... We had better supposethat each jury has to judge quite a number of times, and thatsometimes they really are dealing with a man and not a machine.That will prevent them saying \It must be a machine" every timewithout proper consideration. (Newman, Turing, Jeerson, andBraithwaite, 1952)Here, he describes the point of the Test directly in the rst sentence, and makesclear that the comparison issue (whether through repeated trials, as described inthis selection, or one-on-one, as in the original paper) is an expedient to make theforced choice a real one.Thus, at base, the Turing Test is a test based on the idea that abilityto produce sensible verbal behavior is an indication of intelligence. The syllogismthat underlies the appropriateness of the Turing Test as a criterion for intelligenceproceeds something like this:Premise 1: If an agent passes a Turing Test, then it produces a sensiblesequence of verbal responses to a sequence of verbal stimuli.Premise 2: If an agent produces a sensible sequence of verbal responses to asequence of verbal stimuli, then it is intelligent.Conclusion: Therefore, if an agent passes a Turing Test, then it is intelligent.Block refers to a premise such as the second one as the \Turing Testconception of intelligence", and his (and others') repudiation of the Turing Testas a criterion for intelligence is based on a denial of this premise.1.2. The Conceptual Basis for Turing-Test Denial. Philosophers of mindfall, roughly speaking, into two camps, the Turing-Test deniers, who think thatpassing a Turing Test cannot be used as a sucient condition for intelligence, andthe Turing-Test approvers, who think that it can. Turing-Test deniers think ofintelligence like a bad cold. It has a hidden cause, a germ. Victoria can say of herfriend Peter without sounding ridiculous things like \Oh, Peter's not really sick;he's just faking it, to get out of school." Sickness can't be cashed out in terms ofsome disposition to exhibit sickness symptoms (coughing, complaining of stomachpain, staying in bed). There has to be a germ.Turing-Test approvers, on the other hand, think of intelligence like beinguent in Italian. (In fact, they think it's exactly like being uent in Italian.) Imagineyou've been talking for an hour with Victoria's friend Pietro using perfect Italian.Now suppose Victoria were to say, \Oh, Pietro's not really uent in Italian; he'sjust faking it, to be eligible for an Italians-only scholarship." Such a statementis clearly silly. One can't exhibit the symptoms of being uent in Italian and befaking, missing some essential \germ" of uency; the symptoms are the uency.THE TURING TEST AS INTERACTIVE PROOF 3Now imagine a scenario in which Peter has been getting straight A's inschool and just got two 800's on the SAT. Victoria says \Oh, Peter's not reallyintelligent; he's just faking it to get into a good school." Intelligence in this sense(which is not, of course, the sense that the Turing Test is meant to test for) isclearly like uency in Italian, which is why the statement sounds ridiculous.Finally, imagine Victoria takes you to a Searlian \Italian room" whereyou can insert slips of paper with Italian written on them through a slot in thedoor and get back other slips of paper with perfectly uent Italian responses,sometimes clever, sometimes amusing, always insightful; the room is a brilliantconversationalist. After an hour or so of this, you're quite impressed, but Victoria,ever the spoilsport, says \Oh, that room isn't intelligent; it's just faking it." If youthink that sounds silly prima facie, you can see why the Turing-Test deniers' view isso counter-intuitive. They seem to think that one could have the symptoms withoutthe germ. Dierent philosophers diagnose this necessary causal agent dierently.Searle (1980) thinks the germ is intentionality (though Dennett (1987) objects thatSearle thinks it's consciousness); Davidson (1990) thinks it's semantics; Gunderson(1964) thinks it's exibility of behavior; Block (1981) thinks it's \richness ofinformation processing". But all (except Dennett) agree that intelligence is nottestable in purely behavioral terms.On the other hand, many nd it hard to shake the intuition thata Turing-Test-passing entity must surely be intelligent. To such Turing-Testapprovers, like Dennett (1985), no germ is necessary. \[T]he Turing test, conceivedas he conceived it, is (as he thought) plenty strong enough as a test of thinking.I defy anyone to improve upon it." This intuition is quite strong. Nonetheless,intuitions may be wrong and a little philosophy might be just the thing to lead usto accept previously counterintuitive conclusions, for instance, that sentences like\that machine is just faking intelligence" aren't ridiculous at all.1.3. The Argument Against Behaviorist Tests. In \Psychologism andBehaviorism", Block (1981) presents what I take to be the strongest argument todate of the inadequacy of the Turing Test as a criterion of intelligence. Through aseries of thought experiments, Block argues that no conception of intelligence thatrelies solely on external behavior (as manifested in Premise 2) can be sucient;some (at least minimal) internal conditions on the means by which the behavior isgenerated must be included. In particular, he faults the Turing Test for failing todemonstrate not only the fact of producing \a sensible sequence of verbal responsesto a sequence of verbal stimuli" but of a general capacity for such behavior,and further, one derived from sucient \richness of information processing"; theantecedent in Premise 2 is too weak. Because I think this is the strongest argumentagainst the Turing Test as a sucient condition of intelligence, it is the argumentthat I address in this paper. I argue that the Turing Test can in fact provide sucha demonstration, thereby vitiating Block's argument against the suciency of theTuring Test as a test of intelligence.Searle, in his \Minds, Brains, and Programs" (1980), presents a dierentargument against the Turing Test, his \Chinese room". This argument is based onan article of faith that is too woolly to argue against, namely, that no formal systemthat merely manipulates symbols could bear intelligence. But Block doesn't go that4 STUART M. SHIEBERfar,2 and indeed has argued against Searle on this point (Block, 1980). Block issaying something simpler, that it is logically possible that some thing that not onlyis merely a symbol manipulator but also is a trivial one could pass the Turing Test.Furthermore, it not only can pass the Turing Test, but has a general capacity todo so. But if Block is right, why would we be inclined to attribute intelligence toa machine that passed a Turing Test?It seems to me that Block is right in principle: Such a machine isconceptually possible; hence the Turing Test is not logically sucient as a conditionof intelligence. Let us suppose this view is correct and, as Block argues, some furthercriterion is needed regarding the manner in which the machine works. Some furthercriterion is needed, but how much of a criterion is that, and can the Turing Testtest for it? Although Block calls this further internal property `nonbehavioral', Iwill argue that the mere behavior of passing a Turing Test can reveal the property.Borrowing an idea from theoretical computer science, I argue that the Turing Testcan be viewed as an interactive proof not only of the fact of sensible verbal behavior,but of a capacity to generate sensible verbal behavior, and to do so \in the rightway". Assuming some extraordinarily weak conditions on physical realizability,any Turing-Test-passing agent must possess a sucient property to vitiate Block'sargument. In summary, Block's arguments are not sucient to negate the TuringTest as a criterion of intelligence, at least under a very slight weakening of thenotion of `criterion'.The argument I present does not demonstrate that the Turing Test issucient as a criterion for intelligence. It merely shows that Block's argumentagainst its suciency fails. However, some other argument might hold; thispossibility remains open.2. MotivationBefore I argue for the resurrection of the Turing Test as a sucientcondition of intelligence, it merits mention of why such an argument is worthundertaking in the rst place. Discussions such as the present one (and Block's)for or against the Turing Test as a denition or necessary or sucient condition for2At the end of \Psychologism and Behaviorism", Block presents claims that an agent that exhibitsintelligent behavior on the basis of exact emulation of the neurological processes of a person wouldarguably still not be intelligent.Consider a device that simulates you by using a theory of your psychologicalprocesses. It is a robot that looks and acts as you would in any stimulussituation. Instead of a brain it has a computer equipped with a description ofyour psychological mechanisms. You receive a certain input, cogitate about it,and emit a certain output. If your robot doppelganger receives that input, atransducer converts the input into a description of the input. The computeruses its description of your cognitive mechanisms to deduce the product ofyour cogitations; it then transmits a description of your output to a mechanismthat causes the robot body to execute the output. It is hardly obvious thatthe robot's process of manipulation of descriptions of your cogitation is itselfcogitation. It is still less obvious that the robot's manipulation of descriptionsof your experiential and emotional processes are themselves experiential andemotional processes.It is hard to know how this claim could be distinguished in spirit from Searle's, and Block (personalcommunication, 2002) has since stated that, though the various hedges make it possibly literallytrue, it goes too far.THE TURING TEST AS INTERACTIVE PROOF 5intelligence might be denigrated (and have been) on the grounds that Turing didn'tpropose his Test as a criterion of intelligence. Rather, Turing wanted to replace thequestion \Can machines think?" with the question \Can machines pass the TuringTest?". But philosophers just won't listen. They insist on investigating the issue ofwhether the Turing Test is a good denition of intelligence, despite Turing's besteorts to avoid denitions entirely.A few voices have kept up pressure to stop such useless bickering. \Itis a sad irony that Turing's proposal has had exactly the opposite eect on thediscussion of that which he intended," says Dennett (1985). \Alas, philosophers |amateur and professional | have instead taken Turing's proposal as the pretextfor just the sort of denitional haggling and interminable arguing about imaginarycounterexamples he was hoping to squelch." Chomsky's view is that \Turing'ssensible admonitions should also be borne in mind, more seriously than theysometimes have been, in my opinion." (Chomsky, 2004)But how can we know that Turing's test is an adequate replacement for thequestion \Can machines think?" if we can't compare the results of the Test with thecorresponding answers to the question? I could request replacing the question \Canmachines think?" with a test of their ability to perform arbitrary precision squareroots, but one would be within rights to note that this is not a useful replacement.As Moor (1976, page 250) points out, \if Turing intends that the question of thesuccess of the machine at the imitation game replace the question about machinesthinking, then it is dicult to understand how we are to judge the propriety andadequacy of the replacement if the question being replaced is too meaningless todeserve discussion. Our potential interest in the imitation game is aroused not bythe fact that a computer might learn to play yet another game, but that in someway this test reveals a connection between possible computer activities and ourordinary concept of human thinking." Thus, philosophers have been inexorably ledto the question of the relationship between a machine's passing of the test and itsthinking capacity.Turing nds himself sliding down the slippery slope from replacement todenition for just this reason. \We cannot altogether abandon the original form ofthe problem, for opinions will dier as to the appropriateness of the substitutionand we must at least listen to what has been said in this connection" (Turing, 1950).He discusses, for instance, whether the test should be thought of as a necessary orsucient condition for attributing intelligence, nding for the latter only.I therefore take seriously the issue as to whether passing a Turing Testis a sucient criterion for intelligence. (The arguments against the Turing Testas a necessary condition, and therefore as a denition, of intelligence are simple,clear, uncontroversial, and need not be restated. The views of French (1990) areparticularly trenchant on the matter.) In the next section, I rehearse conventionalphilosophical wisdom on the matter (Dennett notwithstanding).3. Turing Test Conceptions of IntelligenceWhether one thinks that the Turing Test is a sucient condition forintelligence or not depends in large part on one's interpretation of particularaspects of the role of the Turing Test in the stating of the condition. In Block'sphraseology, it depends on the \Turing Test conception of intelligence" that onehas in mind. Block takes the upshot of passing a Turing Test as demonstrating6 STUART M. SHIEBERthat the subject-under-test can \produce a sensible sequence of verbal responsesto a sequence of verbal stimuli". The Turing Test conception of intelligence thusprovides the connection between such production and the possession of intelligence.In its most direct form, the relation is expressed as in Premise 2 above, repeatedhere under the name \the occasional conception of intelligence".3The occasional conception: If an agent produces a sensiblesequence of verbal responses to a sequence of verbal stimuli, thenit is intelligent.This conception, together with Premise 1 | which asserts that passing a TuringTest demonstrates the antecedent | allows the conclusion that the agent isintelligent.It is simple to argue that this conception (admittedly a straw man, as noone to my knowledge, including Turing, has ever claimed it) is awed. Imaginea machine that responds to the interrogator's queries by emitting a randomsequence of keystrokes. (The idea is conventionally implemented using monkeysand typewriters.) There is some (admittedly astronomically small) probabilitythat these keystrokes will fortuitously spell out perfectly plausible responses to thequeries, and the interrogator would therefore be fooled into confusing the randomkeystroke generator with a human. If one holds the stance that the random typingresponses were not true intelligent behavior (and why would they be?), then themere possibility of such an occurrence, by itself, demonstrates that passing theTuring test is not a sucient condition for intelligent behavior, at least under theoccasional conception.Of course, even Turing admitted as much. He thought of the test as havinga statistical component, requiring more than a single occasion of passing. This isclear from his 1952 interview, quoted above. His statements about passing the Testwere statistical too, as in his famous prediction that \an average interrogator willnot have more than 70 per cent. chance of making the right identication after veminutes of questioning" (Turing, 1950).But subjecting the monkeys to multiple Tests, or longer ones, doesn't solvethis problem; it merely adjusts the odds of a false positive. Instead, what is neededis a change in the conception of intelligence, along the lines that Block argues for in\Psychologism and Behaviorism". I skip ahead to his \neo-Turing-Test conceptionof intelligence", which I will callThe capacity conception: If an agent has the capacity toproduce a sensible sequence of verbal responses to a sequence ofverbal stimuli, whatever they may be, then it is intelligent.Arguably, this revised conception already gives up on a purely behavioristview. How could one know that an agent has a (counterfactual) capacity withoutresort to analysis of its internal workings, that is, to a theory of its behavior, rather3The conceptions highlighted here correspond roughly to Block's \operationalist proposal",\neo-Turing Test conception", and \amended neo-Turing Test conception", respectively, exceptthat crucially they are phrased as conditionals to better accord with the view of the Test asan ostensible sucient condition, not an ostensible denition. In particular, Block states hisconceptions in the form of denitions, e.g., \Intelligence (or more accurately, conversationalintelligence) is the capacity to produce a sensible sequence of verbal responses to a sequenceof verbal stimuli, whatever they may be." Compare this to my capacity conception below.THE TURING TEST AS INTERACTIVE PROOF 7than a mere sample of it? In particular, how could the fact of passing one or moreTuring Tests allow one to conclude the antecedent of this conception?I will pay this promissory note later. But Block is willing to grant capacitiesto the Turing-Test approvers anyway, ex hypothesi, because he has an argumenteven against this conception.Imagine (with Block) a hypothetical machine that stores a tree ofinteractions providing a sensible response for each possible interrogator's input ineach possible conversational context of up to, say, one hour long. (These responsesmight be modeled on those that Block's ctional Aunt Bertha would have given.)Such a tree would undeniably be large, but processing in it would be conceptuallystraightforward. By hypothesis, such an \Aunt Bertha machine" would pass aTuring Test of up to one hour, because its responses would be indistinguishablefrom that of Aunt Bertha, whose responses it recorded. Such a machine is clearlynot intelligent, by the same token that the teletype that the interrogator interactswith in conversation with the human confederate in a Turing Test is not intelligent;it is merely the conduit for some other person's intelligence, the human confederate.Similarly, the Aunt Bertha machine is merely the conduit for the intelligence of AuntBertha. Yet just as surely, it can pass a Turing Test, and more, has the capacityto pass arbitrary Turing Tests of up to an hour. The mere logical possibility of anAunt Bertha machine is sucient to undermine the capacity conception.4Block pursues a number of potential objections to his argument that thecapacity conception is awed, the most signicant of which (his Objection 8) isbased on the fact that the Aunt Bertha machine is exponentially large, that is, itssize is exponential in the length of the conversation.Objection 8 leads to his \amended neo-Turing-Test conception":\Intelligence is the capacity to emit sensible sequences of responses to stimuli, solong as this is accomplished in a way that averts exponential explosion of search."(Emphasis in original.) It is not exactly clear what \exponential explosion ofsearch" is intended to indicate in general. In the case of the Aunt Bertha Machine,exponentiality surfaces in the size of the machine, not the time complexity ofthe search. Further, the aspect of the Aunt Bertha machine that conicts withour intuitions about intelligence is its reliance upon memorization. Removing thepossibility of exponential storage amounts to a prohibition against memorization.5Consequently, an appropriate rephrasing of this conception isThe compact conception: If an agent has the capacity toproduce a sensible sequence of verbal responses to a sequenceof verbal stimuli, whatever they may be, and without requiringstorage exponential in the length of the sequence, then the agent isintelligent.Again, Block notes that this additional condition is psychologistic in mentioninga nonbehavioral condition, viz., that the manner of the processing must avert4This anti-behaviorist argument was apparently rst proposed in sketch form by Shannon andMcCarthy (1956, page vi): \A disadvantage of the Turing denition of thinking is that it ispossible, in principle, to design a machine with a complete set of arbitrarily chosen responsesto all possible input stimuli.... With a suitable dictionary such a machine would surely satisfyTuring's denition but does not reect our usual intuitive concept of thinking."5For this reason, adding this extra condition to the conception of intelligence is not ad hoc. Itamounts to saying, in a precise way, that the agent must have the capacity to produce sensibleresponses without having memorized them.8 STUART M. SHIEBERcombinatorial explosion of storage. He claims that insofar as the condition ispsychologistic, a Turing Test cannot test for it.To summarize, Block's Aunt Bertha argument forces us to pay up ontwo promissory notes. For the purely behavioral Turing Test to demonstrateintelligence, it must suce as a demonstration of the antecedent of the compactconception of intelligence, that is, it must indicate a general capacity to producea sensible sequence of verbal responses and it must demonstrate compactness ofstorage of the agent. It requires us to demonstrate a basis for an alternative toPremise 1:Premise 10: If an agent passes a Turing Test, then it has the capacity toproduce a sensible sequence of verbal responses to a sequence of verbalstimuli, whatever they may be, and without requiring storage exponentialin the length of the sequence.To invalidate Block's argument, then, it is sucient to provide a basis for the new,stronger, view of the Turing Test codied in Premise 10.4. The Deductive, Inductive, and Abductive Basisfor the Turing TestOne potential way of salvaging the Turing Test is to change the notion of\demonstrate" in the claim that passing a Turing Test demonstrates intelligence.For instance, James Moor's view (1976) is that Turing Tests should be viewed notas deductive proofs of intelligence (as Block would have it), but as \a source ofgood inductive evidence".He calls the evidence inductive evidence, but what kind of induction could aTuring Test be evidence for? Induction, in one guise at least, is the form of reasoningfrom instances of a universal to the universal. The instances we see in a TuringTest are the agent \producing a sensible sequence of verbal responses to a sequenceof verbal stimuli" as Block would say. The natural inductive conclusion to drawfrom such data is that the agent has the \capacity to produce a sensible sequenceof verbal responses to arbitrary sequences of verbal stimuli". Moor's inductiveevidence is evidence for the antecedent in the capacity conception of intelligence.Already, we see that by relaxing our notion of demonstration, we can make someheadway on the path from Premise 1 to 10.Nonetheless, the Test is only inductive evidence for the consequent if thecapacity conception is sound. Thus, if Block is right, and the capacity conceptionfails, so does the inductive evidence reconstruction.But what Moor is getting at goes beyond the inductive view of the TuringTest, and is made clearer by Stalker's reply (1978) and Moor's response (1978).Stalker refers to the evidence not as inductive evidence, but as explanatory evidence.More properly, though Stalker doesn't use the terminology, it appeals to reasoningby abduction, that is, reasoning to the best explanation.We can caricature the types of reasoning as follows: Deduction is reasoningfrom P and P ! Q to Q; induction is reasoning from (repeated instances of) Pand Q to P ! Q; abduction is reasoning from P and Q ! P to Q.6 Of course, suchabductive reasoning is deductively unsound, and is appropriately limited to special6Hobbs, Stickel, Martin, and Edwards (1988) present a similar symmetrical view of the three typesof reasoning.THE TURING TEST AS INTERACTIVE PROOF 9cases where Q ! P holds because Q is a cause of P, and if there are multiple Qisuch that Qi ! P, we select the Qi that serves as the \best" explanation as causeof P. (What \best" means is a tricky issue, of course; it is where all the action isin formalizing abductive reasoning.)In the case at hand, we take P to be the passing of the Turing Test and Qto be the bearing of intelligence. Abduction then allows us to reason from an agentpassing the Turing Test, along with the view that intelligence (at least of a certainsort) implies the ability to pass the Turing Test, to the conclusion that the agentis intelligent.Stalker points out that abductive reasoning requires an argument that theparticular Q ! P that one chooses must be the best explanation, not just any one,and he thinks he has a better one, namely, that the machine is merely followinga particular computational procedure. Moor's reply amounts to arguing that theintelligence view is, as an abductive explanation, just as good, if not better.Abductive reasoning in general has the following problem: The explanationthat is best may still be wrong. Moor implies as much when he talks about thepossibility that new evidence can cause one to change one's conclusions. So themove to viewing the Turing Test as abductive evidence of intelligence probablywon't satisfy those (like Searle) who believe themselves in possession of a prioriarguments against the possibility of mechanical intelligence. No matter how much\evidence" of this sort accumulates, the deductive conclusion from the premise\machines can't think" will trump the abductive evidence to the contrary.It may also not satisfy Block, as it is hard to see how to rate the relativequality of the explanation \the machine is intelligent" and \the machine is lookingup the replies in a table" without begging the question.Nonetheless, the attempt to salvage the Turing Test as a test for intelligenceby changing the kind of demonstration that we take it to be is a promising one. Inthe next section, I argue that the Turing Test can serve as a proof of the antecedentin the compact conception, and therefore a sucient condition for intelligence,under a notion of proof that is very slightly weakened. By going from a requirementof deductive proof to that of interactive proof, and adding a weak condition ofphysical realizability, we can resurrect the Turing Test as a criterion of intelligence.5. The Interactive Proof AlternativeTo review, there are two psychologistic promissory notes out in the compactconception of the Turing Test. First, we must ascertain a general capacity to passthe test. Second, the manner of passing must satisfy a compactness limitation. Iwill pay the capacity promissory note rst, and then turn to the compactness issue.Certainly, there is no deductive move that allows one to go from observationof the passing of one or more Turing Tests to a conclusion of a general capacity;the monkeys and typewriters argument shows that. This is the Humean problemof induction. But it does not follow that there is no method of reasoning fromthe former to the latter. I will argue that the powerful notion of an interactiveproof, taken from theoretical computer science, is exactly such a reasoning method.Furthermore, as I will show in Section 6, Turing Tests bear some of the tell-tale signsof interactive proofs that have been investigated in the computer science literature.Although interactive proof is a mathematical notion, the argument I willprovide is not a formal one. I do not propose that the Turing Test is an interactive10 STUART M. SHIEBERproof in the mathematical sense, but rather, that interactive proofs provide theright metaphor or analogy for thinking about what Turing Tests provide.7Interactive proofs are protocols designed to convince a verierconventionally denoted V that a prover P has certain knowledge or abilities, whichwe will think of as being encapsulated in an assertion s.8 In a classical (deductive)proof system, P would merely reveal a deductive proof of s, which V then veries.This provides V with knowledge of s and perhaps other knowledge implicit inthe proof. Interactive proofs augment classical proof systems by adding notionsof randomization and interaction between prover and verier. (The interactionimplicit in classical proof systems | P's presenting V with the proof | isessentially trivial.) Interaction is added by allowing V and P to engage in roundsof message-passing. Randomization is introduced in two ways: First, the veriermay make use of random bits in constructing her messages. Second, she may berequired to be satised with a probabilistic notion of proof. When we state thatP proves s with an interactive proof, we mean (implicitly) that s has been provedbut with a certain determinable residual probability of error. That is, the veriermay need to be satised with some small and quantiable chance that the protocolindicates that s is true when in fact it is not, or vice versa. The residual error isthe reason that moving to a notion of interactive proofs is a weakening relative toa view as a deductive proof. The fact that the residual error can rapidly be madevanishingly small through repeated protocols is the reason that the weakening isreferred to as \very slight".9The idea of interactive proofs has been absolutely revolutionary incomputer science since their introduction by Goldwasser, Micali, and Racko(1985). It has had two major payos. First, there are ecient interactive proofsof assertions for which classical proofs are hopelessly inecient. Second, there areinteractive proofs of theorems that reveal to V much less knowledge about s; inthe case of so-called zero-knowledge proofs, they reveal nothing but the fact of theassertion's truth.The idea is perhaps best grasped through an example, a variation onthe Graph Nonisomorphism interactive proof system of Goldreich, Micali, andWigderson (1991). A graph is a mathematical object consisting of a set of nodes7In independent work, Bradford and Wollowski (1994) do attempt to provide a mathematicalargument relating interactive proofs and the Turing Test, but of a quite dierent avor.For instance, they assume that the subject-under-test is polynomially bounded, and take thesubject-under-test and confederate to be the veriers, and the judge to be the prover. It is safeto say that the upshot of their analysis is unclear given the strong assumptions that they make.8The roles of verier and prover are analogous to those of Victoria and Peter/Pietro above. Forconvenience in reference, we will therefore refer to them using gendered pronouns \her" and \him"respectively.9The probabilistic nature of interactive proof conclusions constitutes a very important distinctionbetween interactive proofs and general inductive evidence (as appealed to by Moor). Inductivearguments may, like interactive proofs, be thought of as statistically founded, but they end in astep of acceptance of the general conclusion of which the instances form the inductive evidence.(We select many marbles from a jar and note that all are red. Statistics and independenceassumptions allow us to compute a probability distribution over proportions of red marbles inthe jar, with 100 percent being the most likely. By inductive acceptance, we conclude thatall of the marbles in the jar are red.) Pollock (1990, Chapter 5) reviews problems with thestatistical foundations of induction, and in particular, the acceptance step. But by virtue ofyielding probabilistic conclusions, interactive proofs have no acceptance step, and thus do not fallprey to these problems.THE TURING TEST AS INTERACTIVE PROOF 11(a) (b) (c)12 3 45123 45Figure 1. Example graphsand a set of edges connecting some of them. Two graphs are isomorphic if thereis a one-to-one mapping from the nodes of one to the nodes of the other such thatthere is an edge between a pair of nodes in the one if and only if there is an edgebetween the pair of nodes in the other that they map to. Figure 1 presents agraphical depiction of some graphs. Although all have the same number of verticesand edges, only graphs (a) and (b) are isomorphic, under a mapping of the verticesgiven by the node numberings in the gure. Neither is isomorphic to (c). Thisis easily seen, as (c) has a minimal cycle (that is, a set of vertices connected in acycle no subset of which forms a cycle) of four vertices, while neither (a) nor (b)do. In the general case, determining that two graphs are nonisomorphic is not sostraightforward. It is important for the purposes of this example to understandthat (given current assumptions in the foundations of computational complexity)the time required to determine if two graphs are isomorphic is exponential in thenumber of nodes in each graph, that is to say, the problem is very dicult.Suppose P claims to know that the following assertion s is true:Graphs G0 and G1 are not isomorphic.V wants to be convinced of this. We can imagine that the graphs G0 and G1 arequite large, say thousands of nodes. It would thus be impractical for V to determineby direct computation the truth of s.10The following interactive proof protocol achieves this goal.(1) V selects one of the two graphs G0 or G1 at random by choosing a randombit b, a 0 or 1; the selected graph is then Gb, the unselected graph G1
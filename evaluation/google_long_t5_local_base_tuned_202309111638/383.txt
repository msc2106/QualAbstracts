ABSTRACT: 
The problem of obtaining designs that result in the greatest precision of the parameter estimates is encountered in at least two situations in which item response theory (IRT) models are used. In so-called two-stage testing procedures, certain designs may be specified that match difficulty levels of test items with abilities of examinees. The advantage of such designs is that the variance of the estimated parameters can be controlled. In situations in which IRT models are applied to different groups, efficient multiple-matrix sampling designs are applicable. The choice of matrix sampling designs will also influence the variance of the estimated parameters. Heuristic arguments are given here to formulate the efficiency of a design in terms of an asymptotic generalized variance criterion, and a comparison is made of the efficiencies of several designs. It is shown that some designs may be found to be most efficient for the one- and two- parameter model, but not necessarily for the three-parameter model. Index terms: efficiency, generalized variance, item response theory, optimal design. 
 
PREDICTION: 
This article considers the efficiency of designs in the first-, Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227.99.1080.00.00. The results of this comparison are relevant to constructors of item banks who need to estimate the item parameters efficient. The use of information in IRT models is discussed first, however, and heuristic arguments are given to propose the generalized variance criterion. The results of this comparison are relevant to constructors of item banks who need to estimate the item parameters efficient. The use of information in IRT models is discussed first, however, and heuristic arguments are given to propose the generalized variance criterion. 
 
FULL TEXT: 
  parameter model. Index terms: efficiency, general- ized variance, item response theory, optimal design. The notion of information about parameters in item response theory (IRT) models has led to several applications. In test construction and item selection, for example, Theunissen (1985), van der Linden (1987), and van der Linden and Boekkooi-Timminga (1989) used the information about ability (0) parameters to obtain optimal item selection procedures and test designs. Samejima (1977) demonstrated how information as a function of 0 can be used in tailored/adaptive testing. Lord (1974), Lord and Wingersky (1985), and Thissen and Wainer (1982), among others, used the asymptotic standard er- rors obtained from the inverse of the information on the parameters to compare the relative efficien- cy of tests, models, and designs. Vale (1986) applied sampling designs to minimize equating errors. Lord (1980) and Hambleton and Swaminathan (1985) described applications of information as a func- tion of the IRT parameters in various fields of measurement. Lord (1962) investigated precision of the estimation of population means for an item domain and demonstrated that for a fixed number of item-person confrontations, the mean performance of a population for an item domain is estimated most reliably when each item is taken by a different sam- ple of persons. A similar result was obtained empirically by Pandey and Carlson (1976). Although this result has been used to stress the importance of multiple-matrix sampling designs, the question still remains whether these designs are also efficient to estimate IRT parameters. As the sampling concept from survey analysis gained currency in educational measurement, the interest in alternative sampling designs increased. In large-scale assessment studies, it would save con- siderable classroom administration time if only a subset of items instead of a whole test is administered to the examinees. Whether such a selection of items would influence the efficiency of the item parameter estimates will depend on the assumed IRT model. The efficiency of designs is considered here in terms of a generalized variance criterion connected with IRT parameters, and this criterion is used to compare the efficiencies of designs for the one-, Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 294 two- and three-parameter models. The results of this comparison are relevant to constructors of item banks who need to estimate the item parameters efficiently. The use of information in IRT models is discussed first, however, and heuristic arguments are given to propose the generalized variance criterion. Information in IRT Models The notion of information in any statistical model is connected with the estimation of unknown parameters. The amount of information is defined (Kendall & Stuart, 1973, p. 10) as where ln(L) is the log of the likelihood function L of a parameter 0, E is the expected value, and a is the partial derivative sign. The information about the parameters in IRT models is defined similarly. For example, consider the three-parameter logistic model, which gives the probability of a correct response to item i (i = 1, ... , n) as a function of the Oj E (-~, + 00) for examinee j ( j = 1, ... , N): where bi E (-00, + oo) and a; E (0, + oo) are the item difficulty and discrimination parameters, respec- tively, and c; E (0,1) is the guessing parameter. If consistency holds when all the parameters are estimated simultaneously and when the number of examinees and the number of items becomes large simultaneously, then it would be reasonable to represent the information by To avoid indeterminacy of the model, two parameters must be fixed (i.e., m = 3n + l~l - 2). The likelihood is L and ~ = (çp) = (,.,9), where and Lord and Wingersky (1985) suggested gathering the information in the response data about the m parameters in the following partitioned matrix: Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 295 The 3n x 3n superdiagonal matrix I contains the 3 x 3 item information matrices 1, through In for n different items for the parameters c~;, b;, and ci, respectively. Note that the off-diagonal elements of I are 0, although the estimated covariances among estimated item parameters for different items may not be. The {lV - 2) x (IV - 2) diagonal matrix J contains Fisher’s information J, through IN-2 2 for Oj, and K;~ is the 3 x 1 joint Fisher information vector for item i and person j. Thus the infor- mation in the data for the simultaneous estimation of the m parameters of the three-parameter logistic model are stored in the information matrix Inf,, and the asymptotic variances and covariances of the m estimated parameters can be obtained from Cov(~) = Inf3’. The three-parameter model in Equation 2 will reduce to a two-parameter model if it is known that c; = 0, and it will reduce to a one-parameter model if it is known that a; = 1 and ci = 0. However, a distinction should be made between a model with parameters having certain values and the information on these parameters needed for joint estimation. For example, if it is known that c, = 0, c; does not have to be estimated from a sample. Equation 2 will not only reduce to a two- parameter model, but the information on c¡ and the joint information of c; with the other parameters will not be needed. In addition, will reduce to the information matrix Ia~f2 for the two-parameter model. If it is not known that c; = 0, however, c; will have to be estimated jointly with the other parameters, and all information in Inf3 will be needed. It should also be noted that the information matrices Inf, and for the one- and two-parameter logistic model can be obtained from Inf3 by deleting the appropriate rows and columns of I and the corresponding rows of K, and by adding a column to K and a diagonal element to J corresponding to examinee I~T - 1 for Inf,. Two Different Approaches to Estimating Standard Errors Two approaches have been employed to obtain the asymptotic standard errors of the estimated item parameters under the assumption that the examinees are not randomly sampled from a certain population. The difference between these two approaches is that the first approach (de Gruijter, 1984; Thissen & Wainer, 1982) assumes 8j to be known, whereas the second approach (de Gruijter, 1985, 1988; Lord & Wingersky, 1985; Wingersky & Lord, 1985) does not assume that Os are known, but rather that they have to be estimated. It is argued here that the approach that assumes 8; to be unknown is in fact implemented by using the information on the item parameters corrected for the joint infor- mation with the Os. The first approach uses the fact that the maximum likelihood estimator A, of the triplet fl¡ = (a;, bi, ci) is asymptotically normally distributed with covariance matrix Cov(t1¡) (Kendall & Stuart, 1973, p. 59), which can be obtained from the inverse of the information matrix: Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 296 The elements of the 3 x 3 information matrices II through In can be obtained from Lord (1980, p. 191), and the standard errors of the estimated parameters can be obtained from the diagonal elements of Coval) = I-’. The second approach is based on the full information matrix Inf, (or Inf, and Infz for the one- and two-parameter models, respectively), and assumes that the N 8j parameters are unknown and must be estimated jointly with the item parameters. The covariance matrix of the estimated item parameters is now denoted by Cov*(Ji) and is obtained from the leading 3n x 3n matrix of Inf3 ’ (or the leading n x n matrix of Infj ’, or the leading 2n x 2n matrix of Inf~’). The asymptotic stan- dard errors of the estimated parameters are obtained from the diagonal elements of Cov*(~). The asymptotic standard errors from these two approaches are not equal. See McLaughlin and Drasgow (1987) for a comparison of these standard errors. The difference between the two approaches is explained below in terms of information and &dquo;par- tial&dquo; information. It is demonstrated how these quantities can be computed for any non-singular transformation of the parameters in an IRT model. Information and &dquo;Partial&dquo; Information A general result on partitioned matrices is given below that demonstrates that the use of the diagonal elements of Cov*(~) is in fact based on the information on the item parameters corrected for the joint information with the 0 parameters. Let H be an m x m non-singular transformation matrix that is partitioned as H = ( H,). The m x p matrix HI and the m x (m - p) matrix ~Iz are of ranks p < m and (m - p), respectively. The information matrix Inf, of m parameters can be transformed into a partitioned matrix containing information on two different sets of transformed parameters: Let T be a p x m matrix, such that TH = (IdO). Id is an identity matrix and 0 is a zero matrix. The columns of I~, form the basis of the vector space spanned by the rows of T, and Hz is a so- called deficiency matrix. If the information matrix Inf, is symmetric and positive definite, the following equality holds (Lemma 1 of Khatri, 1966, p. 76-77): From Equation 9, the &dquo;partial&dquo; information on the first set of transformed parameters can be ob- tained, given the information on the second set of transformed parameters. Pre- and post- multipli- cation of both sides of Equation 9 by H,’Inf, and Iof3&dquo;&dquo; respectively, and rearrangement of terms yields Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 297 This equation holds for different sampling designs and different parameterizations of the model. If different restrictions are used to take care of the indeterminacy of the model, for example, matrix H will contain the corresponding contrasts. De Gruijter (1988) uses such contrasts. Although H and T may be chosen arbitrarily, as long as the condition TH = ] Id0 is satisfied, a very simple choice for H and T is This choice gives the same partitioning of Inf, as given in Equation 6, and Equation 10 reduces to This equation is comparable with Equations 8 and 14 from de Gruijter (1988) for the one- and two- parameter models, respectively. Equations 10 and 12 indicate that when considering only the standard errors of the item parameters taken from the diagonal elements of Cov*(~) (which is the 3n x 3n leading matrix of the inverse of the full information matrix Inf3), the inverse of the &dquo;partial&dquo; information on the item parameters corrected for their joint information with the 0 parameters is in fact being used. To simplify nota- tion, the matrix H is dropped from the equations below. An Optimality Criterion for Efficiency It is clear from the above that there is nothing incorrect in using only the diagonal elements of the matrix Cov*(~) as an indication of efficiency. Because the covariances of the estimated item parameters of an IRT model are not zero, however, it is preferable to use one of the criteria common in optimal design research that takes into account both the variances and covariances of the estimated item parameters and the estimation of the 0 parameters. Let the item parameters be of primary interest. The normal probability density of the estimator of the item parameters (Graybill, 1969) is then given by: where Cov*(~) is the leading 3n x 3n matrix of Cov(4) [for the one- and two-parameter models the matrix Cov*(iJ,) will be of order n x n and 2n x 2n, respectively]. Shannon (1948) proposed the following measure of uncertainty about the parameters, which is related to information theory and is associated with the probability density: Substitution of Equation 13 into 14 yields I . Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 298 Thus, apart from the constant terms 1/2 and 3n[ln(2~) + 1]/2, the In I Cov*(ii) reflects the amount of uncertainty about the parameters. Minimizing this function is equivalent to minimizing ICov*(J1) I. - The criterion-the determinant of the covariance matrix of the estimated parameters-is often referred to as the generalized variance (Anderson, 1984) or the D-optimality criterion. It must be emphasized that the question of efficient estimation of IRT parameters is more difficult than the efficient estimation of parameters in linear models. The main difficulty with IRT models is that the efficiency measure I Cov*(,î) depends on the value of the unknown parameters, because the information matrix depends on these values. The values of the parameters to be estimated must be known before selecting an efficient design. To circumvent this difficulty, the criterion used in the next section is defined at the level of a parameter set ~, for an item i, and it is ICov*(JiJI, where Cov*(J1¡} is a main diagonal matrix of Cov*(~). This makes it possible to express the criterion as a function of combinations of parameter values. Berger and van der Linden (1991) provide a review of other procedures to overcome this difficulty. Although 1 Cov*(¡1¡} takes into account both the variances and covariances of estimated item parameters and assumes unknown 8s, it does not ac- count for the covariances of estimated item parameters among the n items. Finally, even though the generalized variance is a reasonable criterion to consider when dealing with the efficiency of a set of parameters, this criterion is model dependent. For example, if a design is investigated under the assumption that a model with m parameters is correct, but a model with rn -~ 1 parameters is in fact more appropriate, then it is impossible to compare the efficiencies of these two models with this criterion. Comparison of Designs Suppose that an instructional program is designed to teach a number of skills to a population of examinees who can be grouped according to their ability to master a certain skill. Suppose also that there is an item domain containing a set of items that can be used to assess mastery of each individual skill, and that these items can be ranked according to their difficulties. It will generally be possible, for example, to make a distinction between examinees with high and low ability in solv- ing certain mathematical problems. It is also generally possible to group the items of an arithmetic test in a design based on difficulty. A design might consist of administering the easy portion of the test to examinees with low ability, and the difficult portion to examinees with high ability. The efficiency of this design can be compared with another design in which all examinees take the entire test. A design D(g) can be characterized by the sampling procedure used to select examinees from a population and by the selection of items from an item domain. The items for the one-, two-, and three-parameter models are characterized by the parameter set gi = ( b; } , gi = { a;,b; } , and J.l¡ = ( c~;,b;,c; } , respectively. The relative efficiency of a particular design 172(~) compared to another design 1~,(~)-both of which are used to estimate the same parameter set ~;-can be defined as where I Covi(rlJ and ICov2*(fti)l are the generalized variances of the estimated parameters for an item i in I~1(~) and D2Üt), respectively. If the relative efficiency is less than 1, the parameters of item i in Design I32(~) are estimated less efficiently than in Design D,(~)y if the relative efficiency is Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 299 greater than 1, the item parameters in DZ(~.) are estimated more efficiently than in Di(p). It is well known that the information on bi for c; = 0 is For fixed values of ca;, this information will be maximal when P,. (&reg;;) = .5 (i.e., when 8j = b;). Thus, a sample of examinees with abilities equal to the item difficulty (i.e., with a standard deviation of abilities SD, = 0) will give optimal information only when the difficulty parameter bi is estimated (van der Linden, 1988). This will not generally hold true for the two- and three-parameter models, however, where a; and c; are also estimated. The relative efficiency measure in Equation 16 is used below to display the effect of the standard deviation of 0 on the efficiency of the item parameters for the three IRT models. Effect of Standard Deviation of 0 on Information The relative efficiencies for the one-, two-, and three-parameter models are given in Figure 1 as a function of SD,. (To restrict the range of the actual plotted values, the square roots of the relative efficiencies are displayed in the figures.) These relative efficiencies were computed for one item at a time with the following combinations of parameter values: b, = 0; c; = 0; and a¡ = .5, 1.0, 1.5, and 2.0. Several designs were considered, with each design based on a sample of N = 1,000 normally distributed 8s-all with the same mean 0, M~ = bi = 0, but with different SD,s ranging from .1 to 2.0. Thus the only difference between these designs was their different sDes. This made it possible to display the relationship between SD, and the efficiency of the item parameters. The relative effi- ciencies were computed directly from the parameters by using Equation 16 and by comparing the I Cov*(Ø-¡) for each of these designs to the ~Cov*(~;)~ for Design ~3,(~.) with M, = 0 and SD, = 2. Cov*(Ø-¡} was a scalar for the one-parameter model, and Cov*(~;) was a matrix of orders 2 x 2 and 3 x 3, respectively, for the two- and three-parameter models. As expected for the one-parameter model, decreasing the values of SD, will result in an increase in efficiency. For the two-parameter model, however, a decrease in SD, will not always lead to an in- crease in efficiency. For this model, the relative efficiency increases first, and eventually decreases as the sDe becomes smaller. This effect can be explained by the fact that the variance of the estimated discrimination parameter generally increases as SD, becomes smaller. Thus, the increas- ing variance of the discrimination parameter will dominate the outcome of the generalized variance as SD, becomes smaller. Note that a similar effect is also found in regression analysis, where the variance of the estimated slope is inversely related to the variance of the independent variable. The pattern of relative efficiencies for the three-parameter model is the reverse of the pattern noted for the one-parameter model, and it differs from the pattern for the two-parameter model. It should be noted that, for the three-parameter model, the information on c; and the joint information of c; with the other two parameters is taken into account. For items of easy and average difficulty, the information on c; is relatively small, but the joint information of c; and bi is relatively large, whereas the information on c; is relatively large for difficult items. This causes the variances and covariances in the 3 x 3 matrix Cov*(ii¡} to differ from the corresponding variances and covariances in the 2 x 2 matrix Cov*(JÎ¡) for the two-parameter model. Thissen and Wainer (1982) offer a further explana- tion for the differences in variance of the estimated parameters for the two- and three-parameter models. The most efficient design for the three-parameter model is one in which the 8s have a relatively large standard deviation. The relative efficiencies in Figure 1 suggest that efficiency will be gained by sampling examinees from subpopulations with relatively small differences in 0 among examinees for the one- and two- Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 300 1=~ N 2 s 2 ~ c~ M aN -4 ~: w sj§ , *°~ #l U7 a,, ~zvm I.- 0 ~ c u .5 s ill a) ’? ~g~ Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 301 parameter models. For a test of items with difficulties b; ranging from -3 to + 3, for example, it ap- pears to be more efficient to select a design with different samples of examinees with relatively small sDes and then administer items to each of these samples such that the item difficulties are approx- imately equal to the Os. This is in contrast to selecting a design in which items with b; in the same range are administered to one sample of examinees with a large SD,. The comparison of designs below was made to investigate this conjecture. Alternative Sampling esigns with It&reg;u~l~ly atched Os and Item Difficulties Method. A limited comparison of designs was analyzed to illustrate the application of the pro- posed efficiency measure. Five designs are diagrammed in Figure 2 for a fixed number of examinee- item combinations (~l x n). It was assumed that the Os were uniformly distributed with a certain mean and range. The test consisted of n = 7 items, even though different groups took different items, as explained below. The computations were performed for all items having the same ca; value. This procedure was repeated for a; values of .5, 1.0, 1.5, and 2.0. It was assumed that c; = 0 for the three- parameter model. In addition, the efficiency measure given by Equation 16 was directly computed using item and 0 parameter values. Results can differ when the relative efficiency measure is based on estimated item and 0 parameters. Depending on the range of the 0 scale employed, some items can be used as anchors for the actual estimation and scaling of item parameters. 1. Design ~,~~): This design consisted of one sample of N = 1,000 examinees from a uniformly distributed population of Os ranging from -3 to + 3, taking a test of n = 7 items with equally spaced difficulty parameters bi ranging from -3 to -I- 3. The total number of examinee-item com- binations for this design and the four designs described below was approximately N x n = 7,000. 2. Design I~Z~p~): This design consisted of one group of 700 examinees with Os ranging from -3 to 1.5 taking the five easiest items in the test, and another group of 700 examinees with Os ranging from -1.5 to 3 taking the five most difficult items in the test. 3. Design 1~3(~): This design had three groups of 467 examinees each with Os ranging from -3 to Figure 2 Five Designs for a Fixed Number of Examinee-Item Confrontations b/8 Scale b/8 Scale Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 302 1.5, -2 to 2, and -1.5 to 3, respectively. Each group took five items with difficulties within the range of the 0 scale for that group. For example, Group 1 took the five items of the test with difficulties in the interval -3 to 1.5. 4. Design D4(f.l): This design consisted of three groups with 667 examinees each with Os ranging from -3 to 0, -1.5 to 1.5, and 0 to 3, respectively. Again, each group took three or four items with difficulties within the range of the 0 scale of each group. 5. Design D5(f.l): The last design had seven different groups of 540 examinees each with Os ranging from -4 to -2, -3 to -1, -2 to 0, -1 to 1, 0 to 2, 1 to 3, and 2 to 4, respectively. Each group took one or two items with difficulties within the 0 range of that group. The matrix Cov*(,1) for Designs DZ(la) through D5(f.l) was computed for a test with n = 7 items having equally spaced bi values ranging from -3 to + 3, but with the same a; value for all items. Thus the Cov*(fl)s were of orders 7 x 7, 14 x 14, and 21 x 21, respectively, for the one-, two-, and three- parameter models. The main diagonal matrix for each item was Cov*(,1¡). As previously noted, Cov*(,1¡) was a scalar for the one-parameter model. The relative efficiency for Designs 2 through 5 was obtained by dividing I Covf(,1¡) for D,(p) by I Cov*(,1¡) for each of these designs. Results. The relative efficiencies of D2(f.l) through DS{~,) compared to Design D¡(f.l) are given in Figures 3 and 4 for items with combinations of parameters bi E (-3, + 3), ai E (.5, 2), and c; = 0. Because Designs D2(f.l) through D5(f.l) are each related to D,(g), the results make it possible to com- pare these designs with each other. It is clear from these figures that Design D4(f.l) is generally more efficient than D3(pt) for the one- and two-parameter models, and Design D5(f.l) seems most efficient for tests with highly discriminating items. This can be explained by the smaller standard deviations of 0 in each of the samples of D5(f.l). Design D4(~,) seems most efficient for very easy items with large values for a; for the three-parameter model, but Design D1(~) is superior for bi > 0. Computations were also performed for a 14-item test, and the results were quite comparable. Moreover, other sample sizes did not seriously affect the results, as long as the designs had the same number of examinee-item encounters. Discussion A generalized variance criterion to measure efficiency in IRT models was proposed and illustrated here. Although this criterion takes into account both the variances and covariances of maximum likelihood (ML) estimators of the item parameters and assumes that the 0 parameters are fixed and unknown, it may not be optimal in all situations. Several other optimality criteria-defined as a func- tion of the asymptotic variance-covariance matrix of ML estimators-have been proposed in the literature for optimal designs. One review of these criteria is given by Atkinson (1982). Each of these measures has advantages in specific situations and may be more or less sensitive to different scale restrictions of the parameters. The effect of scale restrictions in relation to the other optimality criteria needs to be studied more carefully. Suppose that a test that measures certain skills is considered in which examinees are grouped ac- cording to their ability to master such skills. If the easy items from this test are administered to the examinees with lower ability, and the difficult items are administered to the examinees with higher ability, the application of the generalized variance criterion leads to the following recommendations for efficient estimation of the item parameters: 1. For the one- and two-parameter models, it would be more efficient to administer the easy half of a test to a sample of about .67N lower-ability examinees, the difficult half to another sample of about .67N higher-ability examinees, and the items of average difficulty to about .67N ex- Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 303 IR C4 0 % 2 .5~ S Q ’tJ c en ’R0.0 ’ # £i U - cn . 2 C) 0 b, r. .1 uLr-l w v . r~ Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 304 â % 0 -c ,2 .E~ v92 g ~ O r. ca =L S ~!3Q M M E c °## a) o 4. 0 ;>-. r_ *2lJ E M a) ’S ’M Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 305 aminees with average abilities-rather than to administer the entire test to one sample of size N. This will also be the case for the three-parameter model when easy, highly discriminating items are considered [i.e., Designs I~1(~) versus 1~4(~)]. The number of items to be administered per examinee in I)4(~) is half as large as the number of items administered in 1~,(~). In practice, however, testing time may not be reduced to a similar degree, because it may take examinees longer to answer items of appropriate difficulty. 2. It would be better for all three IRT models to administer the entire test to a sample of N, rather than to administer approximately 70070 of the test to three different samples of approximately .47N examinees each in a design in which the easy section of the test would be administered to the lower-ability group and the difficult section would be administered to the higher-ability group [i.e., Designs Di(yx) versus D,(It)]. 3. For the efficient estimation of parameters in the three-parameter model, it would be generally more efficient to use one sample of examinees with a relatively large SD,. Efficiency is gained only for easy items by administering them to a separate sample of lower-ability examinees. The results reported here are based on a limited number of designs; however, they illustrate how the proposed efficiency measure can be applied. More research is needed to expand these conclusions to other designs. The importance of the proposed measure will be enhanced if its effectiveness is also evaluated with empirical datasets based on different designs. References Anderson, T. W. (1984). An introduction to multivariate statistical analysis (2nd ed.). New York: Wiley. Atkinson, A. C. (1982). Developments in the design of experiments. International Statistical Review, 50, 161-177. Berger, M. P. F., & van der Linden, W. J. (1991). Op- timality of sampling designs in item response theory models. In M. Wilson (Ed.), Objective measurement: Theory into practice. Norwood NJ: Ablex Publishing Company. de Gruijter, D. N. M. (1984). A comment on some stan- dard errors in item response theory. Psychometrika, 49, 269-272. de Gruijter, D. N. M. (1985). A note on the asymp- totic variance-covariance matrix of item parameter estimates in the Rasch model. Psychometrika, 50, 247-249. de Gruijter, D. N. M. (1988). Standard errors of item parameter estimates in incomplete designs. Applied Psychological Measurement, 12, 109-116. Graybill, F. A. (1969). Introduction to matrices with ap- plications in statistics. Belmont CA: Wadsworth. Hambleton, R. K., & Swaminathan, H. (1985). Item response theory. Boston MA: Kluwer-Nijhoff. Kendall, M. G., & Stuart, A. (1973). The advanced theory of statistics (Vol. 2). New York: Hafner. Khatri, C. G. (1966). A note on a MANOVA model ap- plied to problems in growth curve. Annals of the In- stitute of Statistical Mathematics, 18, 75-86. Lord, F. M. (1962). Estimating norms by item- sampling. Educational and Psychological Measure- ment, 22, 259-267. Lord, F. M. (1974). The relative efficiency of two tests as a function of ability. Psychometrika, 39, 351-358. Lord, F. M. (1980). Applications of item response the- ory to practical testing problems. Hillsdale NJ: Erlbaum. Lord, F. M., & Wingersky, M. S. (1985). Sampling vari- ances and covariances of parameter estimates in item response theory. In D. J. Weiss (Ed.), Proceed- ings of the 1982 Item Response Theory and Computer- ized Adaptive Testing Conference (pp. 69-88). Minneapolis MN: University of Minnesota, Depart- ment of Psychology, Computerized Adaptive Test- ing Laboratory. McLaughlin, M. E., & Drasgow, F. (1987). Lord’s chi- square test of item bias with estimated and with known person parameters. Applied Psychological Measurement, 11, 161-173. Pandey, T. N., & Carlson, D. (1976). Assessing payoffs in the estimation of the mean using multiple matrix sampling designs. In D. N. M. de Gruijter & L. J. van der Kamp (Eds.), Advances in psychological and educational measurement. London: Wiley. Samejima, F. (1977). A use of the information func- tion in tailored testing. Applied Psychological Mea- surement, 1, 233-247. Shannon, C. E. (1948). A mathematical theory of com- munication. Bell System Technical Journal, 27, 379-423, 623-656. Theunissen, T. J. J. M. (1985). Binary programming and test design. Psychometrika, 50, 411-420. Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 306 Thissen, D., & Wainer, H. (1982). Some standard er- rors in item response theory. Psychometrika, 47, 397-412. Vale, C. D. (1986). Linking item parameters onto a common scale. Applied Psychological Measurement, 10, 333-344. van der Linden, W. J. (1987). IRT-based test construc- tion (Research Rep. No. 87-2). Enschede, The Netherlands: University of Twente. van der Linden, W. J. (1988). Optimizing incomplete sampling designs for item response model parameters (Research Rep. No. 88-5). Enschede, The Netherlands: University of Twente. van der Linden, W. J., & Boekkooi-Timminga, E. (1989). A maximin model for test design with prac- tical constraints. Psychometrika, 54, 237-247. Wingersky, M. S., & Lord, F. M. (1985). An investiga- tion of methods for reducing sampling error in cer- tain IRT procedures. Applied Psychological Measure- ment, 8, 347-364. Acknowledgments The author expresses his appreciation to the two anonymous reviewers for their valuable comments, and to Nambury l~ju for suggesting improvements in the text. Author’s Address Send requests for reprints or further information to Martijn P. F. Berger, Department of Education, University of Twente, P.O. Box 217, 7500 AE Enschede, The Netherlands. Downloaded from the Digital Conservancy at the University of Minnesota, http://purl.umn.edu/93227. May be reproduced with no cost by students and faculty for academic use. Non-academic reproduction requires payment of royalties through the Copyright Clearance Center, http://www.copyright.com/ 
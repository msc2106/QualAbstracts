ABSTRACT: 
This paper reflects on the concept of the 'Expected Value of Perfect Information' (EVPI) and the procedure used to determine it. It is widely accepted that this value is the difference between the expected value when we have perfect information and the best expected value provided by alternatives. However, this difference often results in values that no rational decision-maker would accept. Here, we overcome this difficulty by defining the 'Value of Perfect Information for the Problem' (VPIP) where we consider not only the price of perfect information (EVPI) but also two additional parameters: the 'Loss to be Avoided' and 'The Most Favourable Payoff in the Worst Scenario'. In this way, we are able to obtain a more accurate value of the amount a decision-maker might be willing to pay for perfect information. We also seek to show that the indiscriminate employment of probability theory, based by definition on the repetition of the experiment, can be misleading in the case of decisions which, owing to the very nature of the problem, are unrepeatable. 
 
PREDICTION: 
This article focuses on the value of perfect information for the problem (V PIP) in order to determine the expected value of perfect information. In this paper, we examine the relationship between probability theory and decision theory, taking into account the relationship between probability theory and decision theory, taking into account the relationship between probability theory and decision theory, taking into account the relationship between probability theory and decision theory, taking into account that the former is sustained by the repetition of experiments and that the latter needs to be right when making unrepeatable decisions. We focus on finite decision problems, that is, problems where both sets of possible actions and states of nature are finite. We structure our contribution as follows: (1) (1) the value of Perfect Information for the Problem (V PIP) – in which we consider not only the price of perfect information (EV PI) established by Szaniawski but two additional parameters: the “Loss to be Avoided” and “The Most Favourable Payoff in the Worst Scenario). 
 
FULL TEXT: 
 Keywords: Expected Value of Perfect Information, Decision Theory, Probability Theory, OpportunityCost, Risk Aversion, Unrepeatable Decision1. IntroductionThe “Expected Value of Perfect Information” (EV PI) was defined by Szaniawski in 1967 as “the highestprice the decision-maker would be prepared to pay for perfect information”1. The study of perfect infor-mation and the amount a decision-maker might be willing to pay for it was subsequently developed on thebasis of this article. Szaniawski only discusses finite decision problems where both the set of alternatives andEmail address: mboncompte@ub.edu (Mercedes Boncompte Pons)1Szaniawski (1967), p. 412Preprint submitted to Decision Support Systems March 8, 2018the set of states of nature are finite. Moreover, he points out that the value of perfect information dependson the decision criterion used by the decision-maker. Szaniawski also gives exact formula for the Maximincriteria, Laplace, Minimax loss, Hurwicz, β-criterion and maximizing expected utility.When discussing maximizing expected utility, the expected value of perfect information is calculated,following Szaniawski’s formula, as the difference between the expected value when we have perfect informa-tion and the best expected value provided by alternatives2. Furthermore, he demonstrated that the EV PImatches the minimum expected cost of opportunity. Hereinafter, all books and articles on decision theoryhave used this formula to calculate the EV PI.In the related literature, various decision problems have shown that the mechanical application of thisformula can lead to surprising outcomes. In the present paper, we overcome this difficulty by defining the“Value of Perfect Information for the Problem” (V PIP ), in which we consider not only the price of perfectinformation (EV PI) established by Szaniawski but two additional parameters: the “Loss to be Avoided”and “The Most Favourable Payoff in the Worst Scenario”. This first parameter is a key concept to ensurethe correct evaluation of the value of perfect information in each specific problem.The idea for this paper originates from the contrast between theoretical results and the results that canbe intuited from practical problems. For this reason, it draws on examples that can facilitate reasoning, yetwithout sacrificing mathematical accuracy.Additionally, we consider the relationship between probability theory and decision theory, taking intoaccount that the former is sustained by the repetition of experiments and that the latter needs to be rightwhen making unrepeatable decisions.We focus on finite decision problems, that is, problems where both sets of possible actions and states ofnature are finite. We structure our contribution as follows:Section 2 recognises the need to review the concept and the calculation of EV PI by addressing theoil-drilling problem, a classic in decision theory. It is this which has given rise to the present paper andwhich serves as its unifying thread. Section 3 reviews some of the many contributions on EV PI. We should2Szaniawski (1967), p. 4212stress, nonetheless, that in the theoretical field continuous variables have always been used. As a result, theformula given by Szaniawski in 1967 has retained full validity in practical finite decision problems. Section 4examines the relationship between probability theory and decision theory. In section 5, we summarise whatis known about EV PI in finite problems. Sections 6 and 7 are the core of this paper. Section 6 introducesthe concept of the “Loss to be Avoided” (L), which is the primary motive driving the decision-maker to payfor perfect information. In this section, we present a general formula for deducing this L value. We derivethis formula by applying an inductive reasoning to a further two examples. Section 7 defines a new upperbound for the value of perfect information for each specific problem, which we name the “Value of PerfectInformation for the Problem” (V PIP ). In this section, we present the three requirements that the V PIPmust fulfil. Then, we solve the three examples presented by taking these requirements into consideration.This section also considers the impact that obtaining perfect information has on various decision problems.Section 8 analyses an additional problem (Bierman et al., 1994) which gives a surprising result, unless theV PIP is used. Finally, section 9 presents our conclusions.2. The need to review the concept of EV PI and its calculationThe need to review the concept of EV PI and its calculation becomes evident when analysing the resultsof various published problems. Specifically, the decision problem that has triggered this article is a classicone in decision theory: the oil-drilling problem (Hammond, 1967). The EV PI proposed therein is surprisingand, at least on initial inspection, unacceptable. In this article, we reflect on the EV PI concept and examineits characteristics as well as its application to different problems.We use the updated version of the problem (Hillier and Lieberman, 2010):The GOFERBROKE COMPANY owns a tract of land that may contain oil. A consulting geologist hasreported to management that he believes there is one-in-four chance of striking oil. Because of this prospect,another oil company has offered to purchase the land for $90,000. However, Goferbroke is consideringholding the land in order to drill for oil itself. The cost of drilling is $100,000. If oil is found, the resultingexpected revenue will be $800,000, so the company’s expected profit (after deducting the cost of drilling) will3Table 1: The oil-drilling problemDrilling($) Selling($)Oil (0.25) 700,000 90,000Dry (0.75) -100,000 90,000be $700,000. A loss of $100,000 (the drilling cost) will be incurred if the land is dry (no oil).We propose the following questions:1. What decision should the company’s manager take if he is risk neutral and the utility function isU(x) = x?2. The manager believes that the geological study is not sufficient and requests a seismological study. Ifthe study was fully reliable, how much would the manager be willing to pay for it?Solution:Table 1 provides a summary of the problem.1. We calculate:Expected value (drilling)= 700, 000 ∗ 0.25− 100, 000 ∗ 0.75 = 100, 000Expected value (selling) = 90, 000.Therefore, the manager will drill based on the fact that drilling, as opposed to selling, provides ahigher expected value.2. The manager will be willing to pay the EV PI, in other words, the difference between the expectedvalue that he would obtain if he had perfect information and the best expected value offered by thevarious alternatives.In our problem, if we knew we would strike oil, then we would drill; an outcome that will occur in 25%of cases. In other contingencies, we would sell (75%). Based on the value we would expect to obtainwith these amounts, we would subtract the expected value of drilling, which is the option we wouldchoose if we did not have perfect information.4EV PI= (700, 000 ∗ 0.25 + 90, 000 ∗ 0.75)− 100, 000= 142, 500Answer: The manager would be willing to pay up to $142,500 for perfect information.The aim of this paper is to highlight that in many instances the EV PI obtained is unacceptable for asensible decision-maker.Here, the company is unlikely to be willing to pay $142,500 for a seismic study to obtain perfect in-formation, since this value exceeds the cost of drilling, which gives the perfect information par excellence.Indeed, the reason why the manager resorts to decision theory is the cost involved in drilling. If drilling wascost free, no one would consider selling without drilling3.3. Related LiteratureThe study of the amount of money a decision-maker is willing to pay to have perfect information whenmaking his decision has triggered a broad literature since Szaniawski first published his article, ”The value ofperfect information” (1967), in which he presents the formula that we continue to use to this day. Szaniawski,however, only discusses finite decision problems. We would like to stress that practically everything thathas been written in the theoretical field about the value of perfect information uses continuous distributionfunctions. Below, we present various examples of such studies undertaken in several areas.The EV PI has been studied from many different points of view: using optimal control theory (Mehrez,1985b), analysing the additivity of EV PIs when the perfect information comes from several sources (Samsonet al., 1989), or calculating EV PIs through influence diagrams (Zhang et al., 1993). It has also been shown3It might be thought that this paradox is due to the decision-maker’s attitude to risk. As is known, decision theoryreflects the decision-maker’s aversion or predisposition to risk by choosing concave or convex utility functions, respectively.However, using a concave function as a decision-maker’s utility function does not ensure that the EV PI will be acceptable.For instance, in the oil-drilling problem, using U(x) = ln(x+100, 001), we obtain EV PI = 82, 147 (Lawrence, 1999); but usingU(x) =√x+ 100, 000, we obtain EV PI = 113, 074, which is still higher than the cost of drilling.5that the value of information will sometimes be negative for an agent who violates the independence axiomof expected utility theory (Wakker, 1988). However, the value of perfect information will always be non-negative if the agent satisfies a weak dominance axiom (Schlee, 1991). Thon and Thorlund-Petersen(1993)studied the sufficient conditions on the utility function and the nature of the change in riskiness for thevalue of information to increase; additionally, they related the results obtained with the maximum valueof such information. In 1999, Hammitt and Shlyakhter studied the relation between the expected value ofinformation and the prior distribution used to represent current information. Other studies have identifiedbounds on the maximum amount that the decision-maker would be willing to pay for the perfect information(Huang et al., 1977; Mehrez, 1985a).Many applications have been made in different branches of science and technology, including agriculture(Meza et al., 2003); medicine (Felli and Hazen, 1998; Welton et al., 2011; Briggs et al., 2012) ; pharmacy(McCullagh et al., 2016); and engineering (Chazarra et al., 2017; Le et al., 2014). This last article formspart of an interesting monograph about the value of information that includes numerous other references(Keisler, 2014).4. Decision Theory and Probability TheoryDecision theory is an interdisciplinary field of study that analyses how somebody chooses a particularcourse of action, from a set of different possibilities, which leads to the best result, while respecting thatperson’s preferences (González, 2004).Various criteria can be used to solve a decision problem4 and choosing the one that best reflects thedecision-maker’s intention is the first decision that has to be taken since, as we know, the outcomes arelikely to differ depending on the criteria used (Laporte and Ouellet, 1980).4We mention some of the main ones: Maximax (which chooses the alternative that offers the best consequence), Maximin(which chooses the alternative that offers the best of the worst consequences), Laplace (which considers all states of natureas having the same probability and chooses the alternative that has the best expected value), Savage (which chooses thealternative that guarantees the minimum opportunity cost), and Bayes (which calculates the probability of every state ofnature and chooses the alternative with the best expected value).6Mathematics, via probability theory, sheds light on decision theory and is a basic tool for its develop-ment5.The examples presented in books on decision theory concern “important” decisions, either financially,because of the amount of money involved, or socially, because of the consequences for the decision-maker’sprivate or public life. A fairly common feature of these decisions is their “irreversibility”. Indeed, decisionsare often irreversible, as an about-face implies a serious financial problem or having to address difficultiesof another nature. They are, as such, ”unique” decisions, that is, those taken rarely, when electing, forexample, to invest or not in a particular project, or to change or to stay in a job. We are not dealing withdecisions that are easily made or, at least, decision theory has not been developed for decisions of this kind.Probability theory is based on the study of the results obtained after repeating the same experiment.The more the experiment is repeated, the greater is our precision in establishing the probability that wewill obtain a certain result again. However, from both theoretical and practical points of view, considerablecontroversy is attached to the notion of the “repetition of experiments” (Robert, 2001).When decision-makers use probability theory to determine the expected value of their payoff (positive ornegative) and opt for a certain alternative, they should not forget that what they have is merely an indicatoror, if you will, a fictitious value that only serves as a point of comparison with other indicators, or expectedvalues, that result from opting for other alternatives. It can never be considered a real value.In this article, we identify various aspects about which a decision-maker must exercise caution whenusing the expected utility model to calculate the EV PI6.If we return to the oil-drilling problem outlined in the Introduction, the claim that the expected valueis 100,000 when the decision-maker opts to drill serves merely to compare this course of action with the5However, there are many articles that, for various reasons, question the standard decision theory -namely, the expectedutility model- and propose alternative models such as the “unexpected utility” or the “nonlinear expected utility” (MacCrimmonand Larsson, 1979; Machina, 1987; Lawrence, 1999).6Similarly, although in another context, Ekenberg et al. (1997) point out that ”while a certain evaluation of a strategy mayresult in an acceptable expected utility, the consequences of adopting it might be so dire that it should nevertheless be avoided”and suggest establishing certain security constraints.7expected value of the option of selling, valued at 90,000. However, if the decision-maker drills, under no setof circumstances will his profit be $100,000: either he will make a profit of $700,000 or he will run up a lossof $100,000. Only if the decision-maker has the opportunity to make this decision thousands of times, byearning $700,000 a quarter of the times and losing $100,000 on all other occasions, would he end up witha balance of $100,000, as the expected value predicts.7 Clearly, the difficulty in taking the decision liesprecisely in the fact that it can only be taken once.We believe that the decision-maker must be especially cautious when using probability theory to makedecisions. For example, if we compare the expected value of drilling (100, 000) with that of selling (90, 000),decision theory advises us to drill because the expected value of this action is higher. It is our contentionthat a more accurate reading would set out the resolution in negative terms, intimating that decision theory,in accordance with probability theory, “does not discourage him” from drilling. If, however, the expectedvalue of drilling had been lower than the expected market value, probability theory would indicate to usthat statistically he would be ill-advised to drill.Given that the theory of probability does not discourage us from drilling, it is perfectly consistent onthe manager’s part to ask for a seismological study in order to increase his degree of certainty.In problem solving, the decision-maker should not forget that real data are constantly being mixed withprobabilistic data and that a superficial reading of the decision tree could lead to unfortunate conclusionsbeing drawn.5. The Expected Value of Perfect information (EV PI)In decision theory, the EVPI is defined as the price an individual would be willing to pay to have accessto perfect information (Szaniawski, 1967; Hubbard, 2014).7Note that in the case of selling, the expected value matches the actual value since, if you sell, the probability of obtaining$90,000 is 100%.85.1. The EV PI is an upper boundWe understand that the EV PI always provides an ”upper bound” for the potential value of any exper-iment we can undertake to improve our information (Hillier and Lieberman, 2010; López Cachero, 1989).Mathematically, the upper bound of a set A is defined as follows:Be A ⊂ R, a ∈ Ra is an upper bound of the set A ⇔ a ≥ x ∀x ∈ AWhen an upper bound a belongs to A, then a is called a maximum. Clearly, a maximum gives us moreaccurate information about the set A than an upper bound.But the maximum of the set of amounts that a decision-maker would be willing to pay to have perfectinformation cannot be objective, in the sense that it would probably not result from the application of aformula but would depend on the decision-maker himself and on his aversion/predisposition to risk.For this reason, it could be useful to specify an upper bound as established by the EV PI formula.However, we should stress that this upper bound may lie far beyond the maximum that a sensible decision-maker would be willing to pay in order to have perfect information.While it is true that the price of perfect information cannot be anything other than the difference betweenthe expected value we obtain from having this information and the expected value without it, decision theoryis unable to inform the decision-maker that this value is the maximum he should pay for perfect information,regardless of anything else. In the same way, the correct calculation of the price of a product does not justifyits purchase.5.2. Expected Value of Perfect Information and Opportunity Cost of the Best AlternativeTable 2 lists the notations that we will use in our discussion.First, in order to clarify the following explanation, we redefine the “Expected Value of Perfect Informa-tion” (EV PI) as the price of perfect information. We calculate this in the usual manner: that is, as thedifference between the expected value that we obtain with perfect information and the best expected valuewithout perfect information.9Table 2: NotationsAj The alternatives (1 ≤ j ≤ n)Si The scenarios (1 ≤ i ≤ m)pi The probability of SiE(Aj) The expected value of Ajxij The payoff with Aj in Si (1 ≤ i ≤ m, 1 ≤ j ≤ n)x̃i The best value in Si (1 ≤ i ≤ m)Aj̃ The alternative with the best expected valueCoij The opportunity cost of Aj in Si (1 ≤ i ≤ m, 1 ≤ j ≤ n)Si The worst scenario (where Aj̃ obtains its worst result)xij̃ The worst payoff of the best alternative Aj̃L The Loss to be AvoidedPc The payment pertaining to the decision-maker in the current momentFPW The Most Favourable Payoff in the Worst ScenarioEV PI The Expected Value of Perfect InformationV PIP The Value of Perfect Information for the ProblemV PIPR The R-Value of Perfect Information for the Problem10That is, let a decision problem P with n alternatives Aj (1 ≤ j ≤ n) and m scenarios Si (1 ≤ i ≤ m)each have a probability pi (1 ≤ i ≤ m).Let xij (1 ≤ i ≤ m, 1 ≤ j ≤ n) be the payoff that the decision-maker obtains if he chooses alternativeAj and scenario Si occurs. Hereinafter, we assume that the decision is about maximizing benefits or profits;however, in this paper, we will always refer to a “better” payoff rather than to a “greater” payoff, in orderto include the problems about minimizing costs. In this cases, it is sufficient to replace “max” with “min”.Let x̃i (1 ≤ i ≤ m) be the best value or the highest profit associated with each scenario, that is:x̃i = maxjxijLet E(Aj) be the expected value of Aj .Let Aj̃ be the best alternative, that is, the alternative with the best expected value:E(Aj̃) = maxjE(Aj) = maxjm∑i=1xijpi =m∑i=1xij̃piTherefore,EV PI =m∑i=1x̃ipi −m∑i=1xij̃pi (1)Moreover, if, as per usual, we refer to the opportunity cost (Coij) of the alternative Aj in scenario Si asthe difference between the best payoff in scenario Si and the payoff that takes place with alternative Aj inscenario Si:Coij = x̃i − xijthen, we obtain that the EV PI can also be interpreted as the expected value of the opportunity cost of thebest alternative, that is, the expected value of the amount that we lost with the best alternative with regardto the best option in each scenario (Szaniawski, 1967; Laporte and Ouellet, 1980):EV PI =m∑i=1x̃ipi −m∑i=1xij̃pi =m∑i=1(x̃i − xij̃)pi (2)Furthermore, since seeking the alternative that minimizes the expected value of the opportunity costcoincides with seeking the alternative that maximizes the expected value, then the EV PI matches the11minimum expected opportunity cost (Szaniawski, 1967; Laporte and Ouellet, 1980), that is:minjE(Coij) = minjm∑i=1(x̃i − xij)pi= minj[m∑i=1x̃ipi −m∑i=1xijpi]=m∑i=1x̃ipi −maxjm∑i=1xijpi=m∑i=1x̃ipi −m∑i=1xij̃pi= EV PI(3)Finally, note that an upper bound of the EV PI is maxi(x̃i − xij̃):EV PI =m∑i=1(x̃i − xij̃)pi≤ maxi(x̃i − xij̃)m∑i=1pi≤ maxi(x̃i − xij̃)(4)which means that the EV PI is upper bounded by the highest opportunity cost that results in the bestalternative Aj̃ in certain scenarios.In the next section, we introduce a new concept, which we believe should be taken into account whenmeasuring the value of perfect information.6. The Loss to be Avoided (L)We understand that a decision-maker is willing to pay for perfect information because he wants to avoidrunning up a loss. For example, in the oil-drilling problem, the highest loss that he can make is $100,000.Clearly, therefore, the main objective of any study that provides us with perfect information is to preventsuch a loss. Below, we discuss whether it is possible to define the concept of the “Loss to be Avoided” (L)generally for all problems.Obviously, the decision problem would no longer be difficult if the best alternative Aj̃ was the best in allscenarios. However, it is possible that there is a scenario Si where the best alternative offers a worse resultthan other alternatives. It is in this scenario where the decision problem lies.12Definition 1. The scenario where the best alternative Aj̃ gives its worst result is defined as the “worstscenario for the best alternative” or simply “the worst scenario” and we denote it as Si, that is:minixij̃ = xij̃It does not seem difficult to determine what the worst scenario is, since it is the one of greatest concernto the decision-maker. In the oil-drilling problem, the worst scenario would clearly be that in which theyfail to strike oil.Therefore, we understand that choosing the best alternative can easily entail the risk of making animportant loss in one or more scenarios, and it is precisely this loss that we want to avoid when we resortto decision theory and we analyse the EV PI.The next issue is how to identify the “Loss to be Avoided”. We begin by seeking to determine whetherwe can identify L with one of the concepts that we enumerate below. Then, by analysing two new problems,we discard these concepts in order to obtain the final formulation. To present these concepts, once again,we draw on the oil-drilling problem.In the oil-drilling problem, the “Loss to be Avoided” is, at least at first sight, the drilling costs, whichis the minimum payment offered by the best alternative. It might be thought that this is always the case.It might also be thought that we should take into account the $90,000 profit that we lose when we do nottake up the option of selling, which is the best alternative in the worst scenario. That is, we might alsoconsider L to coincide with the opportunity cost of the best alternative in the worst scenario or, maybe, thatL coincides with the highest opportunity cost that can be obtained with the best alternative but perhaps notin the worst scenario.Therefore, we need to ask ourselves:A. Is L the highest opportunity cost that can be obtained with the best alternative Aj̃?B. Is L the opportunity cost associated with the best alternative Aj̃ in the worst scenario Si?C. Is L the minimum payment associated with the best alternative Aj̃ , that is, the payment associatedwith the best alternative in the worst scenario (xij̃)?13Table 3: The horse-racing problemaA1 A2 A3 x̃iLady (0.5) -30 20 15 20Fury (0.2) 10 50 25 50Black (0.3) 13 -50 0 13E(Aj) -9.1 5 12.5aThe last row presents the expected values of each game ofchance and the last column shows the highest payment that isobtained by each winning horse in some of the games.To answer these questions, let us consider two additional decision problems.• First problem: The horse-racing problemA player is offered the opportunity to participate in one of the following games of chance (A1, A2 andA3). The payments he receives will depend on which horse wins a certain race: Lady is the favouritein 50% of the betting. Fury is favourite in 20% and Black in 30%.The problem is presented in Table 3.EV PI = (20 ∗ 0.5 + 50 ∗ 0.2 + 13 ∗ 0.3)− 12.5= 23.9− 12.5 = 11.4The best expected value criteria indicate choosing game A3 because its expected value is 12.5, which isclearly superior to the values of the other two games. It is also clear that the worst scenario in A3 is thatBlack wins the race. This is the scenario that is likely to cast doubt in the mind of the decision-maker, sinceif he had perfect information and knew that Black would win, he would choose game A1.In all probability, the decision-maker would indeed choose A3, because the expected value is the highestand because in this game he “cannot lose anything”.What, therefore, would be the “Loss to be Avoided” value in this game?In Table 4 we write the associated opportunity costs.14Table 4: The horse-racing problem. Opportunity costsOpp. costs A1 A2 A3Lady (0.5) 50 0 5Fury (0.2) 40 0 25Black (0.3) 0 63 13A. Is the “Loss to be Avoided” the highest opportunity cost associated with A3, that is, 25?We believe that the decision-maker cannot perceive as a loss what he would “fail to win” if Fury wereto win the race, because this is precisely the decision-maker’s most desired scenario (who after allchose A3), since in this game he obtains the highest profit.Note, therefore, that the opportunity cost depends on the profits associated, perhaps with a very lowprobability, with other alternatives and that these amounts could easily constitute “a false promise”.B. Is the “Loss to be Avoided” the opportunity cost associated with A3 if Black wins, that is, 13?We believe that if Black wins, the decision-maker will consider himself unlucky as he has neither wonor lost anything. Moreover, he will be glad that he did not choose A2. However, we believe that hecannot perceive 13 as a “loss” as it was a prize that he had not yet won.C. Is the “Loss to be Avoided” the minimum payment associated with the best alternative A3, that is,0?Indeed, we believe that the decision-maker will consider that in the worst scenario provided by gameA3, he has lost nothing.Therefore, in this decision problem, the “Loss to be Avoided” value is 0.Let us further our explanation by examining a second problem.• Second problem: The airline problem(French, 1986)Consider the case of an airline that has the opportunity to buy a second-hand airplane. The overallpayoff for the airline depends on whether the aircraft turns out to be very reliable, moderately reliable or15Table 5: The airline problemReliability Buying Not buying x̃iHigh (0.2) 100 17 100Mod. (0.3) 34 17 34No (0.5) 1 17 17E(Aj) 30.7 17Table 6: The airline problem. Opportunity costsReliability/Opp. costs Buying Not buyingHigh (0.2) 0 83Mod. (0.3) 0 17No (0.5) 16 0unreliable after economically evaluating customer satisfaction or dissatisfaction, the economic income,the start-up and maintenance costs, etc. This payoff is reflected in Table 5.The payoff is expressed in million $. If the aircraft is not purchased, we assume the payoff will be thesame as in the initial situation.In this problem, the expected value criterion indicates that the best alternative is “To buy the airplane”.Obviously, the worst scenario is the one in which the aircraft turns out to be “Unreliable” because then thecompany fails to improve its real profit of $17 million, and the benefits are reduced to $1 million.What, therefore, would be the “Loss to be Avoided” value in this problem?In Table 6 we write the associated opportunity costs.In this problem the “Loss to be Avoided” is the difference between the current profit, on which thecompany can supposedly count if it does not take the decision to buy the airplane (that is, $17 million), andthe profit that it can obtain if it opts for the best alternative and finds itself in the worst scenario (that is,$1 million). Clearly, what might hold the company back in its decision to buy the aircraft is the possibilityof finding itself in the worst scenario and “losing” $16 million.16Table 7: The airline problem. First variantReliability Buying Not buying x̃iHigh (0.2) 100 17 100Mod. (0.3) 34 17 34No (0.5) -1 17 17E(Aj) 29.7 17Thus, in this case, the “Loss to be Avoided” is the opportunity cost associated with the best alternative inthe worst scenario. Unlike the horse-racing problem, the “Loss to be Avoided” is not the minimum paymentassociated with the best alternative but rather the opportunity cost associated with the best alternative inthe worst scenario. Note that were we to modify the problem slightly, so that the associated payment in theworst scenario was negative, for instance, if the aircraft turned out to be unreliable, then would be a lossof $1 million, and so the “Loss to be Avoided” would still be the opportunity cost associated with the bestalternative in the worst scenario, that is, $18 million. (see Table 7).Why does this difference exist between the horse-racing problem, where the loss coincides with thepayment associated with the best alternative in the worst scenario, and the airline problem, where the lossis the opportunity cost associated with the best alternative in the worst scenario? We believe that the keylies in the time reference. In the first problem, we start from a present moment in which the current profitis $0, whereas in the airline problem, in the present moment we have $17 million.Let us suppose that in the airline problem a third alternative exists, namely acting as intermediaries, inother words, buying the aircraft and then immediately reselling it. Additionally, let us also suppose that thepayments are not strictly the profit but rather the result of a utility function. In this case, if the airplaneproved to be very reliable, the outcome would be understood to be a $10 million loss because we would havesold a good plane that could have yielded greater profits for the company. On the other hand, if it provedto be unreliable, our utility would be $20 million. The new problem is presented in Table 8.Now, buying the aircraft is still the best alternative and the Loss to be Avoided is still $18 million, which17Table 8: The airline problem. Second variantReliability Buying Not buying Inter. x̃iHigh (0.2) 100 17 -10 100Mod. (0.3) 34 17 15 34No (0.5) -1 17 20 20E(Aj) 29.7 17 12.5Table 9: The oil-drilling problem. Opportunity costsOpp. costs Drilling SellingOil (0.25) 0 610,000Dry (0.75) 190,000 0is neither the minimum payment associated with the best alternative nor the opportunity cost of the bestalternative in the worst scenario, which in this instance would be $21 million.Therefore, we are now in a position to define the “Loss to be Avoided”.Definition 2. The “Loss to be Avoided” (L) is the difference between the payment pertaining to the decision-maker in the present moment (Pc) and the worst payment associated with the best alternative (xij̃), providedthat this difference is positive; otherwise, the “Loss to be Avoided” will be zero.L = max{Pc −minixij̃ , 0}= max{Pc − xij̃ , 0}(5)In other words, if the payment associated with the best alternative in the worst scenario is higher thanthe payment in the present moment, the “Loss to be Avoided” will be null.Returning now to the oil-drilling problem that initially triggered the discussion addressed herein, Table9 describes the opportunity costs array associated with the problem. Note that, according to Definition 2,the challenge of determining L is actually that of determining Pc. If the decision-maker understands thatat the present moment his payment is $0, then the “Loss to be Avoided” will be the drilling costs. Onlyif the decision-maker understands that the sale of the tract of land will raise $90,000 will the “Loss to be18Avoided” be the $190,000 indicated by the opportunity cost and, consequently, the decision-maker could bewilling to pay $142,500 for perfect information.In this case, we could probably interpret these implications in the opposite sense: that is, if the decision-maker is unwilling to pay up to $142,500 for perfect information, then it is because he does not actuallyperceive that his “Loss to be Avoided” is $190,000.Here, we should stress once more that we are hardly entitled to refer to the money that we have not yetgained as a “loss” and that the $100,000, which inexorably will have to be drawn from the pocket of thedecision-maker if he drills, cannot be considered as being on the same level as the $90,000 that will probablybe pocketed if the sale is finally formalized.We believe that placing ourselves in the “present” is what allows us to determine whether L is strictly“what is lost” or whether L also extends to what one “fails to win”. Of course, there will be many casesin which the “Loss to be Avoided” will be highly debatable and, therefore, the exclusive competence of thedecision-maker.As we have seen in (2), the EV PI contains in its calculation procedure an approximation of our “Lossto be Avoided” concept, in the sense that its value coincides with the expected value of the opportunitycost associated with the best alternative. However, once again, it is an “upper bound” and the “Loss to beAvoided” can be substantially lower.In the next section, we present a new concept that provides us with the value of perfect information foreach particular problem.7. The Value of Perfect Information for the Problem (V PIP )7.1. Deduction and formulation of the VPIPWe redefined the “Expected Value of Perfect Information” (EV PI) then as the price of perfect infor-mation. We distinguish this value from the “Value of Perfect Information for the Problem” (V PIP ) anddefine this as an upper bound of the set of all amounts that a decision-maker is willing to pay in order toobtain the perfect information related to the specific conditions of a problem. Thus, we calculate our own19value of perfect information by relying not only on the EV PI but also on the data provided by the specificproblem we address. A similar approach was developed by Wang et al. (2008).We calculate the EV PI, as per usual, according to (1), as the difference between the expected value weobtain with perfect information and the best expected value without perfect information.To calculate the V PIP , the new bound we are seeking must fulfil the following three requirements.• First requirement: Expected Value of Perfect Information (EV PI)The first condition is that the upper bound of the V PIP must be lower than that of the EV PI, sinceit makes little sense to spend more money on the study than the amount identified as the price ofperfect information by probability theory.• Second requirement: Loss to be Avoided (L)The second condition is that the V PIP must be lower than the loss we want to avoid (L). As explainedin section 6, if we are willing to pay for perfect information, it is precisely because we wish to avoid agreater loss, in the same way that no one would pay an insurance premium higher than the price ofthe object they want to insure8.• Third requirement: The Most Favourable Payoff in the Worst Scenario (FPW )The V PIP should be lower than the most Favourable Payoff obtained in the Worst scenario (FPW ).In this way, we ensure that the cost of the study is covered in all scenarios.For instance, in the oil-drilling problem, it could be deduced that the maximum amount we would bewilling to pay was $100,000, since this represents the cost of drilling. Thus, any amount that gives usperfect information for less than $100,000 will be a saving. Nevertheless, if, for example, the studycosts $95,000 and we find the well to be dry, we will have saved $5,000 with regard to the drilling costsand we will opt to sell. However, we would be unable to offset the cost of the study by selling thetract of land.8Risk analysis is a valuable approach to adopt in studies of this kind (Marques and Berg, 2011).20Thus, we come to our final formulation of the “Value of Perfect Information for the Problem”:Definition 3. Given a finite decision problem, the “Value of Perfect Information for the Problem”(V PIP )is a higher bound of the value that a decision-maker is willing to pay in order to have perfect information.It is calculated as the minimum between the “Expected Value of Perfect Information” (EV PI), the value ofthe “Loss to be Avoided” (L) and “The Most Favourable Payoff in the Worst Scenario” (FPW ).V PIP = min{EV PI, L, FPW} (6)A decision-maker with a greater predisposition to risk might disregard the latter requirement and considera V PIPR bound acceptable, even though the study costs would signify a net loss in the worst scenario.V PIPR = min{EV PI, L} (7)We refer to V PIPR as the “R-Value of Perfect Information for the Problem”.It is common practice in decision theory to refer to “risk-neutral” decision-makers, indicating that theyare “trusting” of the expected values associated with the various options and that they ignore the negativeconsequences that may result; but, in reality, very few decision-makers adopt such an attitude (Hammond,1967). As a matter of fact, it may not even be acceptable among these decision-makers to proceed withouttheir adhering to the requirement of neither exceeding the value of the “Loss to be Avoided” nor the valueof “The Most Favourable Payoff in the Worst Scenario”. The procedures developed by decision theory cannever lead the decision-maker to risk without warning.Let us stress once again the importance of keeping in mind that the decision we are to take is unrepeatableand unique, and that the difference in expected values can only help us in a negative sense. That is, it canonly serve to warn the decision- maker of the fact that even if he has perfect information, probability theoryindicates an increase in the expected value, in this case, of $142,500 and no higher. Thus, decision theoryadvises against spending more than $142,500 on the study; but, under no circumstances should decisiontheory convey the idea to the decision-maker that he would be right to invest any amount below $142,500in order to obtain perfect information without further details.21Table 10: The oil-drilling problem. V PIP and V PIPR values depending on LL = 100, 000 L = 190, 000V PIP min{142, 500, 100, 000, 90, 000} = 90, 000 min{142, 500, 190, 000, 90, 000} = 90, 000V PIPR min{142, 500, 100, 000} = 100, 000 min{142, 500, 190, 000} = 142, 5007.2. Oil-drilling problem solutionTo conclude the oil-drilling problem, let’s imagine the case of a decision-maker who estimates L=$100,000or L=$190,000 and one that is willing or not to pay for Perfect Information, the price of which may not becovered by the profit he will obtain in the worst scenario (as shown in Table 10).The thesis of the present article is that a very high percentage of decision-makers will prefer the V PIPand L=$100,000; thus, they will be unwilling to pay more than $90,000 for the perfect information for thedrilling problem.In this case,V PIP = EV PI = V PIPRThat is, the price that the decision-maker is willing to pay (V PIP or V PIPR) is lower than the “ExpectedValue of Perfect Information” (EV PI).However, recall that we have defined the V PIP as an upper bound and not as a maximum, given that thedecision-maker could still identify other restrictions related to his problem that might reduce even furtherthe amount he is willing to pay for perfect information.7.3. Knowledge of perfect information and the decision-making processThe primary goal of what is assumed to be perfect information is, clearly, to guide the individual towardstaking the right decision. Yet, this is another unusual characteristic of the drilling problem, because havingperfect information does not allow the company to make a decision. Indeed, whether the company obtainsperfect information by paying for a report or it obtains it by drilling, if it strikes oil, it will suffer noinconvenience. However, if the tract of land is dry, it will have asymmetric information and will no longer beable to sell at the initial $90,000price, which was established for the land with possibilities of oil exploitation.22If the company overlooks this difficulty and sells for $90,000 because the buyer, the second agent, doesnot have the perfect information that it has, then it will be violating a principle of ethical economy.Thus, we can identify two types of problem:1. Problems in which the alternatives remain the same after obtaining perfect information (Airline prob-lem).2. Problems in which the alternatives change or disappear after obtaining perfect information (Oil-drillingproblem).The change in alternatives after obtaining perfect information constitutes a difficulty that can easilyarise in problems when there is a second agent that has to make his decision after the initial decision-makerhas taken his and to whom the decision-maker is morally obliged to transmit perfect information. This isthe case of the oil companies. In contrast, this inconvenience does not exist in the airline problem, since theaircraft supply company has made its decision before our decision-maker has made his.7.4. Resolution of the other two problems applying the V PIPLet us now solve the two additional problems posed:• The horse-racing problemAs discussed, the alternative chosen will be A3, because it has the highest expected value: 12.5. Thatis, probability theory indicates that this is the alternative with which we will obtain the greatest profitsand, therefore, we would choose it. We calculate the EV PI according to (1):EV PI= (20 ∗ 0.5 + 50 ∗ 0.2 + 13 ∗ 0.3)− 12.5= 23.9− 12.5 = 11.4Next, we need to ask ourselves how much we would be willing to pay for the perfect information forthis specific problem. The answer is derived from (6):V PIP = min{11.4, 0, 13} = 023and it transpires that, as the “Loss to be Avoided” value is zero, we would not be willing to payanything.In that case, according to (1), (6) and (7):V PIP = V PIPR = EV PI• The airline problemExpected value (buying)= 100 ∗ 0.2 + 34 ∗ 0.3 + 1 ∗ 0.5 = 30.7Expected value (not buying) = 17As such, the company would prefer to buy; or, in negative terms, it would not reject the buying option.But how much would the company be willing to pay for perfect information? First, let us calculatethe “Expected Value of Perfect Information”:EV PI= (100 ∗ 0.2 + 34 ∗ 0.3 + 17 ∗ 0.5)− 30.7= 8We can now compare this value with the “Loss to be Avoided” and the “The Most Favourable Payoffin the Worst Scenario”.As explained, in this problem the “Loss to be Avoided” is $16 million. Therefore:V PIP = min{8, 16, 17} = 8And in this case,V PIP = V PIPR = EV PIIn this example, probability theory tells us that having perfect information can provide an incrementalbenefit of $8 million. Moreover, the V PIP and V PIPR bounds certify that this amount is perfectlyconsistent with the problem, because the loss we want to avoid is much higher and, even in the worstscenario, it would be covered.24Table 11: Introduction of a new productDemand Introducing Not introducingHigh (0.3) 4 0Low (0.7) -2 0E(Aj) -0.2 0Note also that the definition of V PIP and V PIPR allows the decision-maker to set limits and goals.In other words, the amount of the “Loss to be Avoided” could be relaxed or otherwise, depending onwho the decision-maker is and on his predisposition/ aversion to risk.8. An additional conflict resolution problem: introduction of a new productThe following example, taken from the economic literature (Bierman et al., 1994), also shows thatconsidering only the EV PI can lead to wrong conclusions being drawn.“It concerns a new product whose potential will be either big or small (that is, the product will be eithera success or a failure). The $4 million value corresponds to the net profit if its selling potential is big. Theloss incurred if the product does not sell well is $2 million. Table 11 shows the values that condition thedecision”.Based on the expected value of each alternative E(Aj), probability theory advises against introducingthe new product, and the negative expected value obtained with this option should be sufficient to cause usto abandon the project.However, if we ask ourselves how much we would be willing to pay for perfect information, we obtain:EV PI = (4 ∗ 0.3 + 0 ∗ 0.7)− 0 = 1.2− 0 = 1.2V PIP = min{1.2, 0, 0} = 0V PIPR = min{1.2, 0} = 0Note that even with perfect information the profits in the worst scenario would be 0. Then, we cannotadvise the decision-maker to spend up to $1.2 million to obtain perfect information, because in 70% of the25cases this money will constitute a net loss. Furthermore, we note that the “Loss to be Avoided” in thechosen alternative is null 9.9. ConclusionsImportant decisions do not accept tests or experiments. As such, the aim of decision theory is to providethe decision-maker with some security when faced with a dilemma that does not accept mistakes, becausethe price of such mistakes can be very high.Here, we have stressed that the probability theory is based on the repetition of the experiment, whiledecision theory focuses essentially on problems that do not allow for any repetition. We propose that theonly safe reading of the expected utility of an alternative is in its negative sense. In other words, if wehesitate between two options and the expected utility value of A is lower than that of B, decision theory,supported by probability theory, will rule out option A and will go on to examine option B using the absolutevalues that option B entails.One of the main contributions of this article has been the development of the concept of the “Loss tobe avoided” as a key idea for calculating the upper bound of an amount that a decision-maker would bewilling to pay in order to have perfect information. The concept of the “Loss to be Avoided” underlies9Moreover, underlying the problem there is the idea that the decision-maker hopes to obtain the $4 million profit with a 0.3probability. For this reason, a decision-maker might fail to heed the warning raised by probability theory using the maximumexpected utility criterion and, hence, decide to launch the product, with the subsequent risk of losing $2 million with a 0.7probability. In this case, we understand that the “Loss to be Avoided” is the $2 million. The calculation can be made asfollows:EV PI = (4 ∗ 0.3 + 0 ∗ 0.7)− (−0.2) = 1.2 + 0.2 = 1.4V PIP = min{1.4, 2, 0} = 0Only in this case, and warning the decision-maker about the risk, we have:V PIPR = min{1.4, 2} = 1.4However, we cannot stress enough that these are upper bounds, because a sensible decision-maker is unlikely to spend $1.4million with a probability of 1 to avoid a loss of $2 million with a probability of 0.7.26the decision-maker’s predisposition to pay for perfect information. We have both defined this concept anddeduced how it should be calculated in the case of a finite decision problem.In addition, we have defined a new upper bound for the value that a decision-maker might be willing topay in order to have perfect information in a particular problem. This new bound, which we call the “Valueof Perfect Information for the Problem” (V PIP ), takes into account the “Loss to be Avoided” value andanother new factor, the “Most Favourable Payoff in the Worst Scenario”. These two parameters differ inevery problem and allow the V PIP to provide values that are more closely adjusted to reality than thoseprovided by the simple calculation of the EV PI.We have also formulated a variant of the V PIP , the V PIPR, which could be acceptable to risk-seekingdecision-makers. When these two bounds do not coincide, this indicates to the decision-maker that, in theworst scenario, the V PIPR will not be covered by the payoff he obtains. By introducing these two newbounds, that is, the V PIP and the V PIPR, the value of perfect information defined and formulated bySzaniawski can be adapted to each specific decision problem. Moreover, when we analyse the problems thatpresent surprising results in terms of the “Loss to be Avoided” concept and the “Most Favourable Payoff inthe Worst Scenario” concept, we obtain more accurate values.A sensitivity analysis of the results reveals a series of aspects that we would like to address in futureresearch.10AcknowledgmentsI would like to express my warm appreciation to Professor Marina Núñez Oliva, whose contributionshave been most valuable in the drafting of this article. I am also deeply grateful to Lijue Lu for her technicalsupport. Finally, we would like to thank the editor-in-chief and the three anonymous reviewers, whosecomments and suggestions significantly improved the paper.10With continuous distribution functions, see Felli and Hazen (1998).27ReferencesBierman, H., Bonini, C. P., Hausman, W. H., Morales Peake, E., 1994. Análisis cuantitativo para la toma de decisiones.Wilmington: Addison-Wesley Iberoamericana.Briggs, A. H., Weinstein, M. C., Fenwick, E. A., Karnon, J., Sculpher, M. J., Paltiel, A. D., 2012. Model parameter estimationand uncertainty analysis: a report of the ispor-smdm modeling good research practices task force working group–6. MedicalDecision Making 32 (5), 722–732.Chazarra, M., Pérez-Dı́az, J. I., Garćıa-González, J., 2017. Value of perfect information of spot prices in the joint energy andreserve hourly scheduling of pumped storage plants. Electric Power Systems Research 148, 303–310.Ekenberg, L., Danielson, M., Boman, M., 1997. Imposing security constraints on agent-based decision support. Decision SupportSystems 20 (1), 3–15.Felli, J. C., Hazen, G. B., 1998. Sensitivity analysis and the expected value of perfect information. Medical Decision Making18 (1), 95–109.French, S., 1986. Decision theory: an introduction to the mathematics of rationality. Halsted Press.González, F. A., 2004. Teoŕıa de la decisión e incertidumbre: modelos normativos y descriptivos. Empiria. Revista demetodoloǵıa de ciencias sociales (8), 139–160.Hammitt, J. K., Shlyakhter, A. I., 1999. The expected value of information and the probability of surprise. Risk Analysis 19 (1),135–152.Hammond, J. S., 1967. Better decisions with preference theory. Harvard Business Review 45 (November), 123–141.Hillier, F., Lieberman, G., 2010. Introduction to operations research. McGraw-Hill Education.Huang, C. C., Vertinsky, I., Ziemba, W. T., 1977. Sharp bounds on the value of perfect information. Operations Research25 (1), 128–139.Hubbard, D. W., 2014. How to measure anything: Finding the value of intangibles in business. John Wiley & Sons.Keisler, J. M., 2014. Value of information: facilitating targeted information acquisition in decision processes. EnvironmentSystems and Decisions 1 (34), 1–2.Laporte, G., Ouellet, R., 1980. Théorie de la décision. Montreal: Editions Sciences et Culture Inc.Lawrence, D. B., 1999. The economic value of information. New York: Springer.Le, A. H., Tokai, A., Nakakubo, T., 2014. Applying value of information methods to prioritize elements for water qualitymanagement with an example of linear alkylbenzene sulfonate in the yodo river, japan. Environment Systems and Decisions34 (1), 110–123.López Cachero, M., 1989. Análisis y adopción de decisiones. Madrid: Pirámide.MacCrimmon, K. R., Larsson, S., 1979. Utility theory: Axioms versus paradoxes. In: Expected utility hypotheses and theAllais paradox. Springer, pp. 333–409.28Machina, M. J., 1987. Choice under uncertainty: Problems solved and unsolved. Journal of Economic Perspectives 1 (1),121–154.Marques, R. C., Berg, S., 2011. Risks, contracts, and private-sector participation in infrastructure. Journal of ConstructionEngineering and Management 137 (11), 925–932.McCullagh, L., Schmitz, S., Barry, M., Walsh, C., 2016. Non-parametric approach to estimating expected value of perfectinformation: The usefulness of this approach to a national hta agency. Value in Health 19 (7), A489.Mehrez, A., 1985a. The effect of risk aversion on the expected value of perfect information. Operations research 33 (2), 455–458.Mehrez, A., 1985b. A note on the analysis of the expected value of perfect information with respect to a class of r&d projects.European journal of operational research 19 (2), 217–221.Meza, F. J., Wilks, D. S., Riha, S. J., Stedinger, J. R., 2003. Value of perfect forecasts of sea surface temperature anomaliesfor selected rain-fed agricultural locations of chile. Agricultural and Forest Meteorology 116 (3), 117–135.Robert, C., 2001. The Bayesian choice: from decision-theoretic foundations to computational implementation. Springer.Samson, D., Wirth, A., Rickard, J., 1989. The value of information from multiple sources of uncertainty in decision analysis.European journal of operational research 39 (3), 254–260.Schlee, E. E., 1991. The value of perfect information in nonlinear utility theory. Theory and Decision 30 (2), 127–131.Szaniawski, K., 1967. The value of perfect information. Synthese 17 (4), 408–424.Thon, D., Thorlund-Petersen, L., 1993. The value of perfect information in a simple investment problem. Information Economicsand Policy 5 (1), 51–71.Wakker, P., 1988. Nonexpected utility as aversion of information. Journal of Behavioral Decision Making 1 (3), 169–175.Wang, J., Chaudhury, A., Rao, H. R., 2008. Research notea value-at-risk approach to information security investment. Infor-mation Systems Research 19 (1), 106–120.Welton, N. J., Madan, J., Ades, A. E., 2011. Are head-to-head trials of biologics needed? the role of value of informationmethods in arthritis research. Rheumatology 50 (suppl 4), iv19–iv25.Zhang, L., Qi, R., Poole, D., 1993. Incremental computation of the value of perfect information in stepwise-decomposableinfluence diagrams. In: Proceedings of the Ninth international conference on Uncertainty in artificial intelligence. MorganKaufmann Publishers Inc., pp. 400–407.29
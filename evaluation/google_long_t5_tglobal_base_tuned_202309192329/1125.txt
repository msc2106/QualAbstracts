ABSTRACT: 
When performing data linkage, survey respondents need to provide their informed consent. Since not all respondents agree to this request, the linked data-set will have fewer observations than the survey data-set alone and bias may be introduced. By focusing on the role that survey design features play in gaining respondents’ consent, this paper provides an innovative contribution to the studies in this field. Analysing experimental data collected in a nationally representative household panel survey of the British population, we find that interview features such as question format (dependent/independent questions) and placement of the consent question within the questionnaire have an impact on consent rates. 
 
PREDICTION: 
When performing data linkage, survey respondents need to provide their informed consent. Since not all respondents agree to this request, the linked data set will have fewer observations than the survey data set alone and bias may be introduced. By focusing on the role that survey design features play in gaining respondents' consent, this paper provides an innovative contribution to the studies in this field. Analysing experimental data collected in a nationally representative household panel survey of the British population, we find that interview features such as question format (dependent/independent questions) and placement of the consent question within the questionnaire have an impact on consent rates. 
 
FULL TEXT: 
 This article was downloaded by: [90.244.59.38]On: 10 June 2014, At: 00:36Publisher: RoutledgeInforma Ltd Registered in England and Wales Registered Number: 1072954 Registeredoffice: Mortimer House, 37-41 Mortimer Street, London W1T 3JH, UKInternational Journal of SocialResearch MethodologyPublication details, including instructions for authors andsubscription information:http://www.tandfonline.com/loi/tsrm20Propensity to consent to data linkage:experimental evidence on the role ofthree survey design features in a UKlongitudinal panelEmanuela Salaa, Gundi Kniesb & Jonathan Burtonba Department of Sociology and Social Research, Università diMilano-Bicocca, Milan, Italyb Institute for Social and Economic Research, University of Essex,Colchester, EssexPublished online: 03 Apr 2014.To cite this article: Emanuela Sala, Gundi Knies & Jonathan Burton (2014) Propensity to consentto data linkage: experimental evidence on the role of three survey design features in a UKlongitudinal panel, International Journal of Social Research Methodology, 17:5, 455-473, DOI:10.1080/13645579.2014.899101To link to this article: http://dx.doi.org/10.1080/13645579.2014.899101PLEASE SCROLL DOWN FOR ARTICLETaylor & Francis makes every effort to ensure the accuracy of all the information (the“Content”) contained in the publications on our platform. Taylor & Francis, our agents,and our licensors make no representations or warranties whatsoever as to the accuracy,completeness, or suitability for any purpose of the Content. Versions of publishedTaylor & Francis and Routledge Open articles and Taylor & Francis and Routledge OpenSelect articles posted to institutional or subject repositories or any other third-partywebsite are without warranty from Taylor & Francis of any kind, either expressedor implied, including, but not limited to, warranties of merchantability, fitness for aparticular purpose, or non-infringement. Any opinions and views expressed in this articleare the opinions and views of the authors, and are not the views of or endorsed byTaylor & Francis. The accuracy of the Content should not be relied upon and should beindependently verified with primary sources of information. Taylor & Francis shall not beliable for any losses, actions, claims, proceedings, demands, costs, expenses, damages,and other liabilities whatsoever or howsoever caused arising directly or indirectly inconnection with, in relation to or arising out of the use of the Content. This article may be used for research, teaching, and private study purposes. Terms &Conditions of access and use can be found at http://www.tandfonline.com/page/terms-and-conditions It is essential that you check the license status of any given Open and OpenSelect article to confirm conditions of access and use.Downloaded by [90.244.59.38] at 00:36 10 June 2014 Propensity to consent to data linkage: experimental evidence onthe role of three survey design features in a UK longitudinal panelEmanuela Salaa*, Gundi Kniesb and Jonathan BurtonbaDepartment of Sociology and Social Research, Università di Milano-Bicocca, Milan, Italy;bInstitute for Social and Economic Research, University of Essex, Colchester, Essex(Received 24 August 2013; accepted 25 February 2014)When performing data linkage, survey respondents need to provide theirinformed consent. Since not all respondents agree to this request, the linkeddata-set will have fewer observations than the survey data-set alone and biasmay be introduced. By focusing on the role that survey design features play ingaining respondents’ consent, this paper provides an innovative contribution tothe studies in this ﬁeld. Analysing experimental data collected in a nationallyrepresentative household panel survey of the British population, we ﬁnd thatinterview features such as question format (dependent/independent questions)and placement of the consent question within the questionnaire have an impacton consent rates.Keywords: data linkage; asking for consent; experiments; dependentinterviewing; context effects; longitudinal studies; Innovation Panel1. IntroductionLinkage of person-based administrative data to survey data is becoming increasinglypopular as it has the potential to overcome some of the main challenges currentlyfacing survey practitioners, e.g. reducing survey costs and easing respondent andinterviewer burden. However, successful implementation of data linkage betweensurvey data and person-based administrative data is a complex process.One of the main hurdles in realising the full potential of linked survey andadministrative data is the requirement, common to many countries, that surveyrespondents give their informed consent before the survey organisation can share therespondent’s personal information with the custodians of the administrative data forthem (or a third party) to identify the survey respondent’s record and to send the au-thorised information back to the survey team. In order to be valid, the decision toconsent or not consent must be made by the respondent alone and there must not beany coercion. The respondent must be given full information about what their deci-sion involves, including the beneﬁts and risks, and they must have the capacity tounderstand the information provided to them. Since not all respondents agree to thisrequest, the linked data-set will have fewer observations than the survey data-set alone and bias may be introduced if those who consent differ in some systematicway from those who do not consent. Moreover, consent to data linkage is only askedconditional on the initial agreement of the sample member to participate in the*Corresponding author. Email: emanuela.sala@unimib.it© 2014 The Author(s). Published by Routledge.This is an open-access article distributed under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/3.0/, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properlycited. The moral rights of the named author(s) have been asserted.International Journal of Social Research Methodology, 2014Vol. 17, No. 5, 455–473, http://dx.doi.org/10.1080/13645579.2014.899101Downloaded by [90.244.59.38] at 00:36 10 June 2014 survey. Thus, where the same characteristics are associated with both surveyresponse and consent, the bias introduced between consenters and survey non-responders will be increased.The task of obtaining survey participation may be seen as different to the task ofeliciting consent. The former may require the interviewer to use their skills of per-suasion and potentially conversion, the latter task is more rooted to the standardisedinterviewing model where the interviewer reads out the request as written and is notencouraged to actively inﬂuence the respondent. In addition, the interviewer is ﬁnan-cially incentivised to obtain a survey interview, but is not incentivised to get a con-sent to data linkage (Sakshaug, Couper, Ofstedal, & Weir, 2012).A number of empirical studies have examined consent rates and consent biaswith respect to respondent and interviewer characteristics. By contrast, there is asyet very little methodological research on how the design of the questionnaire instru-ment may assist in achieving higher consent rates and help attenuate potential con-sent bias. Survey design decisions such as where to position the consent question inthe questionnaire or how to word the consent question are often based on practicaland operational considerations rather than on sound empirical evidence. The knowl-edge gap is particularly marked in the context of longitudinal studies where a num-ber of additional design decisions arise. For example, in which wave of the surveyshould respondents be asked the consent question? How can respondents be reaskedor reminded of any consent they have given in the past in an ethical way but withoutjeopardising the quality and quantity of linked data?This study contributes to signiﬁcantly enhance the current knowledge about howto ask for informed consent to data linkage by reporting empirical evidence fromrandom treatment-control experiments on the performance of some important surveydesign options, many of which pertain speciﬁcally to longitudinal studies. Weanalyse experimental data collected in a nationally representative household panelsurvey for Great Britain, the Innovation Panel (IP) of the UK Household Longitudi-nal Study (UKHLS), which allow us to investigate empirically the trade-off betweenasking early on in the life of a panel and holding back the request until more rapporthas been built and to examine the effect of implementing different design optionsfor conﬁrming (or reasking) consent. Moreover, we provide further empirical evi-dence on the effect of the question ordering and provide a deeper understanding ofthe reasons why people give or withhold consent. Section 4, below, gives moreinformation about the IP.The ﬁndings suggest that interview features such as question wording and place-ment of the consent question within the questionnaire have an impact on consentrates. We also ﬁnd evidence that suggests that speciﬁc interviewer training and care-fully drafted question wording may help alleviate concerns about data linkage andtherefore have a positive effect on consent rates. The study also provides practicalguidance to survey methodologists and survey agencies on the implementation ofeliciting consent to data linkage.2. Linking administrative data to survey data. What are the drivers ofconsent?Much of the survey research on data linkage has focused on identifying the corre-lates of respondents’ propensity to consent.1 In a nutshell, studies that have exam-ined which respondent characteristics are associated with consent have typically456 E. Sala et al.Downloaded by [90.244.59.38] at 00:36 10 June 2014 found some association with socio-demographic and socio-economic characteristics,but there were no consistent drivers of consent across studies. The only exception iswith commonly accepted markers of survey cooperation, altruism and trust. Theseare associated with a greater propensity to consent across studies (for a review seeKorbmacher & Schroeder, 2013; Sala, Burton, & Knies, 2012).Moreover, while a number of studies have found interviewer effects, when spe-ciﬁc interviewer characteristics were considered in multivariate models, few of themwere associated with consent (Fulton, 2012; Korbmacher & Schroeder, 2013;Sakshaug et al., 2012; Sala et al., 2012). There was little agreement in ﬁndingsacross studies, albeit the evidence base in this ﬁeld is very small. As Fulton (2012)notes, ‘ﬁndings are inconsistent, and sometimes in opposing directions’. Korbmacherand Schroeder (2013) ﬁnd that the interviewers’ age, experience and performancematter whereas Sala et al. (2012), testing a similar range of characteristics, ﬁnd thatthe interviewers’ task-speciﬁc experience is associated with consent but not theirexperience more generally. Fulton (2012), using the US National Immunization Sur-vey, ﬁnds that increased experience on the survey is associated with lower consentrates. A similar ﬁnding is reported in analysis of the Survey of Health Insurance andProgram Participation where interviewers with greater experience had lower consentrates than those with average levels of experience (Pascale, 2011). Sakshaug et al.(2012) also ﬁnd no evidence for interviewer demographic effects. A consistent ﬁnd-ing across the studies investigating interviewer effects is that there is no empiricalsupport for the hypothesis that interviewer attitudes and personality matter. This istrue both when we look at interviewer personality traits and attitudes to persuadingrespondents more generally (see, e.g. Sala et al., 2012) and also when consideringtheir more speciﬁc attitude to consent to data linkage: Sakshaug, Tutz, and Kreuter(2013) ﬁnd no difference in obtaining consent between interviewers who wouldthemselves consent to data linkage and those who would be reluctant to consent.The main focus of the present study lies in examining whether design and imple-mentation of the consent instrument affect consent rates. Although much understud-ied, a number of studies have considered the association between interview featuresand consent. For example, Jenkins, Lynn, Jäckle, and Sala (2008) ﬁnd that thelength of the interview (interpreted as a proxy for interviewer-respondent rapport)and the level of understanding of survey questions are predictors of consent. Salaet al. (2012) ﬁnd that survey ‘ﬁdelity’, the interview sequence and the number ofconsents that have already been given by other household members are related toconsent. To our knowledge, there is only one study which considers speciﬁc designfeatures of the consent instrument on the consent rate. Sakshaug et al. (2013) ﬁndthat the consent rate was 9.6% points higher among those who were asked for con-sent at the start of a telephone interview compared to those who were asked at theend. The study also ﬁnds no effect on consent rates of mentioning data linkage as aroute to reduce the burden on the respondent.3. Research hypothesesWhen talking about interview features, we will refer, more speciﬁcally, to threeaspects which are relevant to the case of data linkage, especially when it is per-formed in a longitudinal context: the location of the consent question in the ques-tionnaire, the time in the life of the panel when the consent question is asked andInternational Journal of Social Research Methodology 457Downloaded by [90.244.59.38] at 00:36 10 June 2014 the type of question that is used to phrase the consent question. We consider eachaspect as a distinct line of enquiry in our research and expand on them in thesubsections below.3.1. The placement of the consent questionResearch has shown that responses to survey questions may be inﬂuenced by priorquestions (McClendon & O’Brien, 1988; Schuman & Presser, 1981; Tourangeauet al., 2000). A question which causes a respondent to consider a particular subjectmay affect the way that they respond to a subsequent question. This has been foundto occur with general well-being questions (McClendon & O’Brien, 1988) and fearof crime questions (Yang & Hinkle, 2012). The phenomenon has been referred to asthe ‘context effect’ or the ‘question ordering effect’.We aim to investigate whether consent rates vary according to the placement ofthe consent question. As we mentioned in the introduction, survey design decisionsregarding the placement of the consent question are often based on practical andoperational decisions. Where the consent question is accompanied by an informationleaﬂet for the sample member to read, and a form which needs to be signed torecord consent, the consent question is typically asked at the end of the interview soas not to break up the ﬂow of the interview. However, we argue that consent ratesmay be higher when the consent question is asked after a series of questions on asimilar topic (‘in context’) than when the consent question is asked at the end of thequestionnaire. The underlying mechanism is that if the request for consent appearsin context, this makes the request more salient; hence, the respondent will be morelikely to agree to data linkage. Therefore, we test whether asking for consent to linkto administrative data about the receipt of state beneﬁts after a section in the inter-view that asks about these beneﬁts leads to a higher level of consent than asking atthe end of the interview. We hypothesise that having just been asked, and answering,a series of questions about the receipt of a large number of state beneﬁts, the respon-dent will be more likely to consent to linkage to data about those beneﬁts. This maybe because the respondent will want to appear consistent (‘assimilation effect’) orwant to reduce future redundancy and short cut the questionnaire (e.g. ‘If I consentto this, I might not be asked these questions again next year’).3.2. The time in the life of the panel when the consent question is askedIn the case of longitudinal studies, responses to survey questions may be inﬂuencedby a number of factors, including answers to questions administered in previousinterviews (i.e. panel conditioning) and the time in the life of the panel when a spe-ciﬁc question is asked. We intend to explore whether consent rates vary according tothe wave of the panel in which the consent question is asked. Similar to the previousresearch question, studies on this topic are lacking. Our hypothesis is that consentrates are higher for respondents who are interviewed later in the life of a panel.Research has shown that asking for consent to link survey data to administrativedata may be a sensitive topic (Sala et al., 2012); therefore, higher consent rates maybe gained when respondents have developed trust in the survey organisation and areengaged in the survey, i.e. later in the life of the panel.458 E. Sala et al.Downloaded by [90.244.59.38] at 00:36 10 June 2014 3.3. The type of survey questionsResponses to survey questions vary according to the type of question respondentsare administered as well as to the question wording (see, e.g. Belli, Traugott, Young,& McGonagle, 1999; Prohaska, Brown, & Belli, 1998; Schuldt, Konrath, &Schwarz, 2011; Singer et al., 2010; Tourangeau et al., 2000). We aim to investigatewhether consent rates vary by the type of survey question respondents are adminis-tered. This research question is also driven by practical motivations, as ethical guid-ance in many countries requires survey organisations to periodically give samplemembers a chance to change their minds about consent. There are a number of waysthis can be done and different data holders may have different preferences.In a longitudinal context, we may distinguish between dependent and standardindependent questions. Dependent interviewing (DI) is a standardised questioningmethod particular to longitudinal surveys that is widely used on major surveys inter-nationally. It uses data gathered in previous interviews with the respondent to formu-late question text. This practice can be distinguished from the standard independentinterviewing (INDI), which makes no reference to data previously collected tophrase questions or route respondents through questionnaires (Lynn, Jäckle, Jenkins,& Sala, 2006; Mathiowetz & McGonagle, 2000).We hypothesise that overall consent rates to data linkage may vary according tothe type of question respondents are asked. We also argue that responses given in thepast may also play a key role in the mechanisms that lead respondents to consent in alater wave. In particular, we believe that respondents tend to agree with informationthat is fed-forward from previous interviews, regardless of their speciﬁc content. Thishypothesis is driven by two considerations. First, there is evidence that surveyrespondents like to be consistent when they are responding to survey questions(Groves, Cialdini, & Couper, 1992). If they answer in a contradictory way, they mayappear to the interviewer to be indecisive or give the impression that they hadanswered ‘wrongly’ in the past. Thus, by reminding respondents of their previousresponse, they are likely to give the same answer (in our case, a yes or a no to a con-sent question). When respondents are asked the question independently, they have noreminder of their previous answer, and so they are able to make the decision at thetime without worrying about consistency. Second, there is evidence that shows thatDI questions may facilitate the response process and ease respondent burden (Salaet al., 2012). As argued by Tourangeau (1984), the response process is structured infour main steps: (1) understanding the question; (2) retrieving the relevant informa-tion; (3) making a judgment; and (4) selecting a response. In the case of the consentto data linkage question, where respondents need to process difﬁcult information andmake a decision in relatively little time, DI may affect the second and the third step.By reminding the respondent of their previous response, they are given an opportu-nity to short cut this cognitive process by giving them an easy response; to agree withtheir previous answer. This short cut is justiﬁed by the respondent ‘trusting’ their ear-lier thought processes, rather than thinking through the response from the beginning.4. DataWe use data collected in the fourth wave of the IP. The analyses also draw on thelongitudinal nature of the study by including information from previous waves,mainly wave 1.International Journal of Social Research Methodology 459Downloaded by [90.244.59.38] at 00:36 10 June 2014 The IP is a longitudinal household panel study, representative of the populationliving in Great Britain in 2008. Interviews take place annually. The IP is part of theUKHLS, one of the major investments in the social sciences research infrastructurein the UK.2 It is a resource for carrying out innovative longitudinal experimentaland methodological research, such as testing different ﬁeldwork designs (for areview, see Budd et al., 2012). Findings from the IP inform the design of theUKHLS as well as other longitudinal surveys worldwide.The IP sample is a clustered, stratiﬁed and equal probability design of almost1500 households (at wave 1, in 2008). At IP4, a refreshment sample of 960 issuedhouseholds was added to the original sample. The achieved sample at IP4 consistedof 910 households and 1456 adults in the original sample, and 464 households and723 adults in the refreshment sample.The standard IP design, in terms of questionnaire content and sample followingrules, is modelled on the main-stage of the UKHLS. The survey collects a widerange of information including job and education, fertility histories, health condi-tions, personal ﬁnances, social participation and social attitudes.At IP4, eligible adults were interviewed using computer-assisted personal inter-viewing. In addition, there was a self-completion instrument, which for half the sam-ple was administered with a paper questionnaire and for the other half, aquestionnaire carried out using the laptop (Computer Assisted Self Interviewing,CASI). The survey included thirteen experiments, three of which were on consent todata linkage (for a review of the main ﬁndings, see Budd et al., 2012).34.1. Collecting informed consent to data linkage in the IPThe IP offers a valuable opportunity to address some of the outstanding researchquestions around best practices for collecting informed consent, in particular thoseparamount in longitudinal study designs. The decision to seek respondents’ consentto data linkage in the IP was driven by scientiﬁc motivations as well as practicalconsiderations such as the relatively low consent rates to data linkage in the BritishHousehold Panel Survey (BHPS) (Knies, Burton, & Sala, 2012; Sala et al., 2012)and the plans to implement data linkage on the associated UKHLS. To address someof the concerns and the research questions of the IP design team, a detailed plan toask for consent to link respondents’ survey data to a wide range of administrativerecords was developed and a number of experiments were designed and imple-mented over time.The process of asking for consent in the IP is similar to the one implemented inthe BHPS and described in detail in Knies et al. (2012). In summary, there is a briefpreamble to the consent question which informs the respondent that the study wouldlike to add information from speciﬁc (named) administrative records to the responsesgiven in the interview; there is an information leaﬂet which provides further infor-mation on what the data linkage involves, and, in order to give permission, therespondents need to sign a consent form. Consent is asked at the end of the inter-view so that signing the forms and reading the information leaﬂet does not interruptthe ﬂow of the interview. The outcome of the consent question is recorded in CAPIand a copy of the signed consent forms is kept by the respondent and the original iscollected by the survey organisation, reconciled against the data and then sent toISER for secure storage for future reference. The IP4 protocol differs from the460 E. Sala et al.Downloaded by [90.244.59.38] at 00:36 10 June 2014 standard process of collecting informed consent for a number of aspects relating tothe experimental manipulation.Consent to data linkage was collected at a number of different stages. Table 1provides an overview of the implementation of data linkage in the IP together withthe consent rates. IP respondents may revoke their consent anytime after it has beengiven, and there are currently no plans to perform data linkages for consenters.4.2. Experimenting with different ways of asking for consent at IP4To address our research questions, we developed three experiments:4.2.1. Experiment 1. Context effectsIP4 adult respondents (aged 16+) were randomly allocated to two treatment groups4:one group were asked for their consent at the end of the questionnaire (controlgroup, ‘at the end’), the other group were asked for consent after a module of ques-tions which asked about the receipt of state beneﬁts and other payments (treatmentgroup, ‘in context’).4.2.2. Experiment 2. Time in the life panel effectsAt IP1 adult respondents were randomly allocated to two treatment groups: two-thirds of the sample (control group) were asked for consent at IP1; the remainingone-third of the sample were to be asked for consent later in the life of the panel,i.e. at IP4 (treatment group).Unfortunately, there was an error in the implementation of this experiment atIP1. In the ﬁrst two months of ﬁeldwork, all respondents were asked for consent.Table 1. Percentage of the sample agreeing to administrative data linkage on InnovationPanel, waves 1–4.Administrative data typeWave1Wave2Wave3Wave4National Insurance contributions, beneﬁts and tax records,savings and pensionsA56.9a 62.2Education: 4–15-year-oldsB 65.1b 55.6cEducation: 16–24-year-oldsB 69.0b 78.9cHealth: 0–15-year-oldsC 72.6dHealth: 16+-year-oldsC 79.6dNote: Unweighted data.AFrom the Department of Work and Pensions (DWP) and Her Majesty’s Revenue andCustoms (HMRC).BFrom the Department for Children, Schools and Families (DCSF) at IP1, and the English Departmentfor Children, Schools and Families, the Welsh Department for Children, Education, Lifelong Learning,and Skills, the Scottish Government Education Directorate, or the Department of Education/Educationand Skills Authority in Northern Ireland at IP2.CFrom the National Health Service (NHS), Department of Health, General Registration Ofﬁce and theOfﬁce for National Statistics.aExperimental allocation of two-thirds of the sample.bAsked of 16–24-year-olds, plus the responsible adult for children aged 4–15.cFor new entrants or those who had not consented at IP1 and were aged 4–24.dAll responding adults, plus the responsible adult was asked for consent for children aged 0–15.International Journal of Social Research Methodology 461Downloaded by [90.244.59.38] at 00:36 10 June 2014 This was discovered and corrected so that from the start of the third month of IP1ﬁeldwork one-third of respondents were not asked for consent. It is this group whoare being asked ‘later in the life of the panel’, at IP4. Implications for evaluatingExperiment 2 are discussed in the analysis methods section.4.2.3. Experiment 3. Question wording effectsIP4 respondents who had been asked for consent to link to beneﬁt data at IP1 wererandomly allocated to two treatment groups: one group were asked the consent ques-tion independently, i.e. they were not reminded of their previous answer (controlgroup, ‘INDI’), the other group were reminded of their IP1 response and were askedif they were still (un)willing to allow the data linkage (treatment group, ‘DI’). Theallocation to this experiment was done independently of the context effect experi-ment.The wording of the verbal consent question for all experimental groups is pro-vided in Appendix 1. Respondents who gave verbal consent were then asked fortheir written consent in a follow-up question, which was administered at the end ofthe interview including for those asked for consent ‘in context’ (i.e. the treatmentgroup of Experiment 1).5In addition, all respondents were asked a follow-up question on reasons for con-senting or not consenting to data linkage at the end of the interview. Upon theadministration of the follow-up question, the interviewer coded whether or not therespondent had changed their mind. Last, but not least, some sections of the IP4interviews were audio-recorded, including the consent to data linkage question (con-sent to audio-recording: 68.4%).65. Methods of analysisTo address the research questions, we use both bivariate and multivariate logisticregression analysis. The dependent variable is a dummy variable that indicateswhether a respondent has provided verbal consent to perform data linkage: a valueof 1 indicates that consent has been provided and a value of 0 indicates consent waswithheld. The key independent variable is an indicator of the experimental treatmentgroups.In the bivariate analysis, we compare consent rates at the relevant waves, for therelevant respondents and samples. The analysis plan is described in detail in the lastcolumn of Table 2. A standard t-test is used to test for differences in consent rates.In the regression analysis, we include additional control variables such as age, gen-der, employment status, net earnings, number of times the respondent was inter-viewed prior to IP4, a proxy for cognitive skills (the level of understanding of thequestionnaire) and the type of considerations while deciding about data linkage.Due to the implementation error of Experiment 2 in IP1, for a robustness check,we will restrict the IP4 analysis sample to respondents who were interviewed in thelast sample months. Respondents in the IP1 experimental treatment groups may beviewed as those most difﬁcult to get hold of, since it had taken interviewers multiplecontact attempts to interview them successfully, so we will need to compare themwith the most difﬁcult to get hold of respondents in IP4.Results from the bivariate and multivariate analysis consider the complex sam-pling design of the IP: results are weighted for unequal selection probabilities as462 E. Sala et al.Downloaded by [90.244.59.38] at 00:36 10 June 2014 well as non-response. For results drawing on just the IP4 sample (assessment ofExperiment 1, analysis of reasons for consent/non-consent), we use cross-sectionalweights; for results drawing on the continuing IP1 sample (assessment of Experi-ments 2 and 3), we use longitudinal population weights.The analysis is carried out using Stata version 12.1 (StataCorp, 2012). Toaccount for the complex survey design (i.e. clustering, stratiﬁcation, samplingweights), we use the svy suite of commands.6. ResultsTable 3 shows the results of the ﬁrst experiment; the placement in the interview ofthe consent request.We ﬁnd evidence that consent rates vary by the position of the consentquestion: respondents who were asked the consent question ‘in context’ are, onTable 2. Overview of the design of IP4 consent experiments.ExperimentTreatment groupAssessmentControl (C) Treatment (T)Experiment 1.ContexteffectsConsent questionasked at the end ofthe questionnaireConsent questionasked after thebeneﬁt moduleComparisons of consent rates atIP4 between the C and T groupsEligible sample for C: IP4respondents allocated to Cresponding at IP4 (N = 1114)Eligible sample for T: IP4respondents allocated to T,responding at IP4 (N = 1065)The refreshment sample isincluded in the analysisExperiment 2.Time of thelife paneleffectsBeneﬁt consentquestion asked atIP1Beneﬁt consentasked at IP4Comparisons of consent ratebetween the C and T groupsrespectively at IP1 and IP4Eligible sample for C: continuingIP1 respondents in IP4 allocatedto C group responding at IP4 (N= 1096)Eligible sample for T: continuingIP1 respondents in IP4 allocatedto T, responding at IP4 (N = 174)Experiment 3.QuestionwordingeffectsIndependentinterviewingquestion askedDependentinterviewingquestion askedComparisons of consent rates atIP4 between the T and C groups,also broken down by therespondents’ previous answers tothe IP1 consent questionEligible sample for C: IP4respondents allocated to Cresponding at IP4 (N = 510)Eligible sample for T: IP4respondents allocated to Tresponding at IP4 (N = 578)Refreshment sample is excludedfrom the analysisInternational Journal of Social Research Methodology 463Downloaded by [90.244.59.38] at 00:36 10 June 2014 average, 7 percentage points more likely to consent than respondents who areasked for consent at the end of the questionnaire (65% compared to 58%,two-sample t(60) = 2, p = .05). The result is robust also when we absorb furtherpopulation heterogeneity (i.e. when we include in a logistic regression modelcontrols for age, gender, employment status, net earnings, as well as how oftenthe respondent has given an interview (all not statistically signiﬁcant), respondentsuspicion (negative association with consent) and good understanding of thequestionnaire (positive association with consent), but becomes not statisticallysigniﬁcant if we include markers for whether the respondent mentioned anyconcerns or considerations when deciding on whether or not to consent to datalinkage (results reported in Appendix 2).Table 4 reports the result of Experiment 2, which was started in IP1 and con-cluded in IP4. There is some indication that consent varies by the stage in the life ofa panel in which the data linkage question is asked (at least over the four-year periodthat we are looking at). A greater share of continuing IP1 respondents who were ﬁrstasked for consent at IP4 consented to economic record linkage (71%) than was truefor IP1 respondents who were asked at IP1 (60%). The difference is statistically sig-niﬁcant at the 10% level, t(60) = −1.66, p = .10.However, due to the previously mentioned survey implementation error, thegroup in the sample who were being asked later in the life of the panel (i.e. at wave4) are disproportionately made up of those respondents who were interviewed at alater stage of ﬁeldwork at IP1 (i.e. after the ﬁrst two months). Such respondents tendto be more difﬁcult to interview because of their busy schedules or greater reluc-tance to participate. It may well be that this confounds the expected positive effectof rapport because we try to identify this effect among the most difﬁcult to getrespondents who may be the least responsive to such a treatment effect. In supportof the argument, when we exclude from the IP1 sample respondents who were inter-viewed in the ﬁrst two months, and from the continuing IP1 sample those inter-viewed in the ﬁrst month7, we ﬁnd that the consent rate in these groups is overalllower. However, the difference in the consent rate between the two groups isvirtually unchanged; whilst 64% of continuing IP1 respondents who were ﬁrst askedfor consent at IP4 give consent, the ﬁgure amounts to 53% in the group who wereasked for consent at IP1. The difference in means is not statistically signiﬁcant,t(60) = −1.17, p = .25.Table 3. Consent rates for respondents asked in context (treatment group) and asked at theend of the interview (control group), Experiment 1.Consent rate SE95% Conﬁdence intervalNLower bound Upper boundAsked at the end .58 .03 .52 .64 1114Asked in context .65** .02 .60 .69 1065Note: Standard errors adjusted for the complex survey design. Results weighted for unequal selectionprobabilities and non-response. Sample includes all IP4 adult respondents. Differences in experimentalgroup means.**Signiﬁcant at the .05 level.Source: Innovation Panel, waves 1–4, IP4 release.464 E. Sala et al.Downloaded by [90.244.59.38] at 00:36 10 June 2014 Table 5 reports the results of the DI experiment. Non-consenters at IP1 had a 22percentage point higher probability to consent in IP4 if they were not reminded oftheir decision in IP1 (i.e. 46% compared to 24%), t(60) = 3.14, p = .00. Consentersat IP1 had a 26 percentage point higher probability to consent when reminded thatthey had consented to the linkage in IP1, t(60) = −5.86, p = .00. In other words,respondents tend to be consistent with their previous decision when reminded of thatdecision. These results are robust to including further controls in multivariate regres-sion models, see Appendix 3.Table 4. Consent rates for respondents ﬁrst asked at IP1 (control group) and IP4 (treatmentgroup), Experiment 2.Consentrate SE95% Conﬁdence intervalNLowerboundUpperboundExperimental groupsAsked at ﬁrst interview (IP1) .60 .02 .55 .65 1096Asked at the fourth interview(IP4).71* .05 .60 .82 174Excluding ﬁrst sample monthsAsked at ﬁrst interview (IP1) .53 .05 .44 .63 358Asked at the fourth interview(IP4).64 .08 .48 .81 54Base consent ratesIP1 sample in IP1 .57 .02 .53 .61 2073IP4 refreshment sample in IP4 .61 .03 .55 .66 723Note: Standard errors adjusted for the complex survey design. Results weighted for unequal selectionprobabilities and non-response (and attrition). Differences in experimental group means.*Signiﬁcant at the .1 level.Source: Innovation Panel, waves 1–4, IP4 release.Table 5. Consent rates for respondents asked dependently (treatment group) or indepen-dently (control group) at IP1 by IP1 consent status, Experiment 3.Consent rate SE95% Conﬁdence intervalNLower bound Upper boundNon-consenters at IP1Asked IND .46 .06 .35 .57 193Asked DI .24*** .05 .13 .34 219Consenters at IP1Asked IND .68 .04 .59 .76 317Asked DI .94*** .02 .91 .97 359Note: Standard errors adjusted for the complex survey design. Results weighted for unequal selectionprobabilities and non-response (and attrition). Differences in experimental group means.***Signiﬁcant at the .01 level.Source: Innovation Panel, waves 1–4, IP4 release.International Journal of Social Research Methodology 465Downloaded by [90.244.59.38] at 00:36 10 June 2014 6.1. Why do people (withhold) consent to data linkage?To further explore the mechanisms that inﬂuence respondents’ consent, we alsolooked at the reasons they gave after agreeing or disagreeing to data linkage.Respondents were asked about what they considered when they gave their response.The exact question wording was as follows: ‘Different things can be important whendeciding to give consent to add information from DWP administrative records tosurvey data. What were you considering when answering?’ Respondents could namemore than one reason, and the interviewer coded their response to a preset list ofcategories with two ‘other’ categories where the reason was recorded by the inter-viewer verbatim.Graph 1 shows the reasons for agreeing or disagreeing to the data linkagerequest by consent status.A number of ﬁndings clearly stand out. First, a sizable share of the sample(26.2%) did not mention any considerations or concerns they had when making theirdecision and this is not associated with consent status. Second, 32% of the sampleexpressed concerns about sharing conﬁdential data with third parties whilst a similarproportion mentioned that they considered being ‘helpful’ with research. Third, asone may expect, there are signiﬁcant differences in the nature of the considerationsexpressed by consenters and non-consenters (p < .01). For example, 58% of non-consenters expressed concerns regarding sharing of conﬁdential data compared to15% of those who consented, and 49% of consenters wanted to be helpful comparedto 6% of non-consenters.It is worth noting that just over one in six people who consented still had con-cerns about conﬁdentiality. Fourth, when focusing on the reasons mentioned by con-senters, just under one in ten of those who gave consent (9.1%) said they consideredtheir trust in the ﬁeldwork agency or survey organisation, whereas 6.3% mentionedit was because they clearly understood why and how the linkage would take place,compared to 1.9% of those who declined to consent. This demonstrates the impor-tance that the reasons why linking survey responses to administrative data helps0% 10% 20% 30% 40% 50% 60%No considerations/concerns mentionedOther considerations: positiveOther considerations: negativeConcerns about sharing of confidential dataTrust in survey/fieldwork agencyInfluenced by othersFeeling of "duty" as a respondentHaving a clear understanding of whyBeing helpful with the researchAllConsentersNon-consentersGraph 1. Reasons for agreeing or disagreeing to data linkage by consent status.Source: Innovation Panel, wave 4. All results consider the complex survey design and areweighted.466 E. Sala et al.Downloaded by [90.244.59.38] at 00:36 10 June 2014 research, and the process by which the information is linked, are available to therespondent. Their ‘duty’ as a respondent was mentioned as a consideration by 5% ofthose who gave consent whilst this aspect was considered by only 1.2% of the non-consenters. Note that some proportion of non-consenters and consenters mentionedother reasons than those anticipated by the research team based on the literature onsurvey participation and consent, both positive (4%) and negative (6.8%).7. ConclusionsData linkage is an increasingly popular survey feature; decisions regarding its imple-mentation, however, are seldom based on empirical evidence. Very few guidelinesand shared practices have been produced on how to best implement this complexprocess, especially in a longitudinal context. For example, we still do not knowwhere to locate the consent question in a questionnaire to maximise consent ratesand reduce bias. One of the reasons for this lack of knowledge lies in the scarcity ofexperimental data available.This research sets out to evaluate the role that a number of interview featuresplay in the consent process drawing on a unique set of experiments carried out inthe framework of a national panel study of the British population; the IP. Wefocused on three aspects of the consent process; the location of the consent questionwithin the questionnaire, the time in the life of the panel in which the consent ques-tion should be asked and the question wording of the consent question. These aresome of the key issues that survey designers have to face while implementing datalinkage. We also collected additional non-experimental information from consentersand non-consenters on reasons for consent.A number of ﬁndings clearly stand out from our analysis. First, drawing on thecontextual explanation, we hypothesised that consent rates may vary by the positionof the consent question within the questionnaire. In particular, we state that whenthe consent question to link survey data to economic records is asked after a seriesof questions on beneﬁt receipts (i.e. a context where the request is salient), consentrates may be higher. This hypothesis ﬁnds some support in the empirical data. Whenasked ‘in context’ consent rates are 7% point higher than when the consent questionis asked at the end of the questionnaire (signiﬁcant at the .1 level).However, one may argue that this ﬁnding is also consistent with the ‘survey fati-gue’ explanation. Towards the end of the questionnaire, the respondent may want tohurry the interview along because of the length of the questionnaire. They maytherefore be less inclined to spend time reading an information leaﬂet and consentform and giving the matter their full consideration. Unfortunately, we cannot disen-tangle this explanation from the contextual explanation since in our treatment groupthe beneﬁts module always appeared at the same place in each interview. If our ﬁnd-ing is conﬁrmed by other similar studies, it may be advisable to ask for consent in arelevant context rather than at the end. In our study, we focussed on consent to datalinkage to beneﬁt records. Further research should investigate, for example, whetherthe relationship between consent rates and the location of the consent question holdswhen looking at other domains (e.g. health or education) and should further explorethe mechanisms in place. Experiments with manipulations of the relevant question-naire section may be designed to contribute to an understanding of the reasons thatlead respondents to consent when the request to data linkage is asked in a relevantcontext.International Journal of Social Research Methodology 467Downloaded by [90.244.59.38] at 00:36 10 June 2014 Second, we intended to test whether consent rates varied by the wave in whichthe request to consent to data linkage is asked. Comparing consent rates obtained atwave 1 to those obtained later in the life of the panel, i.e. wave 4, we ﬁnd someindication that consent rates may be higher when asked later in the life of the panel.The implications of this ﬁnding are not straightforward as pros and cons are associ-ated with the decision to ask for consent at the ﬁrst wave or at a later wave in thelife of the panel. Despite the increased consent rate elicited when asking for consentat a later stage in the life of a panel study, it may be advisable to ask for consent asearly in the life of the panel as is possible when the larger sample size (before attri-tion) results in more individuals giving consent, compared to a higher consent ratefurther into the life of a panel when attrition has reduced the sample. This is at leasttrue as long as asking for consent does not have an impact on attrition. In our case,we did not ﬁnd that being asked the consent question in wave 1 inﬂuenced participa-tion in wave 4 (N = 2399, b-coefﬁcient −.035, SE = .117). There has, however, beena sizable rate of attrition with only about 50% of interviewees at IP1 being re-inter-viewed in IP4. We believe that a possible strategy for maximising the number oflinked data would be to ask at the ﬁrst wave and then to reask those who did notgive consent at a later wave. As with our ﬁrst experiment, further research is neededbefore clear guidelines on this issue could be provided. The main limitation of thestudy is the implementation error at IP1 that may weaken the impact of our ﬁndings.Such errors are likely to occur when the data collection is commissioned to thirdparties and researchers have little control on how, in practice, the experiment isimplemented and carried out. To minimise the occurrence of such errors, one mayevaluate the introduction of particular norms in the contract that regulate this aspect.Third, we evaluated whether the question wording, i.e. dependent and indepen-dent questions, has an effect on consent rates. When previous consenters and non-consenters are administered the DI question, we ﬁnd the highest and the lowest con-sent rates, 94% and 24%, respectively. This suggests that respondents tend to beconsistent with their previous answers when answering survey questions. We canspeculate, in accordance with ﬁndings from other studies (Sala et al., 2011), that DImay facilitate the response process. The results from this experiment lead us to for-mulate the following recommendation. When having to recollect consent to datalinkage, we have shown that reminding people of their earlier decisions promptsthem to make the same decision. Thus, to maximise the number of people for whomconsent is retained, a strategy would be to remind those who had previously givenconsent whilst those who have not given consent in the past are asked an indepen-dent question. This strategy may not always be implemented as different ethicalcommittees may have different requirements and they may not necessary agree withthe suggested recommendation.Last but not least, when looking at reasons for agreeing or disagreeing to datalinkage, two important ﬁndings stand out. First, the results suggest that higher con-sent rates may be achieved if the consent question wording highlights, for example,the research potential that data linkage opens up. Second, if interviewers are able toreassure respondents, concerns about conﬁdentiality need not lead to a refusal toconsent. Concerns about conﬁdentiality are the main reason given by those whowithhold consent. Thus, improving messages about data security may be importantin easing these concerns. Overall, these ﬁndings demonstrate the importance that thereasons why linking survey responses to administrative data helps research, and theprocess by which the information is linked, are available to the respondent. An468 E. Sala et al.Downloaded by [90.244.59.38] at 00:36 10 June 2014 effective interviewer training programme, with a focus on how to deal with majorconcerns on data security, may contribute to increase consent rates.AcknowledgementsWe are grateful to Peter Lynn and participants of the 2012 Panel Survey Methods Workshopand the ESRA 2013 conference for their comments on a preliminary version of this manu-script.Notes1. A small number of studies have taken the survey methodological work somewhat further.Jenkins et al. (2008) have examined the performance of different matching criteria;Sakshaug and Kreuter (2012) and McKay (2012) analyse selectivity in linked data.2. More details on the UKHLS can be found at https://www.understandingsociety.ac.uk/.3. Further information on the IP, including the questionnaire, can be found at https://www.understandingsociety.ac.uk/about/innovation-panel.4. In practice, all random allocations were at the household level, and all adults within ahousehold were in the same experimental treatment group.5. Overall, 3.9% of all IP4 respondents who provided verbal consent did not provide writ-ten consent. Respondents who had given consent at IP1, were dependently asked at IP4and conﬁrmed their consent were not asked to sign a consent form (again).6. Data from the audio recordings are currently prepared for analysis under the project‘Understanding non-response on Understanding Society’, funded by the NCRM.7. Very few interviews on IP4 took place outside the ﬁrst month of ﬁeldwork; excludingthe ﬁrst two months of IP4 would leave less than 10 respondents to evaluate the experi-ment.Notes on contributorsEmanuela Sala is tenured lecturer at the Department of Sociology and Social Research of theUniversity of Milano Bicocca (Italy) and research associate of the Institute for Social andEconomic Research of the University of Essex (UK). She has published several papers ondifferent methodological aspects of longitudinal surveys (i.e. data collection and measurementerror) and their relationship with data quality.Gundi Knies is a research fellow at the Institute for Social and Economic Research at theUniversity of Essex, UK. She is a member of the Understanding Society study team andoverlooking health and economic record linkages in the study. She has published on issuesaround consent to data linkage, and her substantive research interests lie in subjective well-being, neighbourhood effects and income distribution research.Jon Burton is a senior research fellow at the Institute for Social and Economic Research atthe University of Essex, UK. He is also the survey manager of Understanding Society: TheUK Household Longitudinal Study. He has published papers on survey methodological issuessuch as non-response, mixed-modes and consent to data linkage.ReferencesBelli, R. F., Traugott, M. W., Young, M., & McGonagle, K. A. (1999). Reducing vote overre-porting in surveys: Social desirability, memory failure, and source monitoring. PublicOpinion Quarterly, 63, 90–108.Budd, S., Gilbert, E., Burton, J., Jäckle, A., Kaminska, O., Uhrig, S. C. N., Brown, M., &Calderwood, L. (2012). Understanding society innovation panel wave 4: Results frommethodological experiments. Understanding society working paper series no. 2012 - 06.Colchester: University of Essex.International Journal of Social Research Methodology 469Downloaded by [90.244.59.38] at 00:36 10 June 2014 Fulton, J. A. (2012). Respondent consent to use administrative data (Unpublished PhDthesis). University of Maryland. http://hdl.handle.net/1903/13601Groves, R. M., Cialdini, R. B., & Couper, M. P. (1992). Understanding the decision to partic-ipate in a survey. Public Opinion Quarterly, 56, 475–495.Jenkins, S. P., Lynn, P., Jäckle, A., & Sala, E. (2008). The feasibility of linking householdsurvey and administrative record data: New evidence from Britain. International Journalof Social Research Methodology, 11, 29–43.Knies, G., Burton, J., & Sala, E. (2012). Consenting to health record linkage: Evidence froma multi-purpose longitudinal survey of a general population. BMC Health ServicesResearch, 12, 52.Korbmacher, J. M., & Schroeder, M. (2013). Consent when linking survey data with admin-istrative records: The role of the interviewer. Survey Research Methods, 7, 115–131.Lynn, P., Jäckle, A., Jenkins, S. P., & Sala, E. (2006). The effects of dependent interviewingon responses to questions on income sources. Journal of Ofﬁcial Statistics, 22, 357–384.Mathiowetz, N., & McGonagle, A. (2000). An assessment of the current state of dependentinterviewing in household surveys. Journal of Ofﬁcial Statistics, 16, 401–418.McClendon, M. J., & O’Brien, D. J. (1988). Question-order effects on the determinants ofsubjective well-being. Public Opinion Quarterly, 52, 351–364.McKay, S. (2012). Evaluating approaches to family resources survey data linking. DWPworking paper, no 110. London: Department for Work and Pensions.Pascale, J. (2011). Requesting consent to link survey data to administrative records: Resultsfrom a split-sample ballot experiment in the survey of health insurance and programparticipation (SHIPP). U.S. Census Bureau Survey Methodology Study Series; 2011-03.Prohaska, V., Brown, N. R., & Belli, R. (1998). Forward telescoping: The question matters.Memory, 6, 455–465.Sakshaug, J. W., Couper, M. P., Ofstedal, M. B., & Weir, D. (2012). Linking survey andadministrative records: Mechanisms of consent. Sociological Methods and Research, 41,535–569.Sakshaug, J. W., & Kreuter, F. (2012). Assessing the magnitude of non-consent biases inlinked survey and administrative data. Survey Research Methods, 6, 113–122.Sakshaug, J. W., Tutz, V., & Kreuter, F. (2013). Placement, wording and interviewers: Identi-fying correlates of consent to link survey and administrative data. Survey Research Meth-ods, 7, 33–144.Sala, E., Burton, J., & Knies, G. (2012) Correlates of obtaining informed consent to datalinkage. Respondent, interview, and interviewer characteristics. Sociological MethodsResearch, 41, 414–439.Sala, E., Uhrig, N., & Lynn, P. (2011). It is time computers do clever things! The impact ofdependent interviewing on interviewer burden. Field Methods, 23, 3–23.Schuldt, J. P., Konrath, S. H., & Schwarz, N. (2011). ‘Global warming’ or ‘climate change’?Whether the planet is warming depends on question wording. Public Opinion Quarterly,75, 115–124.Schuman, H., & Presser, S. (1981). Questions and answers in attitude surveys: Experimentson question form, wording, and context. New York, NY: Academic Press.Singer, E., Couper, M. P., Raghunathan, T. E., Antonucci, T. C., Burmeister, M., & VanHoewyk, J. (2010). The effect of question framing and response options on therelationship between racial attitudes and beliefs about genes as causes of behavior. PublicOpinion Quarterly, 74, 460–476.StataCorp. (2012). Statistical Software: Release 12.1. College Station, TX: Stata Corporation.Tourangeau, R. (1984). Cognitive science and survey methods: A cognitive perspective. In T.Jabine, M. Straf, J. Tanur, & R. Tourangeau (Eds.), Cognitive aspects of survey methodol-ogy: Building a bridge between disciplines (pp. 73–100). Washington, DC: NationalAcademy Press.Tourangeau, R., Rips, L. J., & Rasinski, K. (2000). The psychology of survey response.Cambridge: Cambridge University Press.Yang, S., & Hinkle, J. C. (2012). Issues in survey design: Using surveys of victimization andfear of crime as examples. In L. Gideon (Ed.), Handbook of survey methodology for thesocial sciences (pp. 443–461). New York, NY: Springer.470 E. Sala et al.Downloaded by [90.244.59.38] at 00:36 10 June 2014 Appendix 1. Consent question wording for experimental treatment groupsIndependent question Dependent questionGaveconsentat IP1Finally, we would like to addinformation on your NationalInsurance contributions, beneﬁts andtaxes, savings and pensions fromadministrative records held by theDWP to your survey responses. Areyou happy for us to do so?Finally, we would like to addinformation on your NationalInsurance contributions, beneﬁts andtaxes, savings and pensions fromadministrative records held by theDWP to your survey responses.According to our records, when weinterviewed you in 2008, you gave uspermission to do so. Are you stillhappy for us to do so?Did notgiveconsentat IP1Finally, we would like to addinformation on your NationalInsurance contributions, beneﬁts andtaxes, savings and pensions fromadministrative records held by theDWP to your survey responses.According to our records, when weinterviewed you in 2008, you declinedthat we do this. Are you willing togive your consent now?Not askedforconsentat IP1Not applicableInternational Journal of Social Research Methodology 471Downloaded by [90.244.59.38] at 00:36 10 June 2014 Appendix2.Logisticregressionofconsentondemographiccharacteristics,andsomeinterviewfeaturesModel1Model2Model3Model4Model5Coeff.SECoeff.SECoeff.SECoeff.SECoeff.SEAskedforconsentincontext.26†.13.27*.13.27*.13.32*.14.26.15Age−.01.01−.01.02−.02.02.00.02Agesquared.00.00.00.00.00.00−.00.00Female−.04.10−.03.10−.06.11−.08.13Employmentstatus(comparisongroup:employed)Self-employed−.22.42−.19.42−.19.58Unemployed.11.40.08.40−.45.57Pensioner−.04.39−.10.40−.07.53Other−.20.33−.18.35−.38.49Usualmonthlynetearnings(in£)−.01.03−.01.03−.01.04Numberoftimesinterviewed−.00.06−.05.07Respondentwassuspicious−2.39*.23−1.74*.23Goodunderstandingofquestionnaire1.03*.251.26*.32ConsiderationsindecisionabouttodatalinkageBeinghelpfulwiththeresearch1.96*.27Clarityoverwhatisrequested.77.62Dutyasarespondent−.03.57Inﬂuencedbyotherhouseholdmember−.96.89Trustinthesurveyagency1.51*.43Concernsoverdatasharing−1.60*.21Othernegativeconsideration−.80 *.28Otherpositiveconsideration.33.39Constant.34 *.12.88*.37.98*.44.42.54−.15.68Numberofobservations21572157215721572157Note:Standarderrorsadjustedforthecomplexsurveydesign.Resultsweightedforunequalselectionprobabilitiesandnon-response.SampleincludesallIP4adultrespondents.*Signiﬁcantat.05level.†Signiﬁcantat.1level.Source:InnovationPanel,waves1–4,IP4release.472 E. Sala et al.Downloaded by [90.244.59.38] at 00:36 10 June 2014 Appendix3.Logisticregressionofaskingforconsentdependentlyondemographiccharacteristics(N=1091)Model1Model2Model3Model4Model5Coeff.SECoeff.SECoeff.SECoeff.SECoeff.SEIP1consentXINDI(Non-consentersaskedINDI)ConsentersaskedINDI.88*.29.85*.28.86*.28.80*.28.63†.34Non-consentersaskedDI−1.03*.34−1.08*.33−1.21*.32−1.08*.32−1.07*.38ConsentersaskedDI2.91*.322.86*.322.88*.322.95*.342.55*.42Age−.04.05−.03.05−.07†.04−.02.04Agesquared.00.00−.00.00.00.00−.00.00Female−.03.17−.07.16−.20.17−.42*.20Employmentstatus(employed)Self-employed−.341.05−.501.22−1.461.48Unemployed1.081.07.681.18.501.40Pensioner.85.97.551.15.331.42Other−.40.91−.371.15−.821.45Usualmonthlynetearnings(in£)−.00.08−.01.09−.03.12Numberoftimesinterviewed.03.23−.02.24Respondentwassuspicious−3.37*.70−2.72*.70Goodunderstandingofq’aire1.78*.531.73*.57ConsiderationsabouttolinkageBeinghelpfulwiththeresearch1.69*.42Clarityoverwhatisrequested.25.63Dutyasarespondent15.08*.73Inﬂuencedbyotherhouseholdmember−18.95*1.42Trustinthesurveyagency2.47*.62Concernsoverdatasharing−1.95*.32Othernegativeconsideration−.86.56Otherpositiveconsideration.03.51Constant−.13.231.071.211.121.28.751.45.511.44Note:Standarderrorsadjustedforthecomplexsurveydesign.Resultsweightedforunequalselectionprobabilitiesandnon-response.SampleincludesallIP4adultrespondents.*Signiﬁcantat.05level.†Signiﬁcantat.1level.Source:InnovationPanel,waves1–4,IP4release.International Journal of Social Research Methodology 473Downloaded by [90.244.59.38] at 00:36 10 June 2014 
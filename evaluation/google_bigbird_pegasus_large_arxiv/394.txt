ABSTRACT: 
Ethical disputes arise over differences in the content of the ethical beliefs people hold on either side of an issue. One person may believe that it is wrong to have an abortion for financial reasons, whereas another may believe it to be permissible. But, the magnitude and difficulty of such disputes may also depend on other properties of the ethical beliefs in question-in particular, how objective they are perceived to be. As a psychological property of moral belief, objectivity is relatively unexplored, and we argue that it merits more attention. We review recent psychological evidence which demonstrates that individuals differ in the extent to which they perceive ethical beliefs to be objective, that some ethical beliefs are perceived to be more objective than others, and that both these sources of variance are somewhat systematic. This evidence also shows that differences in perceptions of objectivity underpin quite different psychological reactions to ethical disagreement. Apart from reviewing this evidence, our aim in this paper is to draw attention to unanswered psychological questions about moral objectivity, and to discuss the relevance of moral objectivity to two issues of public policy. 
 
PREDICTION: 
this short note concerns the semantics of the following question : in the title of this paper , we investigate the appropriateness of the following statement : in the first section , we state that in the course of our investigation , we have found that the following statement has been misleading : in the first section , we have found that in the course of our investigation , the following statement has been misleading : in the first section , we have found that in the course of our investigation , the following  moral '' property of a person is not a property of the universe . in the second section , we state that in the course of our investigation , we have found that in the first section , the following  moral '' property of a person is not a property of the universe . in the third section , we state that in the course of our investigation , we have found that in the first section , the following  moral '' property of a person is not a property of the universe . 
 
FULL TEXT: 
  Keywords Public Policy, Objectivity, Ethical Beliefs Comments Suggested Citation: G.P. Goodwin and J.M. Darley. (2009). "The Perceived Objectivity of Ethical Beliefs: Psychological Findings and Implications for Public Policy." Review of Philosophy and Psychology. Vol. 1(2). pp. 161-188. The final publication is available at www.springerlink.com. http://dx.doi.org/10.1007/s13164-009-0013-4 This journal article is available at ScholarlyCommons: https://repository.upenn.edu/neuroethics_pubs/59 Rev. Phil. Psych.DOI 10,1007/513164-009-0013-4The Perceived Oqjectivity of Ethical Beliefs:Psychological Findings and Implicationsfor Public PolicyGeoffrey P. Goodwin & John M. DarleyAbstract Ethical disputes arise over differences in the content of the ethical beliefspeople hold on either side of an issue. One person may believe that it is wrong tohave an abortion for financial reasons, whereas another may believe it to bepermissible. But, the magnitude and difficulty of such disputes may also depend onother properties of the ethical beliefs in question-in particular, how objective theyare perceived to be. As a psychological property of moral belief, objectivity isrelatively unexplored, and we argue that it merits more attention. We review recentpsychological evidence which demonstrates that individuals differ in the extent towhich they perceive ethical beliefs to be objective, that some ethical beliefs areperceived to be more objective than others, and that both these sources of varianceare somewhat systematic. This evidence also shows that differences in perceptions ofobjectivity underpin quite different psychological reactions to ethical disagreement.Apart from reviewing this evidence, our aim in this paper is to draw attention tounanswered psychological questions about moral objectivity, and to discuss therelevance of moral objectivity to two issues of public policy.1 IntroductionA central question in the study of ethics is the extent to which a belief about someethical' matter represents a true, Objective fact about the world, as opposed to a'For the purposes of this paper we use the terms "moral" and "ethical" interchangeably.G. P. Goodwin ( * )Department of Psychology, University of Pennsylvania, 3720 Walnut St., Solomon Lab Bldg.,Philadelphia, PA 19146, USAe-mail: ggoodwin@psych.upenn.eduJ. M. DarleyDepartment of Psychology, Princeton University, Princeton, NJ, USAPublished online: 17 December 2009 ~ SpringerG.P. Goodwin, J.M. Darleymerely subjective preference. As we will review below, this "meta-ethical" questionhas occasioned considerable disagreement amongst philosophers. However ourreview will not be oriented to advancing the consideration of the usual issuesamongphilosophers. Instead we propose to investigate whether there is agreement-ordisagreement-on these issuesamong ordinary members of a culture. Comparativelylittle is known about this, the "psychology of meta-ethics". How do individualswithout philosophical training think of their ethical beliefs? Do they think of them asfacts or preferences? How do they react to ethical disagreement? What consequencesstem from holding a particular view of an ethical belief? In this paper, we reviewwork conducted by ourselves and other researcherswhich provides some answers tothese questions.We first discuss some of the philosophical background to the study of ethicalobjectivity, in order to discover which meta-ethical issuesusefully could be exploredwithin the belief systems of philosophically na'fve individuals; but then we turn ourattention to discussing existing psychological findings about meta-ethics. Towardsthe end of the paper, we discuss several implications this work has for issues ofpublic interest, including the credibility of criminal laws and voting behavior.2 Philosophical BackgroundPhilosophers have been inclined to take different positions regarding the question ofwhether ethical beliefs are objective. Some philosophers have argued that there areno true moral facts, or that morality is not objective. On this view, moral beliefs areirreducibly subjective, akin to reports of subjective (or inter-subjective) experiences,or to expressions of personal preference or taste (e.g. Ayer 1936; Blackburn 1984;Greene 2002; Harman 1975; Mackie 1977; Williams 1985). Many other philOSO-phers, however, have argued for a more objective position (e.g., Brink 1986; Kant1959; Nagel 1970; Railton 1986; Smith 1994; Sturgeon 1985).A complication in thinking about this issue is that questions about the objectivityof ethical beliefs have been made in a variety of different ways by moralphilosophers. Philosophical debate in meta-ethics is organized by marking out aset of closely related yet distinguishable polarities (see Sayre-McCord 1986; Snare1992). Ethical "Objectivism", "realism", "cognitivism", and "universalism" arerelated, yet different philosophical positions that lie at one end of a scale that tracksthe broad concept of objectivity, whereas "SUbjectivism", "anti-realism", "non-cognitivism", and "relativism" are the respective opposites of these positions.Precision about these terms is important, philosophically, although there is far fromcomplete concordance about their meaning.To proceed, we will first define how we use these terms. According to our usage,the distinction between universalism and relativism refers to a difference in the scopeof a particular ethical claim, i.e., who it applies to. If I say that it is wrong for you tobreak a promise in a particular situation, then, if I am a universalist, I am alsocommitted to the view that it is wrong for anyone else in the same situation to breakthe same promise. The set of features that need to be "the same" in this formulationis hard to specify, but it clearly does not include aspectsof personal identity, i.e., if itis wrong for me to break the promise, it cannot be okay for you to break it, merely in~ SpringerThe Perceived Objectivity of Ethical Beliefsvirtue of you being a different personthan me. The distinction betweenuniversalism andrelativism is usually madeat the level of culture, i.e., in terms of whether something thatis wrong in one culture is also wrong in another. But it can also be made at the inter-personal level, asabove, i.e., in terms of whether something that is wrong for one personto do is also wrong for another person to do (seee.g., Sayre-McCord 1986; Williams1972). Whichever way it is framed, this question is correctly interpreted as one aboutwhat is actually right or wrong (permissible, impermissible, good, bad, etc.), and is notsimply a descriptive or sociological query about what the acceptedviews happen to bein different regions or eras (seeSnare 1992).The distinction between relativist and universalist ethics has been explored tosome extent by psychologists (see Gabennesch 1990a for a review; and Forsyth1980). However, other distinctions in meta-ethics are arguably more fundamental,and have remained largely unexplored by empirical psychologists. One issueconcerns whether moral claims have a truth value. Cognitivism is the view that atleast some moral propositions are capable of having a truth value (Sayre-McCord1986; Snare 1992), whereas non-cognitivism, or emotivism, is the view that moralpropositions are devoid of cognitive status-that is, they are not capable of having atruth value, and serve simply to express attitudes or emotions (Ayer 1936; Stevenson1937). Some modern non-cognitivists (e.g., Blackburn 1993, 1998; Gibbard 1990,2003) do not deny that moral claims have a truth value, although they do deny that acertain kind of truth applies to moral claims, i.e., truth that corresponds to theobjective facts in the world (see further, Sinnott-Armstrong 2006).On the other hand, both objectivists and subjectivists agree that moral claims canbe literally true, but they diverge on what makes such claims true (Sayre-McCord1986). Subjectivists believe that the truth of moral claims depends on the subjectivestates of individuals (Sayre-McCord 1986), such that the claim: "theft is wrong", istrue only when its speaker has the appropriate attitude of disapproval towards theft.This view can again be framed at the level of individuals-what is ethically true foran individual depends on the contents of their mental states; or at the level of aculture (so-called, "inter-subjectivism")-what is ethically true for a group dependson some aggregation over the mental states of the group members. Objectivists, onthe other hand, hold that the truth conditions of moral claims are mind-independentin the sensethat a moral claim can be true without reference to the subjective statesof the individual making the judgment, and without reference to the conventions ofany group of people who are making the moral jUdgment (Sayre-McCord 1986)?Hence, these two meta-ethical distinctions intersect as Fig. 1 illustrates.Two points need clarification. First, meta-ethical subjectivism as defined bySayre-McCord (1986) and Snare (1992), is different from non-cognitivism in thefollowing sense-the non-cognitivist takes moral claims to be mere expressions ofattitudes, while the subjectivist takes them to be reports about subjective states orattitudes (and hence they are capable of being true or false). Thus, although bothmeta-ethical subjectivists and emotivists disagree with objectivists, the differencebetween them is akin to the distinction between someone who in response to a sharpjab says "that hurts" (a subjectivist, cognitivist position which is capable of having a2 This way of describing objectivism is itself not uncontroversial, however (see Putnam 1987).~ SpringerG.P. Goodwin, J.M. DarleyMeta-ethical theory/~Non-cognitivism: moral claims expressattitudes and do not have truth valuesCognitivism: moral claims have truthvalues/~SuQjectivism: moralclaims true in virtueof suQjective mentalstatesObjectivism: moralclaims true mind-independentlyFig. 1 Intersection of cognitivism, non-cognitivism and oQjectivism, subjectivismtruth value), as opposed to "ouch" (an emotivist, non-cognitivist position, which isnot capable of having a truth value).Second, although similar to relativism, meta-ethical subjectivism is different inthe sensethat subjectivism makes a claim about the truth conditions of moral claims(see Sayre-McCord 1986), whereas relativism makes a claim about the scope ofapplication of ethical principles-who they are true for, rather than what makesthem true. So for instance, one could be an objective relativist, by saying that what isethically right for person A is different from what is right for person B, and that thisis true independent of any subjective attitudes that persons A and B might haveabout the matter (see Snare 1992). In this case the scope of the claim about what isethically right is relative, because it does not apply to everyone, but its truthconditions are purportedly objective.Similarly one could be a sUbjectivist and a universalist, by claiming that althoughthe truth conditions of moral claims are subjective mental states, it so happens thatthere is an underlying convergence of these subjective states (even if perhaps notconsciously realized), and so moral claims apply universally. This view would bechallenged by the fact of obvious ethical disagreements in practice, but one couldcounter-argue that such disagreements ultimately rest on disagreements over factual,non-ethical matters (for instance, about the meaning or consequences of a particularact), rather than on fundamental matters of ethical principle; or alternatively thatdisagreements arise over peripheral but not core ethical principles, and that the coreethical principles are universally shared (though sUbjective).This picture is necessarily a simplification of meta-ethical theory. Other meta-ethical distinctions exist, such as between realists and anti-realists, and philosophershave often taken surprising meta-ethical positions. J. L. Mackie, for instance,developed a form of cognitivist subjectivism, which held that ethical beliefs havetruth values, but that they are all false (Mackie 1977).3 It bears mention too that theterminology used here is by no means universally agreed upon. Williams (1972) forinstance, regards non-cognitivism as a form of subjectivism, in contrast to bothSnare (1992) and Sayre-McCord (1986).3 Whether this falsehood is supposed to be a contingent or necessarymatter is not entirely clear in Mackie(1977).~ SpringerThe Perceived Objectivity of Ethical BeliefsThis dense philosophical landscape may seem impenetrable for psychologicalinvestigation. And indeed, it would be a somewhat pointless exercise to ask na"l'veparticipants to produce fine distinctions between sophisticated meta-ethical views.However, we argue that people do have a set of underlying intuitions about theobjectivity or subjectivity of their ethical beliefs, and that these intuitions existwithout prior explicit theorizing. That is, in addition to having a wide range of basic,or what philosophers refer to as "first order" moral beliefs, people also have "secondorder" moral beliefs. We surmise that these second order beliefs have a set ofinteresting and unique properties that cannot be captured simply by asking peoplehow strongly they agree with a particular ethical claim, i.e., by asking them abouttheir first order beliefs. But, if we want to understand the underlying psychology ofethical Objectivity, we need ways to pose questions about the topic that areunderstandable to human participants without any philosophical training-that is, weneed questions that are both philosophically and psychologically meaningful.To that end, our empirical investigations have used two kinds of questions todistinguish objective and subjective positions about ethical beliefs. First, we askquestions that pertain to whether people take their ethical beliefs to be objectivelytrue statements of fact, or alternatively, subjective preferences or attitudes. Hence interms of Fig. 1, the contrast relevant for this paper is best approximated as thatbetween the far bottom right, objectivist position, and either of the remaining twopositions-either philosophical subjectivism or non-cognitivism. (This distinctionreflects the way Williams (1972) distinguishes between subjectivist and objectivistpositions.) Second, we ask participants whether in a situation of moral disagreementbetween two (or more) parties, one party or other must be mistaken. An objectivistmust reply that at least one party is mistaken, whereas a subjectivist need not makethis claim (Snare 1992).3 Psychological LiteraturePsychologists have tended not to be interested in this sort of question. And indeed,they have tended to focus very little on meta-ethical questions in general. We reviewwhat little research there is on meta-ethical questions here before reporting on ourown investigations.The psychological literature on moral judgment, at least during the twentiethcentury, was heavily influenced by the developmental work of Piaget (1965) andKohlberg (1969, 1981). Both were strongly cognitivist in orientation, and sought tounderstand the reasoning processesthat underlie moral judgment, which puts them atodds with more modern affective approaches to moral judgment (see later).Kohlberg proposed an ambitious stage theory of moral development. His dominantresearch method was to present vignettes portraying various moral dilemmas, whichinvolved a conflict between acts that either complied with sociolegal rules, or elseviolated these rules in order to serve human needs or welfare (Rosen 1980, p.69).Children's moral development was assessed by the reasoning processes theyexhibited in reaching a conclusion, rather than by the specific conclusions theyreached (see Rosen 1980). Kohlberg's classificatory scheme comprised three overallstages each with two sub-stages into which any individual's mode of moral~ SpringerG.P. Goodwin, J.M. Darleyreasoning could be placed (Kohl berg 1963, 1976). These three levels, in order ofincreasing moral sophistication, were called the concrete individual perspective, themember-of-society perspective, and the prior-to-society perspective (see Rosen1980). This model was both controversial and influential (Rosen 1980; Darley andShultz 1990).Kohlberg's model is concentrated on normative moral judgments, and offers fewresources for exploring questions about meta-ethics. Although he preferred an"active organism" model of moral development, in which a person constructs andthen reconstructs their moral knowledge (Rosen 1980), there is little evidence thatKohlberg (himself a moral realist and objectivist), regarded the pursuit of meta-ethical questions as a part of this active, constructive process.The highest stage-stage 6 of Kohlberg's scheme-is described in terms of therecruitment of universal ethical principles (Rosen 1980, p. 80). The moral agent atthis stage "is completely de-centered from society's expectations and bases hisresolutions to ethical conflicts upon universal principles of justice which areprescriptively consistent without exception" (Rosen 1980, p.80). This characteriza-tion implies that the seeking of just solutions to moral problems, though notnecessarily straightforward, is ultimately a resolvable problem (cf. Nagel 1979).Moral problems have objectively correct answers, and the moral agent of stage 6 candiscover what these answers are. This is a strong position, because not even allobjectivists agree that all moral dilemmas are indeed resolvable.4More tellingly, Kohlberg's scheme characterizes the pursuit of meta-ethicalquestions as a developmental aberration. Having erected his scheme, Kohlberg andhis collaborators observed a phenomenon which they had not previously paid muchattention to. Moral reasoners (typically boys) who had approached stage 4 in theirmoral development appeared to be regressing to an earlier, egoistic stage of moraldevelopment (see Rosen 1980, pp. 89-90). This stage, characterized by relativisticand skeptical moral thought, was interpreted as a "rebellious moratorium", inpreparation for a restoration and deepening of the higher levels of moral thinking.Initially this posed a challenge for Kohlberg's linear, deterministic theory, which didnot permit backwards movement through the stages. However, theoretical resolutionwas achieved by classifying this phaseas a transitional stage 4B, in which one "is onthe threshold of a breakthrough to principled moral reasoning which, although hedoes not yet realize it, will supply him with the new standard for which he isstriving" (Rosen 1980, p.92).This is the only place in Kohlberg's scheme that allows for moral doubt orskepticism. Meta-ethical reflection plays no role in the higher levels (5 and 6) of hisscheme, and is instead confined to a stage of adolescent rebellion. But, thepossibilities are greater than this. Unlike Kohlberg's ethical skeptics (who tend alsoto be egOists in his mind), not all ethical skeptics are egoists. A full characterizationof moral thinking needs to incorporate the possibility of a mature, and not amoral,ethical skepticism.4 Thomas Nagel, an ethical objectivist (see Nagel 1997) argues that there may be situations where variousmoral values are incommensurate, and there is decisive support for two or more incompatible courses ofaction (Nagel 1979). Although we may look for a "single scale on which all these apparently disparateconsiderations can be measured, added, and balanced" (Nagel 1979, p.131), there may be no such scale.~ SpringerThe Perceived Objectivity of Ethical BeliefsMeta-ethical questions have been investigated in the child development literature.A range of studies have explored children's perceptions of social conventions, and inparticular, whether or not children are able to distinguish social and ethicalconventions (see review by Gabennesch 1990a). This research has shown that bothchildren and adults can distinguish ethical prescriptions from social conventions interms of seriousness (Shantz 1982), alterability (Tisak and Turiel 1988), anddependence on cultural norms (Turiel 1978; Nichols and Folds-Bennett 2003;although both Nichols (2002, 2004) and Kelly et al. (2007) call the distinctionbetween ethical and conventional prescriptions into question. Participants in Turiel'sstudies were asked questions such aswhether a transgression would still be wrong ifthere was no rule to prohibit it, or whether it would still be wrong in another culturethat has no prohibition on it. Such questions are undeniably meta-ethical, but theyconcern the scope of application of an ethical principle, i.e., whether it is universal orrelative, not the nature of its truth conditions. While it is likely true in practice thatuniversalists are more likely to be objectivists than are relativists, there is no logicalrequirement that this be the case.Consider the question whether it would still be wrong to commit a transgressioneven if there were no rule to prohibit it. Answering "yes" to this question does notautomatically make one an objectivist. A "yes" response implies that the warrant forthe principle lies deeper than the mere fact that a rule has been enacted-theprinciple is taken to be more than a mere convention, as Turiel and others haveargued (although this interpretation is controversial, see Gabennesch 1990a, b;Shweder 1990; Helwig et al. 1990). But, this deeper warrant could be eithersUbjective or Objective-it could arise from the subjective mental states of membersof a community (subjective), or it could arise from an external source, such as God(objective), or from some other objective source. Indicating that the existence of arule is not sufficient to ground moral commitments does not commit a person tobeing either a subjectivist or an objectivist.Similarly, consider the question whether it would be wrong for another culture toallow something that in our culture is prohibited, i.e., whether a particular moralclaim is wrong "for some people" or "for real" (Nichols and Folds-Bennett 2003). Acomplication exists with this question in that "for some people" and "for real" arenot true opposites-the question is thus somewhat ambiguous as to whether it isasking about universalism or objectivism. On one reading of this question, "for real"is equivalent to "for all people", and thus answering "for real" indicates auniversalist position, but not necessarily an objectivist one-a subjectivist mightwant to apply a moral claim universally, without being committed to its having anobjective foundation. On another reading of this question, the question is purelydescriptive, and asks about the presenceof conflicting attitudes within society. Onefinal interpretation is that the question does ask about Objectivity-the phrase "forsome people" denotes a kind of "non-realness" precisely because it is contrastedwith "for real". On this reading, the question is similar to the oneswe have asked ourparticipants. But, without further specification the question is ambiguous.This is not intended as a decisive criticism of the approach adopted by Nicholsand Folds-Bennett (2003). They were interested in the moral responsesof 4-6 yearold children, and the question they asked, despite its complications, seems simplerand thus more appropriate for children in that age group, who are not likely to be~ SpringerG.P. Goodwin, J.M. Darleytroubled by the above considerations. Their chief finding was that children treatmoral transgressions as universally wrong, but do not treat conventional trans-gressions in this way.Attempts to investigate adult meta-ethical views have also tended to focus onperceptions of the universality of ethical claims. In a series of studies, DonelsonForsyth and his collaborators (Forsyth 1980, 1981; Forsyth and Berger 1982;Forsyth and Pope 1984) explored what he terms "ethical ideologies", which arebased on the intersection of two variables, relativism and idealism, as measured byhis Ethics Position Questionnaire (Forsyth 1980). Forsyth's resulting taxonomy wasfound to predict the severity of moral judgments (Forsyth 1981; Forsyth and Berger1982), and although it was found not to predict moral behavior in a setting where thetemptation to cheat was presented, it did predict differences in participants' reactionsto their own moral transgreSSions(Forsyth and Berger 1982).Forsyth's questions regarding relativism included items such as the following:14. Different types of moralities cannot be compared as to 'rightness'.15. Questions of what is ethical for everyone can never be resolved since what ismoral or immoral is up to the individual.16. Moral standards are simply personal rules which indicate how a person shouldbehave, and are not to be applied in making jUdgments of others.Such items perhaps do capture meta-ethical beliefs, but they go no further thanthe child development literature in this regard. The principal distinction is againbetween relativism and universalism. And although questions of the universality ofethical claims are undoubtedly within the scope of meta-ethics, they do not directlymap onto questions about the objectivity of ethical claims.The second dimension of Forsyth's (1980, 1981) taxonomy is puzzling. In hisEthics Position Questionnaire (Forsyth 1980), ten statements (which participants ratetheir level of agreement with), are used to assessthe construct of "idealism". Twosuch examples are:1. A person should make certain that their actions never intentionally harmanother even to a small degree.5. One should not perform an action which might in any way threaten the dignityand welfare of another individual.Eight further statements assess ethical idealism in a similar way. The oddcharacteristic of these statements is that they seem to assessbeliefs about the way theworld works rather than any sort of ethical ideology. Many small acts of intentionalharm occur daily, often without any ethical component: a dentist inflicts intentionalharm on a patient when probing sensitive teeth (seee.g., Bucciarelli et al. 2008). Thepossibility of avoiding all of these minor harms is quite remote. It would thus seemmore accurate to think of this "idealism" scale as characterized by naivety at one endand world wisdom at the other. And it is unclear how this dimension assessesanimportant component of ethical thought.The bottom line from the preceding considerations is that questions aboutuniversalism, although likely to produce answers that correlate highly with questionsabout Objectivity, are not identical to those questions. Our own research hasconcentrated on questions about objectivity: to what extent do people regard their~ SpringerThe Perceived OQjectivity of Ethical Beliefsmoral beliefs as objective statements of fact, as opposed to mere subjectivepreferences? To that end, in a recent paper (Goodwin and Darley 2008), we askedparticipants two different sorts of question in order to get at the perceived objectivityof their ethical (and other sorts of) beliefs: whether they thought that there could be acorrect answer as to whether a particular ethical belief was true (or alternatively, inExperiment 1, whether they thought that a particular bel ief that they held was true, asopposed to being an opinion or attitude); and whether they thought that a personwho disagreed with them about the belief was mistaken, or whether instead neitherparty need be mistaken in the face of disagreement. Our strategy was to averageresponses to these questions together to create a composite index of ethicalobjectivity (for further details, see Goodwin and Darley 2008).These three questions track some of the central philosophical thinking on thetopiC of ethical objectivity. Philosophers have been concerned with whether ethicalstatements possess truth values, and with whether correct answers exist to ethicalquestions.s And one common philosophical criterion for whether a belief is objectiveor not is whether disagreement over it implies that one of the disagreeing parties ismistaken (see e.g., Smith 1994; Snare 1992). Moreover, both pilot testing andintuition suggested that the questions we asked are readily understandable, and thatexperimental participants are able to produce answers to them.Before embarking on this research, it was an open question how people wouldperceive the objectivity of their ethical beliefs. Psychological research on "narverealism" has shown that people typically treat their own perceptions and preferencesas fundamentally "correct" (Ross and Ward 1995). Extending this perspective to theethical domain, it follows that most people should be highly objective about theirethical beliefs (and in fact, any sort of belief). However, other considerations suggestthe opposite prediction: that people will self-consciously appreciate the sociallyconstructed nature of ethical beliefs, and thus be moral subjectivists. Chief amongthese considerations is the observation made by several social commentators that welive in a more morally contested and pOSSiblyrelativistic society than we once did(e.g., Hunter 1991). These broad social trends may thus be reflected in theperception that moral issues are ultimately subjective matters.Our initial research yielded the following three central findings (Goodwin andDarley 2008), which are contrary to both of these perspectives. We concentratedprimarily on canonical examples of moral transgressions that involved violations ofjustice or the infliction of harm (see Haidt 2007). The results of several experimentsindicated that people take beliefs about the wrongness of such transgressions to bequite objective-almost as objective as beliefs about matters of everyday orscientific fact, and more objective than beliefs about social conventions (i.e.,appropriate dress wear and manners) and beliefs about matters of taste. That is, theytend to indicate that such ethical beliefs are true, that there is a correct answer as totheir truth, and that in the face of disagreement, one or other party is mistaken. This5 A note about our use of the term "belief": although it is the standard philosophical position, we do notintend the term "belief" to imply that a person assentsto the truth of the proposition they believe (seee.g.,Lacey 1996)-that would presuppose an answer to the question we want to investigate. Rather, we intenda weaker, more psychological reading of the term belief, which denotes an attitude of agreement or assent,without a further commitment to truth (see e.g., Reber 1996).~ SpringerG.P. Goodwin, J.M. Darleyfinding was robust when controlling for how strongly individuals agreed with beliefsfrom each of these classes.However, individuals differed considerably in the degree of objectivity theyascribed to such beliefs. The majority of individuals were quite objective, but therewere some individuals who were not. One pertinent predictor of ethical objectivitywas whether a person thought that ethical beliefs are ultimately grounded by areligious deity-those individuals who thought this was the case tended to be moreobjective than those who did not. Moral objectivity was particularly strong amongindividuals who did not think that right and wrong acts are possible without theexistence of a divine being.There was also some indication from these initial experiments that the specificcontent of ethical beliefs makes a difference in terms of how objective such beliefsare perceived to be. For instance, people tended to treat a statement about thewrongness of consciously discriminating against another person on the basis of raceas more objective than a statement about the goodness of anonymously donating10% of one's income to charity. This finding contrasts with a presupposition thatruns strongly through some philosophical writing-that ethical beliefs as a whole areobjective or subjective, and that one's meta-ethical view should apply en masse toone's entire set of ethical beliefs, in a top-down, deductive fashion-what Sinnott-Armstrong (2009) refers to as the uniformity assumption.6 Clearly, our participantsdid not accord with this description.This initial research thus partially supported a na'fve realist account of ethicalbeliefs-people generally found ethical beliefs about canonical moral transgressionsto be highly objective. But there are two features of our data which cannot beaccounted for by a simple narve realist account. First, not everyone treats theirethical beliefs as Objective-some participants were highly subjective even aboutcanonical moral transgressions. Second, not all ethical beliefs are treated equally, andthere appears to be considerable variation in perceived Objectivity, depending on thekind of ethical belief in question.One caveat from this first investigation is that we only surveyed samples ofundergraduate and graduate student participants from a single American university.Certainly this is a limitation. But, given the nature of our findings we do not considerit to be a critical one, becausewe suspect that in a broader sample, at least two of ourmain results would be amplified. A broader sample of Western participants is likelyto include many who have been much less exposed to skeptical arguments about thenature of morality and religious belief than the students in our samples. We wouldthus expect that perceptions of moral objectivity would be stronger than in oursample, and that the religious grounding of ethics would also be a stronger predictorof ethical objectivity. It would, of course, be of interest to investigate this, and also toinvestigate whether perceptions of objectivity are stronger in Western cultures thanin others (see Mackie 1977, for discussion of how notions of objectivity permeateWestern moral discourse).In more recent research we have followed up three questions left unanswered byour initial investigations: (1) Why are some ethical beliefs treated as more objective6 Although see Gill (2008, 2009) for philosophical critique of this uniformity assumption, and for adefense of meta-ethical variability.~ Springer4 Why Are Some Ethical Beliefs Treated More Objectively Than Others?The Perceived Objectivity of Ethical Beliefsthan others? (2) Why are some people more objective about their ethical beliefs thanothers? (3) Does holding an objectivist or subjectivist position about an ethical beliefhave any important psychological or behavioral consequences?The initial evidence in our 2008 paper showed that people do not treat all ethicalbeliefs as being equally objective. Why is this? What might predict whether a moralbelief is treated as highly objective, or not? In unpublished work, we haveinvestigated three specific hypotheses (Goodwin and Darley 2009).The first hypothesis is that people will be more objective about transgressions thatinvolve the infliction of direct personal harm or injustice. Jon Haidt and his COlleagues(e.g., Haidt and Graham 2007; Graham et al. 2009) have argued that suchtransgressions are the only ones consistently regarded as immoral in Western societies.Other actions that do not cause physical harm or injustice, but that provoke disgust orcontempt, are regarded as moral violations only by more conservative (Haidt andGraham 2007; Graham et al. 2009) and lower class Westerners (Haidt et al. 1993).Other research has indicated that only harm and justice based transgressions areconsidered to be moral violations in all cultures (Shweder 2003; Shweder et al. 1997;although some cultures judge as immoral at least some actions that generate emotionsof contempt or disgust). Taking a less empirical, more philosophical perspective,Royzman et al. (2009), summarize the arguments that harm is the fundamental basis ofmoral jUdgments. Each of these perspectives suggests that people will be highlyobjective only about harm or justice-driven transgressions.7The second hypothesis is that people will regard the negativity of moraltransgressions (i.e., their wrongness or badness) as more objective than the positivityof morally exemplary acts (i.e., their rightness or goodness). One motivation for thishypothesis stems from the fact that legal codes are primarily concerned withprohibiting rather than recommending action. This may, in part, reflect an importantunderlying moral principle, i.e., that clear and objective moral principles can beformulated about what is bad or wrong to do, but not about what is good or right.The third hypothesis is that people will be more likely to view a moral belief asobjective to the extent that they think other people hold that belief-that is, they areinfluenced by the degree of consensus they perceive to hold about the belief.To investigate these hypotheses, we developed an experiment in which participantswere asked to rate the objectivity of 12 different moral beliefs, aswell as some factualbeliefs and some beliefs about social conventions. The moral beliefs fell into fourdifferent classes.One class consisted of beliefs about the wrongness of causing harm orinjustice-assault, cheating, and the provision of a false alibi. The second classconsisted of beliefs about the wrongness of symbolic harms-desecrating a 9/11memorial, performing a Nazi salute to a Jewish sporting audience, and flag burning. Thethird class consisted of beliefs about the goodnessof morally exemplary acts-donatingmoney to charity, performing.a risky swim rescue, and performing onerous energy7 Note, however, that other arguments exist which call into question whether harm is the fundamentalbasis of morality (seee.g., Kelly et al. 2007).~ SpringerG.P. Goodwin, J.M. Darleyconservation activities. And the fourth class consisted of beliefs about the permissibilityof highly contested value of life issues-abortion, and two different instances ofeuthanasia. The contrast between the first (harm, injustice) and second (symbolic harm)classes allows an assessment of whether direct harm or injustice predicts greaterObjectivity. The contrast between the first two classes (transgressions) and the third class(morally exemplary acts) allows an assessment of whether people ascribe greaterObjectivity to moral transgreSSions than they do to morally exemplary acts. And thecontrast between the first three classesand the fourth class (contested value of life issues)allows an assessmentof whether people are more Objective about beliefs that they suspectare widely shared. To investigate this question more precisely, we also asked participantsto estimate the percentage of US citizens they thought would agree with each belief.The three items with in each category hung together well, both in terms of the patternsof means and inter-correlations (see Goodwin and Darley 2009). And, importantly, allof the ensuing analyses controlled for how strongly participants agreed with eachbelief. As in our previous studies, participants were highly objective about thewrongness of inflicting harm and injustice. However, they were no more objectiveabout such transgreSSions than they were about transgreSSions which inflicted muchmore symbolic wrongs. This result was surprising. It does not rule out direct, physicalharm or injustice as important predictors of perceived Objectivity, but it does show thattheir presence is not necessary for an ethical belief to be treated as highly objective. It isof course possible that our participants thought that the symbolic wrongs would inflictemotional harm of equivalent magnitude to the harms caused by the directly harmful orunjust actions. This would be useful to investigate. However, even if this did turn out tobe true, it would not undercut our main conclusion: our results would still show that thenature of the harm or injustice that a moral transgreSSion causes need not be direct orphYSical, in order for the wrongness of that act to be perceived as highly Objective.Participants were also more objective about the wrongness of both kinds oftransgreSSion (direct harms or injustices, as well as symbolic harms) than they wereabout the goodness of the morally exemplary actions. This difference was highlysignificant for each of the items we investigated (there was no overlap between any ofthe means from the two different categories: good vs. wrong). This suggests thatwrongness is indeed perceived to be a more objective moral property than goodness,even when controlling for how strongly participants agreed with the beliefs in the twocategories. This finding, however, might have occurred for two different reasons. On theone hand, it could be that, as we suggest, the valence of the behavior (whether it ispositive or negative) is what accounts for the difference in perceived Objectivity. But, itmight also be that the crucial difference is one between statements of value (goodness,badness) and statements of norms (rightness, wrongness). Our finding could beexplained by the idea that people take claims about rightness and wrongness to be moreobjective than claims about goodness and badness, which is why they treated morallywrong as a more objective category than morally gOOd. This seems implausible forpositively valenced items, i.e., it seems unlikely to us that people would treat rightnessas a more objective category than goodness, at least when it is predicated of the sameaction. The claim that some action is morally right makes it more Obligatory than theclaim that it is merely morally good (see e.g., Gert 2005, p. 321-322), and we thussuspect that a claim about rightness is less likely to be perceived as Objective than aclaim about goodness. But, we cannot as confidently rule out this explanation in the~ SpringerThe Perceived Objectivity of Ethical Beliefsnegative domain-perhaps people do indeed treat wrongness as more objective thanbadness.sWe are thus currently conducting an investigation to determine whethervalence or moral language is the chief driver of the effects described in the presentstudy.9Finally, our participants treated the goodness of morally exemplary actions asmore objective than the permissibility (or impermissibility, depending on how theyresponded) of highly contested value of life choices. In fact, they were no moreobjective about the wrongness of social conventions than they were about thepermissibility (or impermissibility) of the value of life choices. Further analyses,which used participants' estimated consensus responses for each moral belief,showed that such estimates were very reliable predictors of perceived objectivity(our results demonstrated an across-items correlation between objectivity andperceived consensus of r= .84), over and above how strongly participants agreedwith each of the beliefs in question. Because they are correlational, these data are ofcourse consistent with an alternative interpretation according to which perceivedobjectivity inflates consensus estimates, i.e., it is objectivity that drives consensusjudgments rather than the reverse. Our current data is not sufficient to rule out thishypothesis, and indeed it may well be true. Perhaps both directions of causationoperate. At any rate, in order to draw a causal inference from consensusassessmentsto Objectivity, a study which manipulates perceived consensus estimates is called for.These results suggest three reasons why some ethical beliefs are treated as moreobjective than others. First, although harm and injustice are likely to be importantpredictors, their occurrence is not necessary in order for a moral belief to beperceived as highly objective. Second, people seem to treat beliefs about thewrongness of moral transgreSSionsas more objective than beliefs about the goodnessof morally exemplary actions. And third, perceived consensus appears to predictobjectivity assessments. These conclusions are preliminary at this point; all threeresults invite follow-up investigations, which we are currently carrying out.5 Systematic Individual Differences in Ethical OqjectivityThe previous study established that there is systematic variation in Objectivityassessmentsacross different kinds of ethical belief. In our previous studies, we hadalso shown that there were some systematic individual differences in Objectivity.8 We thank Walter Sinnott-Armstrong for this point. Gert (2005, p. 322) makes the point, which we agreewith, that the terms "morally good" and "morally right" tend to refer to different kinds of action, whereas"morally bad" and "morally wrong" are used more interchangeably. We interpret this point as counting infavor of our valence hypothesis regarding negative moral actions-it suggeststo us that there will not be asubstantial difference injudgments of oQjectivity regarding the categories morally bad and morally wrong.Gert himself, however, takes wrongness to be a more objective property than badness (see p. 325). Forpositive moral actions, Gert's point about the non- interchangeability between the terms "good" and"right" suggests that in order to clearly test whether goodness is considered less oQjective than rightness,these moral properties may need to be predicated of different actions.9 A further possible explanation of our finding, suggested by an anonymous reviewer, is that people maythink that it is more likely that people would do morally good (or right) things for the wrong reasons, thanthat they would do morally bad (or wrong) things for the right reasons. This is an intriguing possibility,and worth investigating.~ SpringerG.P. Goodwin, J.M. DarleyThose who grounded their ethical beliefs in religious ideology were more objectivethan those who did not. This finding is correlational, and it would be desirable toshow that there is a causal influence at work here. This might be doneexperimentally by manipulating the salience of religious ideas, and showing a boostin objectivity scores (among religious participants) when religious ideas are madesalient. While this finding would be important, other individual differences may alsopredict jUdgments of objectivity, and these have been the focus of our most recentinvestigations. In particular, we have been interested in whether certain cognitiveand personality variables predict jUdgments of moral objectivity.One striking observation from our previous work concerned the kinds ofexplanations participants gave for why disagreement may have arisen about anethical issue. In those studies (Goodwin and Darley 2008), we asked participants toexplain why disagreement may have arisen in each case.The differences in the kinds ofexplanations people offered were striking. Some participants, typically the objectivistresponders, seemed to be less inclined to explain why the disagreement may havearisen. Rather, they tended to make blanket responseswhich either reiterated their ownbelief, which expressed disbelief that another person could have disagreed with them,or which ascribed some moral defect to the disagreeing other person. For instance, inresponse to a disagreement over whether robbery to pay for a vacation is wrong, theywould say things about the person who disagreed with them like:The other person obviously has no values, and no respect for the property ofothers!or:The other person has a warped view of what is a moral action.By contrast, those who responded more subjectively seemed more interested inexplaining the disagreement. They would say things like:Values are probably the source of disagreement. A hedonist would feel morallyobliged to steal for the vacation. A compassionate person would not.or:The source of disagreement is most likely how the other person and I deriveour morals. It could be that he is a radical hedonist while I take a moreuti Iitarian approach.The subjectivists' responses seemed to place more emphasis on explaining thesource of the disagreement in terms of competing moral values, whereas theobjectivist responses tended to explain the disagreement in terms of the sheerpresence or absence of moral values at all. And indeed, as rated by an independentcoder, there were reliable differences in the quality and kind of explanations thatsubjectivists and objectivists gave (Goodwin 2009).These results suggest that part of what may underlie objectivist responding to anethical disagreement is a tendency not to think of some of the alternative reasons fordoubting or disagreeing with the belief in question. If a person actively considerssome of the reasons for doubting an ethical belief they hold, they may be inclined tobe less objective about that particular belief. To investigate this idea, we presented~ SpringerThe Perceived OQjectivity of Ethical Beliefsparticipants with a task that measuresdi~unctive reasoning ability, i.e., the tendencyto actively unpack alternative possibilities when reasoning (Goodwin 2009). Weused the following "five blocks" task originally devised by Levesque (1986, 1989)and investigated further by Toplak and Stanovich (2002) and Over et al. (in press):There are five blocks in a stack, where the second one from the top is greenand the fourth is not green. Is a green block definitely on top of a non-greenblock?Participants have to choose between three responseoptions: yes, no, cannot tell. Themost intuitively plausible response is to say "cannot tell", but this is incorrect. Toinfer the correct solution you need to consider the alternative possibilities for theindeterminate third block-you need to unpack the two distinct alternatives for thisblock and examine their consequences.The correct answer is "yes": if the third blockis green, then since it is directly on top of the fourth non-green block, the conditionis fulfilled; alternatively, if the third block is not green, then since it is directlyunderneath the second green block, the condition is also fulfilled. Thus, whichevercolor the third block happens to be, there is definitely a green block directly on topof a non-green block.Toplak and Stanovich (2002) examined this task along with a range of other taskswhich are aimed at assessing "disjunctive thinking". These tasks correlate onlymoderately with indicators of cognitive ability such as SAT scores, which led Toplakand Stanovich to describe them as measures of a dispositional tendency towardsdi~unctive thinking rather than as cognitive ability measures. In our initialexperiment (Goodwin 2009), we used only the five block task because it has nomoral content, and because it seemed to capture the difference in the kind ofthinking that underpinned ethically objectivist and subjectivist responses in our freeresponse task. Our hypothesis was that participants who performed the five blockstask correctly would tend to be less objective about their ethical beliefs thanparticipants who did not. Such individuals should possessa dispositional tendency tothink disjunctively, and thus, in a moral context, they should be more inclined toactively consider the reasons why another person might disagree with their ethicalbeliefs. However, they should not be more objective about matters of taste, wheredisagreement can exist at the level of brute preferences rather than reasons.We also presented participants with a range of other measures that we suspectedmight predict objectivity: Frederick's (2005) Cognitive Reflection Test, which is asimple, three measure instrument which measures a person's tendency to over-ridean immediate, intuitive response, and which correlates highly with generalintelligence; Cacioppo et al.'s (1984) Need for Cognition scale, which measures aperson's "tendency to engage in and enjoy effortful cognitive endeavors"; andKruglanski et al.'s (1993; Webster and Kruglanski 1994) Need for Closure scale,which measures a person's "need for an answer on some topic, any answer asopposed to confusion and ambiguity".The study demonstrated that only the di~unctive thinking measure reliablypredicted ethical objectivity. Those participants who performed this task correctlywere significantly less objective on ethical items than those who performed itincorrectly (we observed a correlation between performance on this problem andethical objectivity of r= .36). But they were no more objective than the incorrect~ SpringerG.P. Goodwin, J.M. Darleyresponders on the items about matters of taste. In contrast, and somewhat to oursurprise, none of the other measuresreliably predicted ethical objectivity. This initialresult lends credence to the idea that a propensity towards disjunctive thinkinginclines people towards a more sUbjective view of their ethical beliefs.A follow-up study presented participants with a wider array of di~unctivereasoning tasks that were drawn from Toplak and Stanovich (2002). One of thesetasks was isomorphic to the three blocks task presented earlier and the other wasclosely related to it. The average performance on these items correlated negativelywith objectivity assessments,replicating the previous finding. We again measuredNeed for Cognition, Need for Closure, and Cognitive Reflection, and these measureswere not correlated with Objectivity. The experiment excluded one extra "mindset"variable. When answering the objectivity questions, half of the participants wereinstructed to adopt an "experiential" mindset-they were instructed to respond withtheir "first, natural response" and that the experiment was only interested ininvestigating people's "gut level reactions" (seeEpstein 1991, 1994). In contrast, theremaining participants were instructed to be "as rational and analytic as possible"(Epstein 1991, 1994). This manipulation did not produce a difference in the overalllevel of objectivity scores, but it did produce a marked difference in the pattern ofobserved correlations. The correlation between the di~unctive thinking measure andobjectivity was much stronger in the "experiential" condition (r= .59), and was notreliable at all in the "rational" condition (r= .05). We surmise that the experientialinstructions reflect the normal way in which participants respond to these sorts ofquestion, which is why this condition replicated the strong correlation observed inour first experiment. However, this result was not predicted, and the exact reason forthe difference between the two conditions is not clear. One possibility is that theinstruction to think rationally pushed participants who would not normally considerthe alternative reasons for disagreeing with an ethical belief, to do so. However, theoverall mean Objectivity score in the rational condition was not lower than it was inthe experiential condition, which does not support this explanation.Regardless, these correlational results suggest that there is an underlyingcognitive variable-perhaps the tendency to reason disjunctively-which underpinsthe way people make assessments of ethical objectivity. Our current workinghypothesis is that individuals who are inclined to think di~unctively on a problem-solving task, are also more inclined to generate alternative reasons why anotherperson might doubt or disagree with an ethical belief that they themselves hold.Sometimes these alternative reasonsmay have persuasive appeal-thus, on average,this kind of thinking is likely to lower assessmentsof ethical Objectivity. Thus, in ourcurrent research, we are experimentally inducing participants to first think ofalternative reasons for doubting or disagreeing with an ethical belief before askingthem to respond to questions about the objectivity of that belief-predicting a dropin perceived objectivity under these conditions, compared with a control condition.6 Consequences of Taking an Oqjective PositionOne of our underlying motivations for studying the psychology of meta-ethics wasto examine the sorts of consequences that stem from holding a particular meta-~ SpringerThe Perceived Objectivity of Ethical Beliefsethical view. Do objectivists and subjectivists differ in how they respond to ethicaldisagreement? Philosophers have often written as though, in the face of ethicaldisagreement, objectivists ought to be more open to listening to the arguments of thedisagreeing other party (e.g., Snare 1992). If you are an objectivist, you believe thatthere is a true fact of the matter to be discovered about any ethical belief. As aconsequence, when disagreement arises, you should be interested to hear whether thedisagreeing other party has any convincing reasons that might change your mind.Even if you are highly confident about the belief in question, you should still beinterested to hear an opposing view, in case you have overlooked some pertinentpiece of information. But, if you are a subjectivist, you believe that there is no fact ofthe matter to be discovered, and that the disagreement is essentially a clash of brutepreferences. So you should be less motivated to listen to the arguments of the otherparty.As a psychological hypothesis, however, this prediction seems implausible,particularly when examining the open-ended responses that objectivists andsubjectivists gave when explaining why disagreement may have arisen (see earlier;objectivist: "the other person has no values", subjectivist: "values are probably thesource of disagreement"). Nevertheless, this way of framing the issue does pose aninteresting psychological question: when confronted with ethical disagreement, doethical objectivists respond in a more "open" or a more "closed" fashion thansubjectivists? To examine this question, one of our earlier studies asked participantsthree different questions to investigate their responses to ethical disagreement. Onequestion asked them to indicate how comfortable they would be to have the personwho disagreed with them as a room-mate (a standard social psychological measureof social distance), a second question asked about the personality attributions theywould make about the disagreeing other person (personality attributions), and a thirdquestion asked whether they thought it would be possible for them to give up theiragreement with their original belief (self-reported rigidity of view). Each of thesethree questions was asked for each of the ethical disagreements that participants werepresented with.Across all three variables, objectivist responders responded in a more "closed"way in the face of ethical disagreement (Goodwin and Darley 2009). They were lesscomfortable than subjectivist responders with a person who disagreed with themabout an ethical issue, even when controlling for how strongly they agreed with theethical claim in question. They were also more likely to say that the disagreeingother person was "not a moral person". And they were less likely to indicate that itwas possible that they could give up their agreement with the belief in question. Afollow-up study replicated these effects using slightly different measures. And ineach case, ethical Objectivity predicted more closed responses in the face ofdisagreement, controlling for how strongly participants agreed with the beliefs inquestion (Goodwin and Darley 2009).These results indicate that there appear to be important judgmental and possiblybehavioral consequences that stem from holding a particular meta-ethical view.Moreover, lay meta-ethical views seem to have predictive effects over and abovehow strongly people agree with a particular belief. Although strength of agreementand objectivity are correlated-as people agree with an ethical belief more strongly,they tend to be regard it as being more objective-they are not perfectly correlated,~ SpringerG.P. Goodwin, J.M. Darleyand they have independent predictive effects. Follow up work in this domain shouldaim to test how meta-ethical views affect real interactions in which an ethicaldisagreement occurs.7 Oqjectivity and Current Theories of Moral CognitionWhat is the relationship between studies of moral objectivity and current theorizingin moral cognition? A good deal of current theorizing is concerned with the extent towhich emotions relate to moral judgments. One kind of theory concentrates on theemotions that moral violations produce. For instance, Rozin and his collaboratorshave proposed a theory which argues that characteristic emotions are produced bydifferent sorts of moral violation (Rozin et al. 1999). According to this theory, angertypically arises from violations of personal autonomy (i.e., infractions involvingharm, injustice, violations of rights or restrictions in freedom), contempt arises fromviolations of a community ethic (i.e., violations of social duties and obligations,disrespect for social standing and authority, and disloyalty), and disgust arises fromviolations of a divinity ethic (i.e., violations of the natural order, of the body, and ofpurity and sanctity). These authors' experiments demonstrated support for theselinkages-when presented with violations of the three different sorts, people tendedto select and generate the emotions that 'fit', according to the theory.Other theories have concentrated on the way in which emotions themselvesproduce moral jUdgments. Jon Haidt and his collaborators have performed anintriguing series of studies which demonstrate that incidental emotions can exertlarge effects on moral judgment. In one study, participants were hypnotized to feel apang of disgust whenever they read a non-moral word such as "often" (Wheatley andHaidt 2006). They later read a moral Vignette which described a moral transgression.All participants were hypnotized, but the crucial variable was whether the targetedword occurred in the story, or not. When it did, participants made harsher moralevaluations of the transgression. The incidental occurrence of moral emotions thusappears to affect moral judgment. Similarly, in more recent studies, Haidt and hiscollaborators have shown in different ways how the incidental experience of disgustaffects moral judgments. For instance, Schnall et al. (2008) have shown how disgustthat is elicited by the surrounding environment, or by remembered experiences,produces an increase in the severity of moral judgments about unrelated matters.Other evidence demonstrates the causal role of emotions in different ways. Forinstance, Haidt has documented the phenomenon of 'moral dumbfounding', wherebypeople have strong moral reactions to certain transgressions such as incest, but arenot able to explain their reaction in any satisfactory way-' it just feels wrong' beinga typical response (e.g., Haidt 2001). The interpretation of this finding was that themoral judgment is primarily caused by an emotional reaction, rather than a reason.Similarly, Haidt has documented that for these kinds of violations, an individuals'emotional reaction to the scenario is a more powerful predictor of their eventualmoral judgments than is their assessmentof the harm that the action produces (Haidtet al. 1993).There is also some evidence that self-directed moral emotions are an importantcause of moral decisions. Monin and Miller (2001) have documented a phenomenon~ SpringerThe Perceived OQjectivity of Ethical Beliefswhich they refer to as 'moral licensing'. In their studies, when participants were ableto affirm their non-prejudiced moral identities in an initial phase of the experiment,they were subsequently more likely to express politically incorrect opinions, and tomake hypothetical choices which accorded with those opinions. The explanation forthese effects was that a person's moral behavior is driven in the moment by self-perception of their own moral identity, which arguably has an important emotionalcomponent. In a more recent study, Sachdeva et al. (2009) corroborated this finding,and also demonstrated evidence of the inverse effect. Participants who had writtenabout a past instance of their own moral behavior were subsequently less likely todonate money to charity than those had not. But, participants who had written abouta past instance of their own immoral behavior were subsequently more likely todonate money to charity. Both effects suggest that self-directed moral emotions canexert a causal influence on moral behavior.Finally, more recent researchhas relied on fMRI scanning to document the natureof the emotional responses that may underlie moral judgment (e.g., Greene et al.2001, 2004; Moll et al. 2003; Sanfey et al. 2003). The upshot of this research hasbeen to show that brain areas that are associated with emotional responding areactivated in response to a variety of moral situations. For instance, Greene et al.(2001) showed that moral dilemmas that are thought to activate moral emotions, doin fact activate areas of the brain associated with emotional processing (the medialfrontal gyrus, posterior cingulate gyrus, angular gyrus) in contrast with a set ofcontrol problems which activated areas associated with working memory (middlefrontal gyrus, parietal lobes). Sanfey et al. (2003) showed that the anterior insularegion of the brain-an area which is also known to be associated with emotionalprocessing-is more strongly activated in response to unfair offers in the context ofthe Ultimatum Game,lO than in response to fair offers. More recent work hasillustrated that cognitive processes interact with emotional processes in moraljudgment. Greater recruitment of brain regions known to subserve abstract reasoningand cognitive control (including dorsolateral prefrontal cortex and anteriorcingulated cortex) predicted longer response times on difficult personal dilemmas,and also more utilitarian responseson such dilemmas (Greene et al. 2004).There is thus an accumulated body of evidence that illustrates that emotions arestrongly associated with moral judgments and actions. But there is disagreementabout the nature of this relationship. Prinz (2006) has usefully categorized thepossible relationships that could be argued for. The least controversial position,which it is now almost impossible to disagree with, is that emotions co-occur withmoral judgments, at least some of the time. Both fMRI and self-report dataunequivocally support this contention. It is more difficult to know how oftenemotions co-occur with moral judgments, and there is little existing data which isrelevant to this broader issue.The most radical position, which Prinz adopts, is that emotions are constitutive ofmoral jUdgment-ali moral judgments are underpinned by an affective response ofsome kind, even if this affective response is not activated at the time of jUdgment.10 In this game, participants are first divided into pairs. One participant is given a small sum of money (say$10), and makes an offer to the other participant which that person has the choice either to accept or reject.~ SpringerG.P. Goodwin, J.M. DarleyThere are some considerable attractions to this position as a philosophical theory,although its empirical support is indirect (see Joyce 2009; Prinz 2007).A third position is that at least in some cases emotional reactions cause moraljudgments. Haidt's experimental manipulations of moral emotions and thedemonstration of the subsequent effects this has on moral judgment support thisposition. And indeed, this evidence has made it difficult to argue with the idea thatemotions play at least some causal role in moral judgment.However, there are major debates concerning the extent of emotional involvementin moral judgment, and there is still great scope for disagreement. Some theoristshave argued for the dual role of cognitive and emotional processes in moraljudgment (e.g., Greene et al. 2001, 2004; Moore et al. 2008; Bucciarelli et al. 2008;see also Cushman et al. 2006; Hauser et al. 2007), although there is no greatagreement between these authors about the nature of the cognitive processesinvolved. Other theorists, however, including Jon Haidt and his collaborators, havemaintained that emotions are the critical driver of moral judgments. Althoughallowing that cognitive override may sometimes affect moral jUdgments, theseauthors have maintained a commitment to a social intuitionist model, according towhich: 'moral reasoning is an important part of moral life, but for most people, mostof the time, most of the action is in the quick, automatic, affective evaluations theymake of people and events' (Schnall et al. 2008, p. 1097).This claim is very strong, and we take our findings concerning the perceivedobjectivity of ethical beliefs to be relevant to it in the following two ways. First, ourdata has shown that metajudgments of moral objectivity seem best predicted bycognitive rather than affective factors. Second, it has also shown that objectivityjudgments are divergent from first order moral judgments, i.e., they are divergentfrom strength of agreement ratings concerning moral beliefs. Both findings suggestthat there are important dimensions of moral judgment that are distinct from theinitial, affective reactions that playa role in producing first order moral judgments.Our data also indicates that at least some of the predictors of objectivityjudgments-i.e., the extent to which a person grounds their ethical beliefs in God,and the propensity for di~unctive thinking (i.e., the five blocks task)-are notwholly affective. Taken at face value, these measures are predominantly cultural andcognitive, respectively. Is it possible that they have more primitive, affective roots?This seems possible for the religious grounding of ethics, but not for the measure ofdi~unctive thinking. Perhaps some other, more affective measure, is a betterpredictor of individual differences in objectivity judgments, and subsumes the twomeasures we have found to be predictive. This, of course, cannot be ruled outentirely. But it strikes us as an implausible pOSSibility, particularly since Need forClosure, which measures more affective and motivational components than thedi~unctive thinking measure, had almost no predictive power in our experiments. Ofcourse, affective reactions may explain part of the variance in Objectivityassessments,and as yet, we have not yet measured them directly. Nevertheless, thecurrent evidence suggests there are cognitive factors that underpin assessmentsofObjectivity, and that these do not depend on affective responses.Our research has also shown people's perceptions concerning the Objectivity of anethical belief diverge from how strongly they agree with that belief. This result ishard to account for on the view that a single affective response underpins all aspects~ SpringerThe Perceived Objectivity of Ethical Beliefsof moral judgment. Assuming that an underlying affective response causes aperson's agreement or disagreement with a particular ethical belief (the socialintuitionist claim), then if that affective response is the principal driver of all aspectsof moral judgment, it should also cause a convergent judgment about objectivity. Wedid not observe this sort of convergence in judgment, however. Moreover, althoughmore evidence is needed, judgments of objectivity look like they have importantconsequences. In our studies, they predicted discomfort with a disagreeing otherperson over and above, and in fact more strongly than did strength of agreementratings. They also predicted the tendency to attribute a morally defective personalityto a disagreeing other person. And they predicted a self-reported reluctance to giveup an ethical belief. All three of these responses are likely to be important whenindividuals are faced with real ethical disagreements.Thus, it seems that there is an important property of moral judgment, namelyObjectivity, which is not predicted by affective reactions, and yet which hasimportant consequences. This claim may not be strictly contrary to Haidt's socialintuitionist model, because it could be that affect is the prime cause of first ordermoral judgments, but not of second order, meta-ethical jUdgments-a state of affairsthat would be surprising for the social intuitionist account, but not inconsistent withit. Nevertheless, we do wish to draw attention the multifaceted nature of moraljudgment, and to claim that this ought not to be ignored. Moral judgment dependsnot just on the interplay between affect and cognition, but also on the interplaybetween first order and second order moral jUdgments. Further attention needs to bepaid to each of these dimensions in order to better understand moral judgment in allof its complexity.8 Behavioral ImplicationsResearch on moral objectivity arguably has several implications for public behaviorand policy. One implication is that judgments of objectivity may predict howsatisfied a person is with the prevailing legal code with regard to particular issues,and a second implication is that judgments of Objectivity may affect the extent towhich moral values are prioritized in voting behavior. We deal with these two,admittedly speculative, possibilities in turn.The relationship between law and morality is a notoriously vexed issue ofjurisprudence. Our aim is not to comment directly on long-standing debates betweenlegal positivist and natural law interpretations of the law, but rather to position ourfindings with respect to recent arguments that have highlighted the important relationbetween moral intuitions and the law. One such argument has claimed that the lawinfluences behavior not just through its threat of sanction, but also through its powerto influence and shape social norms (Robinson and Darley 1997). According to thisargument, the law is capable of harnessing the powerful forces of social influenceand stigmatization in order to produce compliant behavior. This is particularlyimportant in caseswhere the morality (or immorality) of a particular behavior is notobvious, and is not yet the subject of social norms. However, in order to gain thispower to shape norms and behavior, the law must itself possess general moralcredibility. It can gain such credibility by accurately reflecting the intuitions of~ SpringerG.P. Goodwin, J.M. Darleyjustice that are held by the majority of the members of a society. If, on the otherhand, the law does not have sufficient moral credibility, it will have a reduced powerto influence social norms, and in some extreme cases pernicious consequences canresult, including vigilantism and flouting of the law.The Rodney King race riots in Los Angeles were a vivid example of this idea.Recent experimental evidence has also corroborated it. Nadler (2005) showed thatwhen participants were presented with a piece of legislation (Study 1) or a courtdecision (Study 2) that they found to be unjust (by being too lenient), they reported agreater intention to engage in minor law-breaking activity (Study 1), and to disregardthe instructions of ajudge when acting asjurors in a mock-trial setting (Study 2).These results are intriguing, and suggest that if the law fails to properly reflect themoral standards of society, negative consequences may result." It has yet to bedemonstrated that law-breaking behavior (as opposed to the intention to commitsuch behavior) is made more likely as a result of perceiving the criminal justicesystem to be unjust, which limits the conclusions that can be drawn from thisresearch. However, while this is an important question for future investigations topursue, other evidence does point to the strong predictive links between intentionsand behavior, particularly in caseswhere the behavior is under volitional control (seee.g., PJzen and Fishbein 1975, 1977, 1980; Schifter and PJzen 1985).Nadler's (2005) flouting effects were demonstrated in cases where participantsconsider that a particular criminal liability is disproportionate to the transgressionthat occasioned it. But the effect may occur not only when the proportionate severityof transgression and punishment is in question, but also when the status of thetransgression itself-whether it is in fact a transgression-is in question. This isparticularly pertinent for a range of activities which are not obviously categorized aswrong in themselves (or 'malum in se' in legal terminology). Such activities includeso-called 'victimless crimes' including prostitution, pornography, drug use, incestbetween consenting adults, and 'public order violations' such as flag burning, ordesecrations of symbolic icons.Whether a particular activity is considered wrong in itself as opposed to wronginstrumentally is a separate conceptual issue from whether it is considered wrongobjectively, but there is likely to be considerable overlap in people'sjudgments. Forour purposes, the important question is whether an activity that the law criminalizesand punishes is widely considered to be wrong in an objective sense,and converselywhether an activity that the law fails to criminalize and does not puniSh, is widelyconsidered to be objectively permissible. Understanding how the public perceivesthe objective-subjective dimension of particular moral issues is an important part ofunderstanding their moral intuitions about those issues-there is more to a moralintuition than simply whether a person agrees with a jUdgment of wrongness orpermissibility. Our data has shown that perceptions of objectivity predictpsychological reactions independently of how strongly a person agrees with a claimabout permissibility or wrongness. Thus, we predict that if a person considers say,incest, to be an objective moral wrong, they are likely to be disappointed with a legal11 Consistent with this interpretation, some theorists have argued that the law hasan 'expressive' function,by which it signals the social values of a society, particularly in cases where existing norms about aparticular behavior are weak or undecided (e.g., Lessig 1996; Sunstein 1996).~ SpringerThe Perceived Objectivity of Ethical Beliefssystem that does not both criminalize it and impose considerable sanctions upon itsoccurrence. And they should be more disappointed about this than a person whoconsiders incest to be wrong only in a sUbjective sense. Conversely, if a personconsiders say, marUuana smoking to be wrong, but not in any objective sense, theymay be disappointed with a legal system that does criminalize and impose harshsanctions upon it, whereas a person would likely be more comfortable with thisresult if they consider marUuana smoking to be objectively wrong.These are speculative claims, because no directly relevant data exist to supportthem directly. Nevertheless, there is good reason to suspect that researchers'assessmentsof moral intuitions neglect an important dimension if they do not takeinto account meta-ethical perceptions of objectivity and subjectivity. Suchperceptions may affect people's reactions to a criminal code's decisions about bothwhich acts to criminalize, and its decisions about sanctioning, which may in turnaffect their generalized respect for the law, and their intention to follow it.Perceptions of objectivity may also impact voting behavior. Whether moralbeliefs and values are held to be objective facts is likely to influence how thosebeliefs and values are prioritized in the polling booth. Although there is considerabledisagreement about the impact of moral values on voting behavior (see e.g., Fiorinaet al. 2004; Burden 2004; Hillygus and Shields 2005; Langer and Cohen 2005),there is good evidence that they play at least some role in how people vote. John Jost(2006) has shown that voting in US presidential elections spanning back to 1972 isstrongly predicted by political ideology-a psychological construct which includesmoral values to a considerable extent. Somewhat earlier, Sears et al. (1980)demonstrated that long-term political and ideological commitments influence votingbehavior more than do immediate considerations of self-interest. Differences inpolitical ideology are obviously influenced by different factual beliefs about, forinstance, the most efficient use of government resources, and the likely effects ofredistribution of wealth-i.e., by beliefs about the best means to achieve certainends. But they are also influenced by disagreements over the correct ends to pursue,and the relative importance of moral values such as fairness, equality, self-determination, self-responsibility, and the value of life.Moral values can affect voting about value of life issues, such as abortion or gaymarriage. But their effects extend well beyond these familiar examples. They alsoaffect political opinions about economic, environmental, health-care, and foreignpol icy issues, to namejust a few examples (see e.g., Rorty 1999). Perceptions aboutthe objectivity of these opinions, and the values underlying them, may playa role invoting behavior in the following sense.Some values are considered to be 'sacred' orprotected' (see e.g., Baron and Spranca 1997; Tetlock et al. 2000; Tetlock 2003), inthat they are thought to be so important that they should not be compromised.Tetlock et al. (2000), demonstrated the existence of such 'taboo trade-offs'. Theyshowed that the mere contemplation of a trade-off between a sacred value such asthe right to vote, and money (i.e., a scenario in which votes were bought in anelection) elicits both moral outrage, and a desire for moral 'cleanSing'. Baron andSpranca (1997) showed that values which people claim ought never be compro-mised, are associated with several other psychology properties, including quantityinsensitivity (people are insensitive to the amount of the compromise), agentrelativity (the agent's participation in breaching the value is what matters most, not~ SpringerG.P. Goodwin, J.M. Darleythe consequencesof the breach), and moral obligatoriness (that is, they are treated asholding independently of whether people think that is the case).Voting, of course, inherently involves compromise and trade-off-no one politicalcandidate is likely to endorse the full range of values that you do. But a protected orsacred value is one that is unlikely to be compromised when voting. However, it isnot entirely clear why some values are considered sacred or protected, and others arenot. One factor that might predict this is objectivity (Baron and Spranca 1997, makea similar suggestion). Hence, we would predict that if a moral value is thought to beObjective, it is more likely to be afforded a sacred or protected status-and thus, anindividual will be unwilling to compromise on that value when deciding how tovote. Again, no data exist to support this contention, and so it is a task for futureresearch to examine it.9 Oqjectivity and MoralismOne final connection with public policy stems from an intriguing recent study whichinvestigated how broadly individuals construe the moral universe. Lovett and Jordan(2005) investigated whether or not people view a range of everyday activities asimbued with a moral quality-a tendency they refer to as 'moralism'. Theydemonstrated that people who voted for George Bush in the 2004 US Presidentialelection were more likely to moralize than were people who voted for John Kerry.That, is they were more likely to perceive activities such as sleeping in late,overeating, and taking on a challenging college course, as involving a moral aspect.One interpretation of this finding is that such voters were more inclined to seepersonal or private virtue as fundamentally a moral issue.A tendency to moralize is not the same as a tendency to view moral values asobjective. A person might see only a limited range of activities as involving a moralcomponent, but perceive such values to be highly objective. Thus, an interestingpsychological question arises as to whether individuals who tend to be Objectiveabout moral values are also more likely to see a larger range of activities asinvolving a moral component-i.e., to 'moralize'. We suspect that this is the case,although again, this is a question for future research.10 ConclusionThe psychological investigation of ethical objectivity is in its infancy, but importantfindings have been made. We have argued that there are systematic sources ofvariance with respect to ethical objectivity. Some individuals treat their ethicalbeliefs as more objective than do others, and this appears to be predicted partly bythe religious grounding of ethics, and partly by a disposition towards di~unctivethinking. Other factors may yet be discovered which yield further insight into thisindividual difference. Moreover, some ethical beliefs are treated as more objectivethan others and this appears to be predicted by the valence of the action underconsideration, and may also be predicted by social factors such as perceivedconsensus. Holding an objective view predicts a more 'closed' response to ethical~ SpringerThe Perceived Objectivity of Ethical Beliefsdisagreement, which has implications for how real ethical disputes may be resolved.Many questions still remain to be answered, and we have described several whichwe think are worth pursuing next.Acknowledgements We thank Adam Alter, Walter Sinnott-Armstrong, and an anonymous reviewer forhelpful comments on an earlier draft.ReferencesAjzen, I., and M. Fishbein. 1975. Belief, attitude, intention and behavior: An introduction to theory andresearch. Reading: Addison-Wesley.Ajzen, I., and M. Fishbein. 1977. Attitude-behavior relations: a theoretical analysis and review ofempirical research.Psychological Bulletin 84: 888-918.Ajzen, I., and M. Fishbein. 1980. Understanding attitudes and predicting social behavior. EnglewoodCliffs: Prentice-Hall.Ayer, A.J. 1936. Language, truth, and logic. London: Gollancz.Baron, J., and M. Spranca. 1997. Protected values. Organizational Behavior and Human DecisionProcesses70: 1-16.Blackburn, S. 1984. Spreading the word. Oxford: Oxford University Press.Blackburn, S. 1993. Essays in quasi-realism. New York: Oxford University Press.Blackburn, S. 1998. Ruling passions. New York: Oxford University Press.Brink, D. 1986. Externalist moral realism. Southern Journal of Philosophy 24(Suppl): 23-42.Bucciarelli, M., S. Khemlani, and P.N. Johnson-Laird. 2008. The psychology of moral reasoning.Judgment and Decision Making 3: 121-139.Burden, B.C. 2004. An alternative account of the 2004 Presidential election. The Forum, 2. http://www.bepress.com/forum/, last accessedon October 10, 2008.Cacioppo, J.T., R.E. Petty, and C.F. Kao. 1984. The efficient assessmentof needfor cognition. Journal ofPersonality Assessment48: 306-307.Cushman, FA, L. Young, and L.D. Hauser.2006. The role of reasoningand intuition in moraljudgments:testing three principles of harm. Psychological Science 17: 1082-1089.Darley, J.M., and T.R. Shultz. 1990. Moral rules: their content and acquisition. Annual Review ofPsychology 41: 525-556.Epstein, S. 1991. Cognitive-experiential self-theory: An integrative theory of personality. In The relationalself: Theoretical convergences in psychoanalysis and social psychOlogy,ed. R.C. Curtis, 111-137.New York: Guilford.Epstein, S. 1994. Integration of the cognitive and the psychodynamic unconscious. American Psychologist49: 709-724.Fiorina, M., C.M. Abrams, and J.C. Pope. 2004. Culture war? The myth of a polarized America. NewYork: Longman.Forsyth, D.R. 1980. A taxonomy of ethical ideologies. Journal of Personality and Social Psychology 39:175-184.Forsyth, D.R. 1981. Moraljudgment: the influence of ethical ideology. Personality and Social PsychologyBulletin 7: 218-223.Forsyth, D. R., and W. R. Pope. 1984. Ethical ideology andjudgments of social psychological research:Multidimensional analysis. Journal of Personality and Social Psychology 46: 1365-1375.Forsyth, D.R., and R.E. Berger. 1982. The effects of ethical ideology on moral behavior. Journal of SocialPsychology 117: 53-56.Frederick, S. 2005. Cognitive reflection and decision making. Journal of Economic Perspectives19: 24-42.Gabennesch, H. 1990a. The perception of social conventionality by children and adults. ChildDevelopment 61: 2047-2059.Gabennesch, H. 1990b. Recognizing conventionality: reply to Shweder and Helwig et al. ChildDevelopment 61: 2079-2084.Gert, B. 2005. Morality: Its nature and justification (Rev. ed.). New York: Oxford University Press.Gibbard, A. 1990. Wise choices, apt feelings. Cambridge: Harvard University Press.Gibbard, A. 2003. Thinking how to live. Cambridge: Harvard University Press.~ SpringerG.P. Goodwin, J.M. DarleyGill, M.B. 2008. Metaethical variability, incoherence,and error. In Moral psychology,Vol. 2, The cognitivescience of morality: Intuition and diversity, ed. W Sinnott-Armstrong, 387-401. Cambridge: MITGill, M.B. 2009. Indeterminacy and variability in metaethics. Philosophical Studies 145: 215-234.Goodwin, G.P. 2009. Individual differences in judgments of moral objectivity. Manuscript in preparation.Goodwin, G.P., and J.M. Darley. 2008. The psychology of meta-ethics: exploring oQjectivism. Cognition106: 1339-1366.Goodwin, G.P.,and J.M. Darley. 2009. Why are somemoral beliefs treated more objectively than others?:Implications for ethical disagreement. Manuscript in preparation.Graham, J., J. Haidt, and B. A. Nosek. 2009. Liberals and conservatives rely on different sets of moralfoundations. Journal of Personality and Social Psychology 96: 1029-1046.Greene,J.D. 2002. The terrible, horrible, no good, very bad, truth about morality and what to do about it.Doctoral dissertation, Department of Philosophy, Princeton University.Greene,J.D., R.B. Sommerville, L.E. Nystrom, J.M. Darley, and J.D. Cohen. 2001. An fMRI investigationof emotional engagement in moral judgment. Science 293: 2105-2108.Greene, J.D., L.E. Nystrom, A.E. Engell, J.M. Darley, and J.D. Cohen. 2004. The neural bases ofcognitive conflict and control in moral development. Neuron 44: 389-400.Haidt, J. 2001. The emotional dog and its rational tail: a social intuitionist approach to moral judgment.Psychological Review 108: 814-834.Haidt, J. 2007. The new synthesis in moral psychology. Science 316: 998-1002.Haidt, J., and J. Graham. 2007. When morality opposesjustice: conservatives have moral intuitions thatliberals may not recognize. Social Justice Research20: 98-116.Haidt, 1. S.H. Koller, and M.G. Dias. 1993. Affect, culture, and morality, or is it wrong to eat your dog?Journal of Personality and Social Psychology 65: 613-628.Harman, G. 1975. Moral relativism defended. Philosophical Review 84: 3-22.Hauser,M.D., FA Cushman, L. Young, R. Kang-Xing Jin, and J. Mikhail. 2007. A dissociation betweenmoral judgments andjustifications. Mind and Language 22: 1-21.Helwig, C.C., M.S. Tisak, and E. Turiel. 1990. Children's social reasoning in context: reply toGabennesch.Child Development 61: 2068-2078.Hillygus, D.S., and TG. Shields. 2005. Moral issuesand voter decision making in the 2004 Presidentialelection. Political Science and Politics 38: 201-210.Hunter, J.D. 1991. Culture wars: The struggle to define America. New York: Basic Books.Jost, J.T 2006. The end of the end of ideology. American Psychologist 61: 651-670.Joyce, R. 2009. Review: JesseJ. Prinz: The emotional construction of morals. Mind 118: 508-518.Kant, I. 1959. Foundations of the metaphysicsof morals (L.W Beck Trans.). Indianapolis: Bobbs-Merrill(Original work published 1786).Kelly, D., S. Stich, K.J. Haley, S.J. Eng, and D.M.T. Fessler. 2007. Harm, affect, and the morallconventional distinction. Mind and Language 22: 117-131.Kohlberg, L. 1963. The development of children's orientation toward a moral order. I. Sequence in thedevelopment of moral thought. Vita Humana 1: 11-33.Kohlberg, L. 1969. Stage and sequence: The cognitive-developmental approach to socialization. InHandbook of socialization theory and research, ed. D.A. Goslin. New York: McNally.Kohlberg, L. 1976. Moral stages and moralization: The cognitive-developmental approach. Moraldevelopment and behavior: Theory, research, and social issues,ed. 1. Lickona, 31-53. New York:Holt, Rinehart & Winston.Kohlberg, L. 1981. Essayson moral development (Vol. 1). The philosophy of moral development: Moralstagesand the idea of justice. San Francisco: Harper & Row.Kruglanski, A.W, D.M. Webster,and A. Klem. 1993. Motivated resistanceand opennessto persuasion inthe presenceor absenceof prior information. Journal of Personality and Social Psychology 65: 861-876.Lacey, A.R. 1996. A dictionary of philosophy, 3rd ed. London: Routledge.Langer, G., and J. Cohen. 2005. Voters and values in the 2004 election. Public Opinion Quarterly 69:744-759.Lessig, L. 1996. Social meaningand social norms.University of Pennsylvania Law Review144: 2181-2189.Levesque, H.J. 1986. Making believers out of computers. Artificial Intelligence 30: 81-108.Levesque, H.J. 1989. Logic and the complexity of reasoning. In Philosophical logic and artificialintelligence, ed. R.H. Thomason, 73-107. Dordrecht: Kluwer Academic.Lovett, B.J., and A.H. Jordan. 2005. Moral values, moralism, and the 2004 Presidential election. Analysesof Social Issuesand Public Policy 5: 165-175.Mackie, J.L. 1977. Ethics: Inventing right and wrong. New York: Penguin.~ SpringerMoll, J.R., R. de Oliveirra-Souza, and P.J.Eslinger. 2003. Morals and the human brain: a working model.Neuroreport 14: 299-305.Monin, B., and D.T. Miller. 2001. Moral credentials and the expression of pr~udice. Journal ofPersonality and Social Psychology 81: 31-43.Moore, A.B., B.A. Clark, and M.J. Kane. 2008. Who shalt not kill? Individual differences in workingmemory capacity, executive control. and moral judgment. Psychological Science 19: 549-557.Nadler, J. 2005. Flouting the law. Texas Law Review 83: 1399-1441.Nagel, T. 1970. The possibility of altruism. Princeton: Princeton University Press.Nagel, T. 1979. Mortal questions. Cambridge: Cambridge University Press.Nagel, T. 1997. The last word. New York: Oxford University Press.Nichols, S. 2002. Norms with feeling: toward a psychological account of moral judgment. Cognition 84:223-236.Nichols, S. 2004. Sentimental rules: On the natural foundations of moral judgment. Oxford: OxfordUniversity Press.Nichols, S., and T. Folds-Bennett. 2003. Are children moral objectivists? Children's judgments aboutmoral and response-dependentproperties. Cognition 90: B23-B32.Over, D., J. St. B. T. Evans, and S. Elqayam. in press. Conditionals and non-constructive reasoning. InCognition and conditionals: Probability and logic in human thought, ed. M. Oaksford. Oxford:Oxford University Press.Piaget, J. 1965. The moral judgment of the child. New York: Free Press.Prinz, J.J. 2006. The emotional basis of moral judgments. Philosophical Explorations 9: 29-43.Prinz, J.J. 2007. The emotional construction of morals. Oxford: Oxford University Press.Putnam, H. 1987. The many faces of realism. LaSalle: Open Court.Railton, P. 1986. Moral realism. Philosophical Review 95: 163-207.Reber, A. 1996. The penguin dictionary of psychology, 2nd ed. London: Penguin.Robinson, P.H., and J.M. Darley. 1997. The utility of desert. Northwestern University Law Review 91:453-499.Rorty, R. 1999. Achieving our country: Leftist thought in twentieth-century America. Cambridge: HarvardUniversity Press.Rosen, H. 1980. The development of sociomoral knowledge. New York: Colombia University Press.Ross, L., and A. Ward. 1995. Psychological barriers to dispute resolution. Advances in ExperimentalSocial Psychology 27: 255-304.Royzman, E.B., R.F. Leeman, and J. Baron. 2009. Unsentimental ethics: Towards a content specificaccount of the moral-conventional distinction. Cognition 112: 159-174.Rozin, P., L. Lowery, S. Imada, and J. Haidt. 1999. The CAD triad hypothesis: a mapping between threemoral emotions (contempt, anger, disgust) and three moral codes (community, autonomy, divinity).Journal of Personality & Social Psychology 76: 574-586.Sachdeva,S., R. lIiev, and D.L. Medin. 2009. Sinning saints and saintly sinners: the paradox of moral self-regulation. Psychological Science 20: 523-528.Sanfey, A.G., J.K. Rilling, JA Aronson, L.E. Nystrom, and J.D. Cohen. 2003. The neural basis ofeconomic decision-making in the ultimatum game. Science 300: 1755-1758.Sayre-McCord, G. 1986. The many moral realisms. The Southern Journal of Philosophy 24(Suppl): 1-22.Schifter, D.E., and I. Ajzen. 1985. Intention, perceived control, and weight loss: an application of thetheory of planned behavior. Journal of Personality and Social Psychology 49: 843-851.Schnall, S., J. Haidt, G.L. Clore, and A.H. Jordan. 2008. Disgust as embodied moral judgment.Personality and Social Psychology Bulletin 34: 1096-1109.Sears, D.O., R.L. Lau, T.T. Tyler, and H.M. Allen Jr. 1980. Self-interest vs. symbolic politics in policyattitudes and presidential voting. The American Political Science Review 74: 670-684.Shantz, C.U. 1982. Children's understanding of social rules and the social context. In Social cognitivedevelopment in context, ed. F.C. Serifica, 167-198. New York: Guilford.Shweder, RA 1990. In defense of moral realism: reply to Gabennesch.Child Development 61: 2060-2067.Shweder, R. A. 2003. Why do men barbecue?: Recipesfor cultural psychology. Harvard University Press.Shweder, R.A., N.C. Much, M. Mahapatra, and L. Park. 1997. The "big three" of morality (autonomy,community, and divinity), and the "big three" explanations of suffering. In Morality and health, ed. A.Brandt, and P. Rozin, 119-169. New York: Routledge.Sinnott-Armstrong, W. 2006. Moral skepticisms. New York: Oxford University Press.Sinnott-Armstrong, W. 2009. Mixed-up meta-ethics. Philosophical Issues19: 235-256.Smith, M. 1994. The moral problem. Oxford: Blackwell.The Perceived OQjectivity of Ethical Beliefs~ SpringerG.P. Goodwin, J.M. DarleySnare, F. 1992. The nature of moral thinking. London: Routledge.Stevenson, C.L. 1937. The emotive meaning of ethical terms. Mind 46: 14-31.Sturgeon, N. 1985. Moral explanations. In Morality, reason and truth, ed. D. Copp, and D. Zimmerman,49-78. Totowa: Rowman & Allenheld.Sunstein, C. 1996. On the expressive function of law. The University of Pennsylvania Law Review 144:2021-2053.Tetiock, P.E. 2003. Thinking the unthinkable: sacred values and taboo cognitions. Trends in CognitiveSciences 7: 320-324.Tetiock, P.E., O.v. Kristel, B. Elson, M. Green, and J. Lerner. 2000. The psychology of the unthinkable:taboo trade-offs, forbidden baserates, and heretical counterfactuals. Journal of Personality and SocialPsychology 78: 853-870.Tisak, M.S., and E. Turiel. 1988. Variation in seriousness of transgressions and children's moral andconventional concepts. Developmental Psychology 24: 352-357.Toplak, M.E., and K.E. Stanovich. 2002. The domain specificity and generality of di~unctive reasoning:Searching for a generalizable critical thinking skill. Journal of Educational Psychology 94: 197-209.Turiel. E. 1978. Social regulations and domains of social concepts. In New directions for childdevelopment. Vol. 1. Social cognition, ed. W. Damon, 45-74. New York: Gardner.Webster, D.M., and A.W. Kruglanski. 1994. Individual differences in need for cognitive closure. Journalof Personality and Social Psychology 67: 1049-1062.Wheatley, T., and J. Haidt. 2006. Hypnotic disgust makes moral judgments more severe. PsychologicalScience 16: 780-784.Williams, B. 1972. Morality: An introduction to ethics. New York: Harper & Row.Williams, B. 1985. Ethics and the limits of philosophy. Harvard: Harvard University Press.~ Springer
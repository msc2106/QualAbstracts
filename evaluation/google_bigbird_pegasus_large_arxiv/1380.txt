ABSTRACT: 
The study of simple talk and silence indices that characterize conversation is limited by the costly, labor-intensive character of data collection and analysis. In the face of results demonstrating the significance of these data in interpersonal judgments (Hayes & Meltzer, 1972; Lustig, Note I), more efficient collection, storage, and analysis methods are required. This report describes a hardware and software system, FIASSCO, that collects, stores, and analyzes two-person separate-channel audio-recorded conversations for various indices of talk and silence. Data output are both continuous and discrete measures in time sequence. Further, data on the validity and reliability of FIASSCO output are provided along with sample analyses of computer results. 
 
PREDICTION: 
this paper presents an investigation into a problem of identifying the intrinsic frequency of an audio signal in the context of a talk given by a human being .<n> the main result of the paper is that there is a natural way to identify the intrinsic frequency of a signal in a situation where the talk is given by a human being .<n> the paper presents a number of examples of situations where the identified intrinsic frequency is different from the rest of the spectrum of the signal .<n> the analysis is carried out in the context of a talk given by a human being .<n> in particular , the paper presents an identification of the intrinsic frequency of a signal in a situation where the talk is given by a human being .<n> the paper presents a number of examples of situations where the identified intrinsic frequency is different from the rest of the spectrum of the signal .<n> the paper presents a number of examples of situations where the identified intrinsic frequency is different from the rest of the spectrum of the signal . <n> [ [ section ] ] the study of the intrinsic frequency of an audio signal is of interest in several fields of research .<n> it is relevant to many areas of research , e.g. , in the fields of natural sciences , social 
 
FULL TEXT: 
 that collects, stores, and analyzes two-person separate-channel audio-recorded conversations for variousindices of talk and silence. Data output are both continuous and discrete measures in time sequence. Further,data on the validity and reliability of FIASSCO output are provided along with sample analyses of computerresults.CommentsNOTE: At the time of publication, author Joseph Cappella was affiliated with the University of Wisconsin.Currently, he is a faculty member of the Annenberg School for Communication at the University ofPennsylvania.This journal article is available at ScholarlyCommons: http://repository.upenn.edu/asc_papers/109Behavior Research Methods & Instrumentation1979, Vol. 11 (3),384-392Computer analysis of talk-silence sequences:The FIASSCO systemJOSEPH N. CAPPELLA and MICHAEL J. STREIBELCenter for Communication Research, Department ofCommunication ArtsUniversity of Wisconsin, Madison, Wisconsin 53706The study of simple talk and silence indices that characterize conversation is limited bythe costly, "labor-intensive" character of data collection and analysis. In the face of resultsdemonstrating the significance of these data in interpersonal judgments (Hayes & Meltzer,1972; Lustig, Note I), more efficient collection, storage, and analysis methods are required.This report describes a hardware and software system, FIASSCO, that collects, stores, andanalyzes two-person separate-channel audio-recorded conversations for various indices of talkand silence. Data output are both continuous and discrete measures in time sequence. Further,data on the validity and reliability of FIASSCO output are provided along with sample analysesof computer results.This report presents a computer-assisted method ofcoding and analyZing sound-silence pattemsin dyadicrelationships. Specifically l it details the procedures usedat the University of Wisconsin's Center for Communica-tion Research for automatically recording, digitizing,storing, and analyzing the sound-silence patterns that arefound in dyadic communication. These procedures havebeen developed as an integrated research approach byutilizing the potential of the center's PDP-12 computer.A discussion of how the various programs analyze asample dyad and a reliability test of these analyses ar~presented.THEORY AND RATIONALEIt is reasonable to ask if the intensive study of simple,naked behaviors such as talk and silence is likely to offerany practical insight into interpersonal communicationsituations. An extensive review of the literature onsimple talk and silence indices by Lustig (Note 1)produces the following: Talkative persons are moreproductive (Norfleet, 1948), more task oriented(Knutson, 1960; Strodtbeck & Mann, 1956), more"leader-like" (Bass, 1949, 1951; Borgatta & Bales,1956; French, 1950; Jaffe & Lucas, 1969), moreinfluential (Bales, 1953; Riechen, 1958; Strodtbeck,1951), more socially adept (Knutson, 1960; Muir,1964; Philips, 1965, 1968; Steward, 1968), and betterliked (Bales, 1953; Bavelas, Hastorf, Gross, & Kite,1965; Strodtbeck & Hook, 1961) than their less verbalcounterparts.The development of the FIASSCO system was made possibleby grants from the Graduate Research Committee and theCollege of Letters and Sciences of the University of Wisconsin.Early work on the hardware aspects of FIASSCO owes muchto Michael Redmond and Ken Emmerich; early softwaredevelopments were advanced by Dan Fogel.Based upon a similar but less comprehensive review,Hayes and Meltzer (1972) conclude, "the foregoingresults and theoretical positions could easily explainand justify an intensive interest ... in the quantitativeaspects of that most social of social behaviors~talk.But the strange fact is that most ... have been curiouslyuninterested in these nonverbal but vocal features ofinteraction" (p. 5).It is curious that the study of talk and silencebehaviors has been neglected despite the avalanche ofevidence attesting to its predictive utility. It is quitepossible that this neglect is based upon a suspicion thatjudgments apparently based on overt simple behaviorsare actually confounded with the supposed richercontent dimensions of speech. Given the researchof Hayes and Meltzer (1972), Soskin and Kaufman(1961), and Starkweather (1956, 1961), the abovesuspicion appears to have no basis.A second reason for avoiding the study of talk andsilence behaviors is that the research is time consumingand, in general, labor intensive. The few attempts atprogrammatic research have relied on various types oftechnological aids to assist in the recording and analysisof talk and silence activity (Cassotta, Jaffe, & Feldstein,1964; Chapple, 1949; Matarazzo, Saslow, & Saslow,1956). The most sophisticated of these was developedand implemented by Jaffe and Feldstein (1970) andtheir associates (Welkowitz & Martz, Note 2) and iscurrently operating in the departments of psychologyat New York University and the University of Maryland,Baltimore County. This system (the AVTA) completelyautomated the collection, transformation, storage, and(at least partially) the analysis of talk and silence data.The AVTA frees the researcher from the necessity ofhaving human coders present during conversations orhaving coders categorize talk and silence behaviorsfrom audio- or videotapes. Consequently, problems ofCopyright 1979 Psychonomic Society, Inc. 384 0005-7878/79/030384-09$01.15/0coder fatigue, coder reliability, time, and financialcosts are substantially minimized. The possibility ofextensive data gathering is enhanced. We report a verysimilar but more flexible automatic talk and silencerecording system called FIASSCO (fundamentalinterpersonal arrangement of sounds and silences inconversational occurrences).The FIASSCO system permits the collection, trans-formation, and storage of talk and silence data in bothdiscrete and continuous form. The discrete data are inthe form of frequencies and probabilities of variousdyadic states. Following Jaffe and Feldstein (1970),these states include a four-state description in whichState 1 = both Person A and Person B silent, State 2 =both A and B talking, State 3 = A talking and B silent,and State 4 = A silent and B talking, and a six-statedescription in which State 1 = A and B silent but A hasthe floor, State 2 = A talking and B silent, State 3 = Aand B talking but A has the floor, State 4 =A and Bsilent but B has the floor, State 5 = A silent and Btalking, State 6 = A and B talking but B has the floor.The discrete state description permits the analysis andrepresentation of talk and silence sequences as somestochastic process, for example,. a Markov chain(Cappella, 1976; Jaffe, 1970; Jaffe & Feldstein, 1970;Cappella, Note 3).The continuous form of the data summarizes theduration of various indices during each turn of eachspeaker. Jaffe and Feldstein (1970, pp. 18-21) postulatea mutually exclusive and exhaustive descriptive schemethat includes vocalizations (continuous sounds made bya speaker bounded by silence on both sides), pauses(silences made by a speaker bounded on both sides bya vocalization by the same speaker), switching pauses(silences made by speaker bounded on one side byvocalization of the speaker and on the other side by avocalization by the other speaker), and simultaneousspeech (simultaneous vocalizations by both speakerswhen one of them has the floor). These data makepossible the kind of descriptive and predictive studiescited earlier in the Lustig (Note 1) review, as well asstudies of matching and synchronization carried out byFeldstein and his colleagues (see Feldstein & Welkowitz,1978, for a review), Natale (1975a), and Webb (1972).A second kind of continuous data is also availablefrom typical talk and silence analysis, namely, vocalintensity. As a simple by-product of collecting talk andsilence data, the intensity of the talk response is alsoroutinely stored. These data could be used for studiesof convergence in vocal intensity (Natale, 1975b),for studies of interruption outcomes (Meltzer, Morris,& Hayes, 1971), or for studies of responsiveness orinvolvement.Each of these types of data is routinely availablefrom the analysis of any audiotape using FIASSCO.Our current research efforts are aimed at studies ofsequential structure in talk and silence and studies ofmatching and synchronization in the various durationalmeasures.TALK-SILENCE SEQUENCES 385METHODSubjects and DesignIn the typical experiment, subjects are brought into acomfortably furnished experimental room and outfitted witheither throat microphones (Audiotone , Phoenix, Arizona)or miniature boom microphones (Plantronics, Santa Cruz,California). The wires from these microphones, as well as thosefrom a room microphone (AKG, 0-109 200 ohms), are connectedto cables that run through the wall to the adjoining computerroom. Subjects are then instructed to discuss a certain pre-arranged topic and are left alone without time constraintsplaced on their discussion. The dialog of each dyad is recordedon a four-channel tape recorder (Sony TC-366-4, quadraphonicstereo) with the room microphone recorded on one channel andeach subject recorded on a separate channel. The fourth channelis left empty for the later insertion of cue pulses.Apparatus and ProcedureThe overall flow of information and analysis proceeds fromthe dyad onto an audiotape and then, either immediately orlater, through electronic smoothing and digitizing circuitry intoa computer-stored data base. The various summaries, analyses,and calculations then proceed under the control of a researcherin an interactive fashion with the computer. The output fromthe programs that perform the various functions remains in thecomputer's data base and can be printed or transmitted to othercomputers at any time. Figure 1 schematizes the overall flow ofinformation and analyses.The audio signal from each person in the dyad can beprocessed (Le., electronically rectified, smoothed, and digitized)in real-time while the discussion is going on, or it can beprocessed from a previously recorded audiotape. The audiosignal is fed into a custom-built patch-panel circuit (PPC) whereEXPT~v~ ~~~~ C0Q.O ML PUAUDIO .. I,m, TETA PE PANEL R/ RI P 00 ~PADCON.BA i~ 2AV STAT.BA~~FLRTI M.BA MATDIS.BA.------- +--------..STADIS.BA HOMOG.BA INDEC.BAFigure I. A schematic representation of the FlASSCOsystem.386 CAPPELLA AND STREIBELit can be electronically mixed, rectified, and smoothed as desired(see Figure I). The smoothing circuit has a rise time of 21 msecin response to a square wave. Tlus was designed so that within-word silences would be less likely to be digitized as silences.The audio signal from the patch panel is then fed into an analog-t<K1igital (A/D) converter that operates under the PDP-12computer's program control. The A/D converter senses an audiosignal varying between + I Y and -I Y and converts this signalinto integer numbers that range from -511 to +511 (0 to+511 when the signal has been rectified into a positive voltage).The voltage level of the audio signal can be manually adjustedby the tape-recorder output and/or PPC.Figure I (bottom block) shows the various programs usedto digitize and analyze the audio signal. These programs arewritten in BASIC and are stored by the PDP-12's disk-basedoperating system (DOS/I 2). The researcher sits at the PDP-12console and executes each program as required. The outputfrom each of these programs is stored as a text file by thePDP-12 computer. The output fIles can be printed, transmittedto other computers over the telephone, or read by otherprograms as input for their analyses. What follows is a briefdiscussion of each of these programs and how they are used withdyadic sound-silence data. Output examples from some of theseprograms are given in the appendices for the six-state analyses.The four-state outputs are comparable.turn initiation time and duration of vocalization, pause,switching pause, simultaneous speech, and floor time for eachfloor tum. The start time and duration of each of thesecategories is presented in 300-msec time units. fLRTlM.BAtherefore provides a complete and convenient summary of thesix-state time-series data. A portion of the data presen ted inAppendix B is presented in Appendix C after analysis byFLRTIM.BA. This program also has an option to store and/orprint only a summary of the conversation. Under this option,only total vocalization time, total pause time, and totalsimultaneous speech duration are printed for each speaker tum.Typically, the output from FLRTIM.BA is transferred to largercomputers, where the statistical software necessary to carryout time-series analyses of the data (e.g., Cappella, in press)is available.MATDIS.BA. This program takes AYSTAT.BA output andcalculates a frequency and probability transition matrix forprespecified time units within the dyadic conversation, as wellas a composite frequency and probability transition matrix.A researcher can therefore immediately know the frequency andprobability of state sequences in the four- or six-state data (seeAppendix D). MATDIS.BA also calculates the individualcontingent probabilities that Person A or B will talk, given oneof the prior dyadic states according to the fonowing formulas(Jaffe & Feldstein, 1970).where Pij(T,k) is the ijth transition element from the compositetransition matrix of the kth conversation, Pij(t,k) is the ijthelement of the tkth matrix, and fi,(t,k) is the row frequency ofwhere the Pi*(t,k,A) are the individual contingent probabilitiesat time t, conversation k, that Person A will talk at t + I giventhe prior state of the dyad is i and where Pii(t,k) is theprobability of transition from state i to state j at time t andin conversation k. Typically, conversations are broken into2-min time units that guarantee data per cell sufficient to insurenonzero row frequencies (400 observations at 30G-msec timeunits).The output from MATDIS.BA is stored for subsequentanalysis by programs testing Markov chain assumptions andpredictions (Hewes, 1975, in press; Kemeny & Snell, 1960) oris transferred to larger computers where software necessary tocarry out other analyses is available.STADIS.BA. This program tests the stationarity assumptionof MATDIS.BA output by taking the initial transition matrixto the Mth power (Le., predicted matrix), where M is the numberof arbitrarily defined time units in the discussion, and comparingit with the product of the M transition matrices (Le., observedmatrix). A discrepancy matrix between the predicted andobserved matrices indicates the degree to which these data fita first order Markov chain (Kemeny & Snell, 1960). A chi-square measure of discrepancy for each of the M matrices fromthe composite matrix is calculated as follows.ProgramsADCON.BA. This program converts the incoming audiosignal from each person into digital form and stores thesenumbers in a fIle for later use (see Appendix A). Its utility liesin the fact that it permits a researcher to specify the samplingrate at which the audio signal is digitized. We have settled on a5G-msec sampling rate. This means that we convert each secondof dialog of each person in the dyad into 20 numbers that rangefrom 0 to 511. This rate, in conjunction with the electronicand statistical smoothing of the audio signal, is sufficient todiscriminate between-word silences for each person withoutpicking up within-word silences (see Goldman-Eisler, 1958;Jaffe & Feldstein, 1970, Appendix A; see also data reportedbelow). The statistical smoothing involves the calculation of amoving average typically 5 sampling units in duration. Themoving average has the same effect as the electronic smoothing,minimizing substantially the presence of sharp peaks andtroughs. The program ADCON.BA also permits the researcherto type an extensive header text into the output file so thatthe analysis is clearly identified. Another useful feature ofADCON.BA is that the digitized audio signal can be displayedon a cathode-ray tube (CRT). This permits the researcher toadjust signal levels and to choose when to store data.AYSTAT.BA. This program takes ADCON.BA output andaverages any number of data points into a single number; itthen converts these data into a four- or six-state string ofnumbers. Typically, we average six data points so that theresultant string of numbers reflects the audio signal as if it hadbeen sampled and digitized once every 300 msec. A silencebetween words therefore must be at least 300 msec before it iscounted as a silence. AYSTAT.BA also permits the researcher tospecify a cut-off level below which an audio signal is considerednoise. The cut-off levels are chosen on a pragmatic andexperiential basis after ADCON.BA output is examined. Thesame procedure is typically employed by Jaffe and Feldstein(1970). The four- and six-state analyses proceed according tothe scheme described earlier for coding discrete talk and silencedata. The output of AYSTAT.BA is therefore a string ofnumbers (1-4 or 1-6) that reflects the state of the sound-silencepatterns every 300 msec for however long one chooses (seeAppendix B). AYSTAT.BA output can be read by eitherFLRTIM.BA or MATDIS.BA.FLRTIM.BA. This program performs an analysis of the six-state time-series data calculated by AYSTAT.BA and categorizesthese data sequentially for each person according to the within-Pi*(t,k,A) = Pi2(t,k) + Pi3(t,k)Pi*(t,k,A) = Pi2(t,k) + Pi6(t,k)Pi*(t,k,B) = pdt,k) + Pi5(t,k)Pi*(t,k,B) = Pi5(t,k) + Pi6(t,k)And, for the four-state description,Pi*(t,k,A) = Pi2(t,k) + Pi3(t,k)Pi*(t,k,B) = Pi2(t,k) + Pi4(t,k)fi (t,k) [Pij(t,k) - Pij(T,k)1'x' = L L -'--------i i Pij(T,k)i = 1,2,3i = 4,5,6i = 1,2,3i = 4,5,6,i=I,2,3,4i= 1,2,3,4,t = 1,2,... ,M,TALK-SILENCE SEQUENCES 387INDEC.BA has been used to produce the data reported inCappella (Note 3).the same matrix (Hewes, in press). This value is distributed aschi square with 12 deg of freedom in the four-state case and18 deg of freedom in the six-state case and serves as a statistictesting the assumption of stationarity.HOMOG.BA. This program takes the frequency andprobability output from MATDIS.BA and tests the homogeneityassumption of a first order Markov chain of two or morecomposite matrices against the overall composite by a chi-squaretest (Hewes, in press):SummaryThe sequence of programs from ADCON.BA to INDEC.BAmake possible the automatic collection, storage, and analysis ofdurational and discrete talk and silence data. The researchercan take a recorded two-channel conversation and, in a shorttime, have a complete description of the distribution of talk andsilence parameters across time, across person, and across timeand person for several different indices. What remains to be seenis whether basic talk and silence data acq uired by r:IASSCOare comparable to those acquired by other systems.G [p..(T,g) - p.. (G)] •x• = ~ ~ ~f. (T) lj lj• • 1. ,g (G)g 1 ) Pijwhere Pij(G) is the ijth element of the composite matrix acrossall G groups, Pij(T,g) is the ijth element of the composite transi-tion matrix of the gth group, and fi (T,g) is the row frequency ofthe latter matrix. HOMOG.BA can test homogeneity for as manyas 10 transition matrices simultaneously.INDEC.BA. This program takes MATDIS.BA output ofthree dyadic discussions, uses the individual parameters of thesame two persons in these discussions to predict a newcomposite transition matrix, and compares it to the observedmatrix for these two persons in these discussions to predict anew composite transition matrix, and compares it to theobserved matrix for these two persons (Jaffe & Feldstein,1970, pp. 84-89, 111-112). For example, if Person A is matchedwith Person C in one 20-min dyadic discussion and Person B ismatched with Person D in another discussion, we can use theinformation about Persons A and B from these two discussionsto predict a transition matrix for them and compare it with anactual discussion between them. For the six-state case, thepredicted transition elements on Occasion 2, Pij, from theindividual parameters would be as follows.FIAS-SCOtJaffe andBrady* Feldstein* Lustig**Mean Vocalization 1.17 1.64 1.48 1.13DurationMean Pause.50 .66 .61LengthMean Switching.40 .77 .62Pause LengthMean Simultaneous.25 .40 .61Speech*Reported in Jaffe and Feldstein (1970, p. 128). **Datagathered with identical hardware but different software thanFIASSCO at Center for Communication Research, Madison,Wisconsin; conversations were triadic. tIn seconds; based on12 20-min conversations, 48,000 300-msec samples.COMPARABILITY OF DATATable 1Comparison of Descriptive Statistics on Vocalizations,Pauses, Switching Pauses, and SimultaneousSpeech from Several LaboratoriesDescriptive DataThere are three types of descriptive data that shouldbe compared to existing data: mean durations oncontinuous indices, distributional data on continuousindices, and sequential data on categorical indices.The last comparison is reported at length in Cappella(Note 3) and will not be repeated here.Based on 12 20-min dyadic conversations reportedin Cappella (Note 3), average durations of vocalization,pause length, switching pause length, and length ofsimultaneous speech were calculated. These meanscores are reported in Table 1 and compared to thosereported by Jaffe and Feldstein (1970) and Lustig(Note 1). Clearly, the data obtained with FIASSCO arevery similar to those reported by other procedures, withvocalization being somewhat shorter and simultaneousspeech somewhat longer than other reports.If the data obtained with FIASSCO are similar tothose obtained with other methods, then there isevidence that the continuous indices are comparableto identical indices gathered with other software andhardware systems. Figures 2, 3, and 4 provide suchevidence. These graphs depict the relationship betweenthe frequency of occurrence of various durations and theduration of vocalization (Figure 2), the duration ofpauses (including both switching pauses and within-turnIn order to insure that the FIASSCO systemproduces reliable and valid data, a series of shortstudies was carried out. A more extensive replicationand extension is reported in Cappella (Note 3). Thesestudies attempted to establish (1) the similarity betweendescriptive data obtained via FIASSCO and thoseobtained via AVTA, (2) the reliability of machine codingof a sequence of talk and silence data, (3) the degree ofdifference between machine- and human-coded talk-silence data, and (4) the adequacy of the time-samplingunit (Arundale, 1977).i= 4,5,6;i = 4,5,6;i = 4,5,6;i = 1,2,3;i = 4,5,6;i = 4,5,6;i = 4,5,6;i = 1,2,3;i = 1,2,3;i = 1,2,3;i = 1,2,3;i = 1,2,3;Pn = [1 - Pi*(T,I,A)] [1 - Pi*(T,I,B)]Pi2 = Pi*(T,I,A) [1 - Pi*(T,I,B)]Pi3 = Pi*(T,I,A) Pi*(T,I,B)Pi4 = 0Pi5 = [1- p;*(T,I,A)] Pi*(T,I,B)Pi6 = 0t>n = 0Pi2 = Pi*(T,I,A) [1 - Pi*(T,I,B)]t>i3 = 0Pi4 = [1 - Pi*(T,I,A)] [1 - pi*(T,I,B)]Pi5 = [1- Pi*(T,I,A)] Pi*(T,I,B)Pi6 = pi*(T,I,A) pi*(T,I,B)388 CAPPELLAANDSTREIBELs.F-Ri"QIu-oJIII•••10. 2,OUAA1:JON>l3-oo: m_.C". uJtH.) '.au RATIOM UOO: ::ni:II.:t uBI·I.}Figure 2. Frequency vs. duration for vocalizations. Figure 3. Freqveneyvs.duratioflforpauses.ao:Figure 4. Frequencyvs. duration forsill1uttaneous speech.the samplings in the two runs began at precisely thesame time, a cue pulse on the third channel of theaudiotape automatically initiated the sampling of the·other two channels. The pulse was less than 50 msec ..wide to insure that no initial samples in the other twochannels were missed. Sampiing in both runs was at50 msec. Each of the channels' signals was smoothed bya S.point moving average procedure and later summedover six adjacent samples, yielding a sampling unit of300 msec duration. There were 800 observations in each••pauses) (Figure 3), and the duration of simultaneousspeech (Figure 4). The functions presented are obviouslyexponential and thus match the distributions reportedin Jaffe and Feldstein (1970, pp. 75.77).Reliability DataTwo small reliability studies were carried out tocompare a machine analysis· of 6 min of a randomlyselected conversation to that .coded by two hum~coders .using a pushbutton procedure. The humancoders entered a pulse on audiotape when they detectedtalk in the conversation. Each coded independently,and the machine analyzed their pushbutton responsesand compared them to its own analysis. Of 1,200 codedtime units, the machine and Coder A agreed on 93.5%ofthe cases; the machine and Coder B agreed on 69% ofthe cases. The average agreement was 81.2%. In general,machine coding and human coding are similar, suggestingthat judges' perceptions of talk and silence are stronglyrelated to machine indices of these data.The second study sought to establish the reliabilityof the machine's analysis of a given signal. If suchreliability cannot be established, then the signalstypically analyzed would be so unstable as to insuredifferent results each time the signal was studied. Suchinstability would call into question the ability to givean unequivocal characterization of any input signal.If the representations are equivocal, then either thephenomenon is too erratic for study or the methodologyfor studying it introduces random components.Because we expect FIASSCO to be reliable, verystrict criteria for reliability are necessary. A randomlysampled +min segment of conversation was analyzedtwice using the FIASSCO system. In order to insure that388 CAPPELLA AND STREIBEL2001150 150FREQ 1005010 20DURATION (300 m.ec unltl)Figure 2. Frequency ys. duration for vocalizations.pauses) (Figure 3), and the duration of simultaneousspeech (Figure 4). The functions presented are obviouslyexponential and thus match the distributions reportedin Jaffe and Feldstein (1970, pp. 75-77).Reliability DataTwo small reliability studies were carried out tocompare a machine analysis of 6 min of a randomlyselected conversation to that coded by two humancoders using a pushbutton procedure. The humancoders entered a pulse on audiotape when they detectedtalk in the conversation. Each coded independently,and the machine analyzed their pushbutton responsesand compared them to its own analysis. Of I ,200 codedtime units, the machine and Coder A agreed on 93.5% ofthe cases; the machine and Coder B agreed on 69% ofthe cases. The average agreement was 81.2%. In general,machine coding and human coding are similar, suggestingthat judges' perceptions of talk and silence are stronglyrelated to machine indices of these data.The second study sought to establish the reliabilityof the machine's analysis of a given signal. If suchreliability cannot be established, then the signalstypically analyzed would be so unstable as to insuredifferent results each time the signal was studied. Suchinstability would call into question the ability to givean unequivocal characterization of any input signal.If the representations are equivocal, then either thephenomenon is too erratic for study or the methodologyfor studying it introduces random components.Because we expect FIASSCO to be reliable, verystrict criteria for reliability are necessary. A randomlysampled 4-min segment of conversation was analyzedtwice using the FIASSCO system. In order to insure thatFREQ 100'0010DURATION (300 muc unlta)Figure 3. Frequency ys. duration for pauses.the samplings in the two runs began at precisely thesame time, a cue pulse on the third channel of theaudiotape automatically initiated the sampling of theother two channels. The pulse was less than 50 msecwide to insure that no initial samples in the other twochannels were missed. Sampling in both runs was at50 msec. Each of the channels' signals was smoothed bya 5-point moving average procedure and later summedover six adjacent samples, yielding a sampling unit of300 msec duration. There were 800 observations in each'050'0DURATION(3QO ml.e units)Figure 4. Frequency ys. duration for simultaneous speech.Table 2Confusion Matrix Representing Two Separate FIASSCOAnalyses of a 4-Min Segment of ConversationRun 2Run I 2 3 4147 7 4 2936.8 48.2 20.6 80.82 9 195 17 343.9 57.6 24.6 96.53 0 6 64 614.8 19.5 8.3 32.64 2 0 2 20961.5 80.7 34.5 135.1Note- The first entry in each cell is the observed frequency,the second is the expected frequency.of the two runs. The first reliability test was made onthe two strings of 800 state categories (one, two, three,or four) output by AVSTAT.BA. Cut-off was set at 60.The two strings are compared in the confusion matrixof Table 2. A confusion matrix is the strictest and mostrevealing test of reliability, since any off-diagonal entryindicates a disagreement between the two runs on someparticular act. The confusion matrix represents an act-by-act assessment of reliability. Distributional andcorrelational indices mask act-by-act disagreements,whereas the confusion matrix reveals each and everydisagreement. The confusion matrix also indicates inits off-diagonal entries where the most likely disagree-ments between coding runs are to be found.The matrix shows that the most likely sources ofunreliability are in the confusions between States 1and 4 and States 2 and 3. These confusions are probablydue to the cut-off level chosen and exactly where inthe sampling unit the sampling pulse itself enters. Whilethe signals are reasonably smooth, peaks and valleysremain and the sampling pulse impinges on the signalat some random point within the sampling unit. Never-theless, reliability is excellent, with a chi square of1,737, which is significant. This chi square yields acontingency coefficient of .828, which is 95.6% of themaximum contingency coefficient for a 4 by 4 table.Thus, the two runs are highly associated.In addition to the act-by-act reliability, the outputof ADCON .BA is a string of numbers from 0 to 511representing the amplitude of the signal in each 50-msecunit. The two strings from each separate run ofADCON.BA, correlated over the first 150 observations,yielded a correlation coefficient of .987.Finally, the four-state and six-state matrices outputby MATDIS.BA for each of the two runs were comparedby a chi-square test. The two four-state matrices differedfrom the composite [X2 (12) =6.01, p>.90] and thetwo six-state matrices differed from the composite[x2 (18) =9.40, p > .90]. The transition matricesbetween runs were not different, and consequently,the individual row frequency distributions and thecontingent probabilities that are based on the transitionmatrix should not differ between reliability runs.TALK-SILENCE SEQUENCES 389Overall, machine reliability is very high for act-bY-act criteria, for continuous amplitude data, and fortransition matrices. We feel confident that the signaland the method of its analysis are sufficiently reliableto permit further study.Sampling UnitJaffe and Feldstein (1970, pp.116-II7, 123-130)comment at some length concerning the problems ofestablishing the appropriate fundamental samplingunit for their sound-silence studies. Based on boththeoretical considerations (Goldman-Eisler, 1958) andinvestigation of the mean sojourn times in the observedexponential distributions of pauses, switching pauses,and vocalizations, Jaffe and Feldstein settled on asampling unit of 300 msec. In reviewing their choiceof sampling unit according to guidelines developed insimulations of sampling unit, Arundale (1977) concludesthat "Jaffe & Feldstein's research thus suggests that avalue of approximately 0.3 seconds has validity as theshortest sojourn time" (p. 277). Thus there is somesupport for choosing the .3-sec unit as the samplingtime.Our data support this finding. Table 1 shows that theshortest mean sojourn time across 48,000 300-msecobservations occurs for the simultaneous speechcategory and is .61. The sampling unit then should beshorter than .61 sec to effectively resolve all of thereal transitions in the signal (Arundale, 1977; Cane,1959; Darwin, 1959). However, this datum is less thanconclusive, since the standard deviation for simultaneousspeech is large in our sample (.465), implicating a largerange of sampling units from .15 to 1.0 sec.Consequently, we chose to take a closer look at thesampling procedure adopted in AVSTAT.BA, whichaverages adjacent groups of 50-msec samples (wheregroup size varies from 1 to 10). The same 4 min of dataemployed in the machine reliability studies were usedhere, since we were confident of their stability. Thedata were averaged for I unit, 2 units, , and 10 units,yielding sampling units of 50, 100, , and 500 msec,in 50-msec increments. Nine four-state transitionmatrices were output, one for each sampling unit, andthe similarity between adjacent frequency matrices wasdescribed by a chi-square measure of discrepancy usingonly the off-diagonal frequencies. Clearly, only the off-diagonal entries should be used, since as the samplingrate increases, the diagonals will necessarily build up forany sampling unit below the minimum. The chi-squaremeasure is only a descriptive statistic, since the diagonalentries have been removed.Figure 5 graphs these values at different samplinginterval comparisons. While no statistical comparisonsare possible, there does seem to be some stabiliza-tion in the discrepancies between adjacent frequencymatrices as one moves to a sampling unit of 300 msec.Researchers with talk-silence data probably should notuse sampling intervals much larger than this given themean sojourn times of Table I. The reader is to be390 CAPPELLA AND STREIBELCONCLUSIONFigure 5. Oti-square discrepancies for transition frequencymatrices as sampling unit increases, based on off-diagonalfrequencies only.SummaryThe data reported in this section attest that theFIASSCO hardware and software system producesanalyses of talk-silence data that are comparable toresults obtained with other systems and are reliable.The sampling unit of 300 msec sec;ms to produce stabletransition matrices.REFERENCESREFERENCE NOTESI. Lustig, M. W. The relationship between communicative pre-dispositions and sound-silence patterns in triads. Paper presentedto the Speech Communication Association convention, Washing-ton, D.C., 1977.2. Welkowitz, J., & Martz, J. WELMAR: Computer programs10 analyze dialogic time patterns. Unpublished manuscript,Department of Psychology, New York University.3. Cappella, J. N. A within- and between-situation analysis oftalk-silence sequences in informal two-person conversations:Replication and extension. Unpublished paper, Center for Com-munication Research, Department of Communication Arts, Uni-versity of Wisconsin, Madison, 1978.ARUNDALE, R. B. Sampling across time for communicationresearch: A simulation. In P. M. Hirsch, P. V. Miller, & F. G.Kline (Eds.), Strategies for communication research. BeverlyHills, Calif: Sage, 1977.BALES, R. F. The equilibrium problem in small groups. In T.Parsons, R. R. Bales, & E. Shils (Eds.), Working papers in thetheory ofaction. Glencoe, III: Free Press, 1953.BASS, B. M. An analysis of leaderless group discussion. JournalofApplied Psychology, 1949,33,527-533.BASS, B. M. Situational tests: II. Variables of leaderless groupdiscussion. Educational Psychology and Measurement, 1951,11,196-207.BAVELAS, A., I-IASTORF, A. H., GROSS, A. E., & KITE, R. W.Experiments on the alteration of group structure. Journal ofExperimental Social Psychology, 1965, 1,55-70.BORGATTA, E. F., & BALES, R. F. Sociometric status patternsand characteristics of interaction. Journal of Abnormal andSocial Psychology, 1956,43,289-297.CANE, V. R. Behavior sequences as semi-Markov chains. Journalof the Royal Statistical Society, 1959, 21(Series B), 36-58.CAPPELLA, J. N. Modeling interpersonal communication systemsas a pair of machines coupled through feedback. In G. R.Miller (Ed.), Explorations in interpersonal communication.Beverly Hills, Calif: Sage, 1976.CAPPELLA, J. N. Structural equation models: An introduction.In P. R. Monge & J. N. Cappella (Eds.), Multivariate tech-niques in communication research. New York: Academic Press,in press.CASSOTA, L., JAFFE, J., & FELDSTEIN, S. AVTA: A device forautomatic transaction analysis. Journal of the ExperimentalAnalysis ofBehavior, 1964,7,99-104.CHAPPLE, E. The interaction chronograph: Its evolution andpresent application. Personnel, 1949,25,295-307.DARWIN, J. H. Note on the comparison of several realizations ofa Markov chain. Biometrika, 1959,46,412-419.FELDSTEIN, S., & WELKOWITZ, J. A chronography of conversa-tion: In defense of an objective approach. In A. W. Siegman& S. Feldstein (Eds.), Nonverbal behavior and communication.Hillsdale, N.J: Erlbaum, 1978.FRENCH, R. L. Verbal output and leadership status in initiallyleaderless group discussions. American Psychologist, 1950, 5,310-311.GOLDMAN-EISLER, F. Speech-analysis and mental process.Language and Speech, 1958, 1,59-75.HAYES, D. P., & MELTZER, L. Interpersonal judgments based ontalkativeness: 1. Fact or artifact? Sociometry, 1972,35,538-561.HEWES, D. Finite stochastic modeling of communication process-es. Human Communication Research, 1975, 1,271-283.HEWES, D. Stochastic models of communication processes. InP. R. Monge & J. N. Cappella (Eds.), Multivariate techniquesin communication research. New York: Academic Press, inpress.-400SAMPLING TIME1 b. 1 I •-150 ·200/\ ./. /•b-1003.'3.12.7CHI 2 2.31.91.'1.1cautioned concerning the data of Figure 5. In a truesampling unit study, the data in each time unit areidentical and the sampling pulse randomly samples thesame signal in increasingly larger sampling domains(50 msec, 100 msec, etc.). In such a case, the smallestsampling unit would contain all of the informationavailable at that sampling duration, and larger unitswould possibly lose certain information. We chose tostudy our own averaging procedure and, consequently,the signal sampled is changing somewhat (averaging 1,averaging 2, ... , averaging 10 values) as the samplingunits (i.e., number of points averaged) change. Conse-quently, Figure 5 shows that at about 300 msec (six50-msec samples averaged) the stability of results desiredbegins to be realized.The FIASSCO system is a usable hardware andsoftware system for the analysis of talk and silence datain two-person conversations. It makes possible thecoding and summarization of categorical and continuoustalk-silence indices directly from audiotape. As a conse-quence, the labor-intensive and costly collection ofthese data is substantially reduced, and the way isopened for extensive research into talk and silencecorrelates and predictors, as well as research intosequential models of these basic templates upon whichconversations are written.TALK-SILENCE SEQUENCES 391Appendix AADCON.BA OutputJAFFE, J. Linked probabilistic finite automata: A model for thetemporal interaction of speakers. Mathematical Biosciences,1970,7,191-204.JAFFE, J., & FELDSTEIN, S. Rhythms of dialogue. New York:Academic Press, 1970.JAFFEE, L. C., & LUCAS, R. L. Effects of rates of talking andcorrectness of decisions on leader choice in small groups. Jour-nal ofSocial Psychology, 1969,79, 247-254.KEMENY, J. C., & SNELL, J. L. Finite Markov chains. New York:Van Nostrand, 1960.KNUTSON, A. L. Quiet and vocal groups. Sociometry, 1960, 23,36-49.MATARAZZO, J. D., SASLOW, G., & MATARAZZO, R. G. The inter-action chronograph as an instrument for objective measurementof interaction patterns in interviews. Journal of Psychology,1956,41,347-367.MELTZER, L., MORRIS, W., & HAYES, D. Interruption outcomesand vocal amplitude: Explorations in social psychophysics.Journal of Personality and Social Psychology, 1971, 18,392-402.MUIR, F. L. Case studies of selected examples of reticence andfluency. Unpublished master's thesis, Washington State Univer-sity, 1964.NATALE, M. Convergence of mean vocal intensity in dyadic com-munication as a function of social desirability. Journal of Per-sonality and Social Psychology, 1975,32,790-804. (a)NATALE, M. Social desirability as related to convergence of tem-poral speech patterns. Perceptual and Motor Skills, 1975, 40,827-830. (b)NORFLEET, B. Interpersonal relations and group productivity.Journal ofSocial Issues, 1948,2,66-69.PHILLIPS, G. M. The problem of reticence. Pennsylvania SpeechAnnual, 1965,22,22-38.PHILLIPS,' G. M. Reticence: Pathology of the normal speaker.Speech Monographs, 1968,35,39-49.RIECHEN, H. W. The effects of talkativeness on ability to influ-ence group solutions to problems. Sociometry, 1958, 21,309-321.SoSKIN, W. F., & KAUFFMAN, P. E. Judgment of emotion inword-free voice samples. Journal of Communication, 1961,11,73-80.STARKWEATHER, J. A. The communication-value of content freespeech. American Journal ofPsychology, 1956,68,121-123.STARKWEATHER, J. A. Vocal communication of personality andhuman feelings. Journal ofCommunication, 1961, 11, 63-72.STEWARD, L. A. Attitudes toward communication: The contentanalysis of interviews with eight reticent and eight nonreticentcollege students. Unpublished PhD dissertation, PennsylvaniaState University, 1968.STRODTBECK, F. L. Husband-wife interaction over revealed dif-ferences. American Sociological Review, 1951, 16, 468-473.STRODTBECK, F. L., & HOOK, H. The social dimensions of atwelve-man jury table. Sociometry, 1961, 24, 397-415.STRODTBECK, F. L., & MANN, R. D. Sex role differentiation injury deliberation. Sociometry, 1956, 19,3-11.WEBB, J. T. Interview synchrony: An investigation of two speechrate measures. In A. W. Siegman & B. Pope (Eds.), Studiesin dyadic communication. New York: Pergamon Press, 1972.Appendix BAVSTAT.BA Output: Six-State AnalysisDATE: JULY 16, 1975TAPE POSITION: 275-571SEX: MALESEX: MALETOTAL TIME: 20.00MINUTESQUESTION SET 1SEX: MALESEX: MALETOTAL TIME: 20.00MINUTESQUESTION SET 1.R PIP*TIY:<ADC6.02/EXPERIMENT NUMBER: 2TAPE NUMBER: 1PERSON A: 4PERSONB: 3SEQUENCE: 1TOPIC OF DISCUSSION:STARTCH: 10#OFCH'S: 2SAMPLING RATE: 50 MSEC#OFOBS: 240006-STATE ANALYSIS# PTS PER PERS AVGD: 6CUTOFF LEVEL: 40/2222221222222222233356221122222222222221112222222222222222222122222222212222222221222222222222222221222111122221112222222222212222222222222122222222222211154444442233355455555455555455554555444555545555554445522211566555554423154454444545555554444554444455425555444444444421221111PERSON A: 4PERSONB: 3SEQUENCE: 1TOPIC OF DISCUSSION:STRTCH: 10#OFCH'S: 2SAMPLING RATE: 50 MSEC# OF OBS: 24000/15881617163717682079187715471186DATE: JULY 16, 1975TAPE POSITION: 275-571.R PIP*TIY:<LTAl:ADC.02/EXPERIMENT NUMBER: 2TAPE NUMBER: 1392 CAPPELLA AND STREIBELAppendix CFLRTIM.BA Output: Six-State DataPROGRAM: FLRTIM.BAINPUT ON(DEV:NAME.EX)?AOC6.02OUTPUT TYPE (FULL/PART)?FULLOUTPUT ON(TTY/DEV:NAME.EX)?TTYNOTE: I TIME UNIT = 300 MSEC# PRS FLOOR TIME VOCAL DUR W!I PAUSES SWT PAUSES SIMUL SPCHSTART LEN STRT LEN STRT LEN STRT LEN STRT LENA 1 20 1 6 7 1 18 38 132 B 21 2 21 2 223 A 23 133 23 2 25 2 153 327 13 40 343 19 62 163 9 72 173 9 82 183 17 100 1101 3 104 4108 3 112 3US 11 126 1127 13 140 1141 124 B 156 7 156 1 157 65 A 163 5 163 5 165 3AppendixDMATDIS.BA Output,Six-State Transition Frequencies and Probabilities Six-State Contingent Probabilities***FREQ MATX*** TIME UNIT: 1TRANSITIONS: ROWS(FROM) - COLS(TO) PROB(A) PROB(B) I-PROB(A) 1-PROB(B)TIME UNIT: 1 0.352 0.176 0.647 0.82316 12 0 0 6 0 34 0.886 0.037 0.113 0.96216 137 4 0 2 0 159 0.636 0.818 0.363 0.1812 0 7 0 2 0 11 0.098 0.271 0.901 0.7280 6 0 S3 20 2 81 0.046 0.728 0.953 0.2710 1 0 28 74 4 107 0.5 0.625 0.5 0.3750 2 0 1 3 2 8 TIME UNIT: 2TIME UNIT: 2 PROB(A) PROB(B) I-PROB(A) 1-PROB(B)19 7 1 0 8 0 35 0.228 0.257 0.771 0.74216 108 8 0 4 0 136 0.852 0.088 0.147 0.9110 6 11 0 3 0 20 0.850 0.700 0.15 0.30 6 0 60 21 4 91 0.109 0.274 0.890 0.7250 3 0 30 55 6 94 0.095 0.648 0.904 0.3510 6 0 1 3 14 24 0.833 0.708 0.166 0.291TOTAL TIME:0.626 0.2850.122 0.8210.058 0.201o 0.045o 0.011o 0.234*0.0090.0410.529oooooo0.7040.3060.0930.0780.0140.2100.2340.6630.218ooo0.0140.0180.453TOTAL PROB MATX0.626 0.2850.122 0.8210.058 0.201o 0.045o 0.011o 0.234*0.0090.0410.529oooooo0.7040.3060.0930.0780.0140.2100.2340.6630.218ooo. 0.0140.0180.453(Received for publication December 14,1978;-revision accepted January 15, 1979.)
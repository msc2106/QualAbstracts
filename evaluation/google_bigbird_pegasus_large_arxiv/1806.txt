ABSTRACT: 
This article describes how the Hartford Foundation for Public Giving, with a subset of its grantees and their program recipients, teamed with the UCLA Center for Healthier Children, Families & Communities to redesign its evaluation process. The foundation’s shift from traditional program evaluation to a more participatory, learning-focused approach resulted in new tools to assess variables that had been previously unexamined but were critical to program success. This article examines the redesign process and those new tools – the data from which are being used to improve employee engagement and front-line practice as part of a cross-agency learning network – and concludes with a discussion of reflective practice and actions taken and with a summary of lessons learned. 
 
PREDICTION: 
the impact assessment of early learning centers is a long - standing problem in education , the social sciences , and the federal government .<n> the main obstacle is the lack of data , which makes interpretation and interpretational difficult .<n> the problem is compounded by the fact that early learning centers operate in a harsh environment , and may not have direct access to the parent s income or other personal financial information .<n> we describe a framework for early learning center impact assessment , in which a team of experts assesses the impact of early learning centers on the learning outcomes of the child , the parent , and the community in which the child resides .<n> the assessment is performed in two steps : a team of experts assesses the impact of early learning centers on the learner , the parent , and the community ; and a team of experts assesses the impact of early learning centers on the learner , the parent , and the community .<n> we describe the framework by which impact assessment can be implemented in a systematic way , and how to interpret the results .<n> we illustrate the approach with a case study in which impact assessment is applied to early learning centers . <n> early learning centers have played an important role in shaping 
 
FULL TEXT: 
 Healthier Children, Families & Communities. Part of UCLA’s appeal for the foundation was its involvement in testing and prototyping sys-tems approaches to improving outcomes for young children and their families. Two of those efforts — the Hope Street Family Center and the Magnolia Place Community Initiative, both in Los Angeles — provided working examples of applying a systems approach to the develop-ment and work of neighborhood-based family centers. Both pay specific attention to aligning a cross-sector network of agencies to provide an integrated set of services and supports. doi: 10.9707/1944-5660.136554 The Foundation Review // thefoundationreview.orgBowie and SussmanToolsSince the inception of its Brighter Futures ini-tiative, the foundation had been investing in neighborhood-based family centers. There are currently six centers, which are overseen by three community-based organizations (CBOs) and continue to receive some operating and pro-gram support from the foundation. The Early Childhood Investment Team introduced UCLA to a group of center staff and CBO leaders during a foundation-sponsored visit to Los Angeles; this group also met with staff from the Magnolia Place Community Initiative and the Hope Street Family Center. After receiving good feedback from the visit, the foundation contracted with UCLA to conduct an assessment of the Hartford-area centers and gauge the potential for and overall interest in a redesign of the centers. The assessment drew a highly positive response from the centers’ staff, involved parents, and the local CBO leadership, and the foundation engaged UCLA to implement the redesign.The redesign process adapted some of the seminal thinking on user-centered design (Brown, 2009), reflective practice in organiza-tional-change management (Senge, Scharmer, Jaworski, & Flowers, 2004), and improvement methods (Langley et al., 2009; Deming, 1986). The work included the introduction of new tools and processes to examine professional practice as well as an assessment of families’ accounts of their experience of care. The new data were to be used for both individual and collective reflec-tive processes that enabled staff and parent lead-ers of the six centers and CBO leaders to adapt their practices in a timely and responsive way, look at patterns across settings, and pilot new approaches that may have applicability to other agency programs and activities. The Redesign of the Family CentersSince their inception, the Family Centers have spent considerable time defining the uniqueness of their role, purpose, and impact. For their first 15 years, an external evaluator assessed the cen-ters’ impact on enrolled children and families. The role of staff in these assessments largely involved submitting data about families partic-ipating in center programs, and the evaluator shared findings with staff on a semi-annual basis. The foundation coordinated annual discussions of the results. Among the important findings uncovered in this process was that center pro-grams had a more significant positive impact on child outcomes than did the same programs offered elsewhere. As awareness of the centers and their impact grew, other funders proposed and supported new programs; the CBO leaders also supported the addition of programs. But each of these new programs, often funded by other sources, came with their own accountability measures — and the centers were soon respond-ing to a dizzying array of evaluation interests and monitoring requirements. In addition, the CBOs often added questions related to their own areas of interest to the center evaluations. While they recognized the value of such assess-ments, center staff often reported that they felt overburdened by demands for data that were often duplicative and that did not yield meaning-ful information about their work with families. Moreover, they strongly asserted that the roots of their programmatic success with children and families were not in what they had to offer — but in how they offered it. Thus, the challenge con-fronting UCLA was to introduce data and mea-surement that would demonstrate how the work of improving outcomes for young children was accomplished. It would require a major shift in perspective from all involved. The original approach of the evaluation was to identify and implement the “right” pro-gram model or intervention. Fidelity to an evi-dence-based program or intervention was key, The work included the introduction of new tools and processes to examine professional practice as well as an assessment of families’ accounts of their experience of care.The Foundation Review // 2017 Vol 9:2 55A Redesign Process: Taking a Systems PerspectiveToolsand a traditional, summative program evaluation was therefore considered sufficient. Center staff, however, knew that they were creating solutions that were highly context specific and that there was no one “right” way for every family. But staff also believed the keys to success were to respond to local conditions, be willing to exper-iment with new ideas, and adopt new roles and structures when necessary. The centers’ staff and leaders, therefore, would have to be relentlessly reflective as they attempted to capture progress and results.Gathering data on multiple levels across a system is critical to generating a complete picture of how a system is performing. In this case, the “system” comprised neighborhood families, the centers, and the CBOs and other organizational partners as well as the foundation. All those actors would now need to produce and share information on the process and actions, as well as the results, to produce a meaningful evaluation and a success-ful redesign. A Systems Perspective Launched in 2015, the Family Center redesign process applied thinking on user-centered design, reflective practice, team decision-making, and improvement methods that focused on enhanc-ing the centers’ neighborhood-based approach to produce positive outcomes for children and fam-ilies. This process would also enable the founda-tion, CBO leadership, and center teams to more clearly understand and articulate that the centers were not merely a point of service, but had, in fact, become: • the primary “go to” support and resource of neighborhood families; • innovation hubs — places where ideas can be tested, piloted, and scaled up if successful; • places where larger CBOs seek and receive the most authentic, consistent consumer feedback; • safe places for residents to try new ways to improve themselves, their families, and their neighborhoods without fear of losing services; and• rooted in the community, not in its institutions. The process led its participants to realize that one goal of the redesign should be to introduce three levers of systems change: 1. a vibrant, neighborhood-based, cross-agency network of centers; 2. committed foundation-staff support for CBO leadership and center teams, creating a network learning community; and 3. a shift from a program-based measurement to measuring systems change within the newly established network. Establishing a Family Center Network While the centers worked from similar principles and offered the same core program components, they functioned independently and developed local expertise based on neighborhood and fam-ily conditions as well as specialized staff and CBO capacity. The leadership of the three CBOs saw that by working a system — being more intentional about sharing knowledge and exper-tise — each center could build off the others’ strengths, better aligning their programs and services for families. As Hartford is a relatively small city, the lead-ers of its community-based organizations are known to one another and have collaborated and In this case, the “system” comprised neighborhood families, the centers, and the CBOs and other organizational partners as well as the foundation. 56 The Foundation Review // thefoundationreview.orgBowie and SussmanTools competed on various programs and initiatives. Yet, outside of those specific initiatives, they had never made the choice to work collectively. The foundation was clearly the impetus for the three CBOs to work more collaboratively on common goals and measurements. Significantly, their agreement to participate and their willingness to set the parameters and boundaries for the collec-tive work was voluntary — and not predicated on financial support from the foundation. In creating the network, the centers commit-ted to bring more intentionality to their role as a bridge between families, community mem-bers, and an array of agency-supported services. As the centers began thinking about the need for changes in practice, an idea emerged for a more formal process for learning that involved the foundation itself — not just its grantees and the families being served — as a partner in that learning. Giving staff and parents the oppor-tunity to ask their own questions dramatically changed the dynamics of the evaluation process and raised expectations for its success. Building a Cross-Agency Learning System As one funder among many supporting the cen-ters, the foundation had to agree to a different set of evaluation questions that would shift its staff, CBO leadership, and center teams from a posture of accountability to one of collective action and learning. While the need for this change was acknowledged from the beginning of the process, the shift took a while and was, to say the least, a constant challenge — agencies worried, for example, about losing funding if they were unable to supply more traditional data. It required changes in deeply held habits and in a culture that offered greater incentives for accountability than for learning. For the foundation, it meant acknowledging there was sufficient data from prior years that demonstrated program impact and that it would be permissible, therefore, to begin gathering data that would more effectively document systems change. It also meant that the foundation had to be responsive to the capacity needs of the CBOs and centers as they made this shift. Again, this was not easy: the foundation had to extend to them the same confidence in their accountability processes that they had in those of their grantees. Human-Centered DesignThe work with UCLA began with a process of discovery using a modified approach to human-centered design (Brown, 2009). This process provided the opportunity for all parties to share their perspectives on the actions of and information generated by others. For exam-ple, parents from one center’s team would visit another center posing as new residents interested in participating in that center’s programs. In the spirit of learning and improvement, they would then recount their experience to the group. Complementing that approach, front-line staff and CBO leaders were asked to map out their understanding of the processes used to engage families and connect them to services and sup-ports. More often than not these process maps were not consistent across center staff or CBO leaders — and were inconsistent with the par-ents’ experience. Broadening awareness in this way highlighted the importance of user partici-pation and led to a fuller recognition that many solutions required an understanding of the lived experience as well as professional expertise. The perspectives of both the staff and the families were key to the success of this work. Support for this multiparty engagement goes beyond a needs survey or focus group; it requires helping people realize that they not only can make important contributions, but that they are integral to the change process. Giving staff and parents the opportunity to ask their own questions dramatically changed the dynamics of the evaluation process and raised expectations for its success.The Foundation Review // 2017 Vol 9:2 57A Redesign Process: Taking a Systems PerspectiveToolsThe collaborative group then established a shared theory of change, which holds that posi-tive outcomes for children and families depend on the day-to-day actions of individuals and organizations supporting families and other neighborhood residents. Progressive changes in these actions contribute to shifts in family and neighborhood conditions and in the health and parenting behaviors of individuals. Taken together, these small shifts build toward lon-ger-term improved outcomes for children. Participants from the various centers, including parents but primarily staff, went a step further, developing and adopting key drivers to arrive at a set of common actions — an approach that helped them begin to test the theory of change. These drivers led the group to coalesce around a shared purpose, principles, and values and to continue progress toward a set of measur-able goals to be shared among the stakeholders (Bryk, Gomez, & Grunow, 2011). With guidance from UCLA, center teams established a common language that enabled the group to build con-sensus, prioritize high-leverage ideas, and focus improvement efforts. The drivers developed by the center teams were adopted institutionally by the CBOs and outline the specific organizational practices the centers must observe in order to create the intended experience for families: activate and build skills of parents to take actions that support their child’s health and development, increase access to resources and support, and support parent-to-par-ent and neighbor-to-neighbor connections. Feedback Loops For the CBOs, center staff, and families, it was not sufficient to simply know that high-quality programs achieved programmatic outcomes; they also needed to know how those outcomes were achieved. Services are experiences, and the only quality measure that matters is subjective: how those receiving the service perceive the experience (Gray, 2012). Therefore, creating and maintaining a feedback loop on the service expe-rience fosters more timely changes and is key to meaningful systems improvement (Meadows & Wright, 2009). There was agreement that new strategies were needed to track and therefore improve front-line practice. Research tells us where uncertainty in the result is high, there is no such thing as a perfect plan — and, in fact, the further out you plan without testing your assumptions, the likelier you are to be wrong (Mitchell, 2009). To be successful, any approach has to involve taking action, reflecting on results, and learning the way forward (Bowie, 2011). By prioritizing a set of actions or leverage points within a system, an actor can test, revise, and ultimately share how a particular result was achieved (Langley et al., 2009). It also helps to keep in mind that a theory of change is just that — a theory. What is required, therefore, are a mechanism and tools to provide feedback and support learning among the players within and across systems. The key to the redesign work, then, was to build a scalable and sustainable data system that would allow all network partners to actually adopt measurement as part of their routine practice (Bowie & Inkelas, 2014). The approach taken by UCLA was to help the CBOs, center staff, and parents build their data capacity and data literacy by moving from data as simply an accountability and reporting function to data as the cornerstone of their learning and system-improvement pro-cess. To that end, decisions on the actual data or about measures, collection tools, analysis, and display, were based on this set of criteria: • Data are to be informed by research. • Long-term outcomes are linked to larger system and foundation goals. With guidance from UCLA, center teams established a common language that enabled the group to build consensus, prioritize high-leverage ideas, and focus improvement efforts. 58 The Foundation Review // thefoundationreview.orgBowie and SussmanTools• Whenever possible, data are selected from other validated tools or are collected within existing programs or services. • Data must be relevant to the result the team is seeking to address. • Data-collection tools are to be tested for ease of use and adaptability to staff capacity, work flow, and different settings. • Data collection and analysis will be devel-oped to work across capacity levels at each of the agencies. • Data analysis will be transparent and avail-able to CBOs and center staff for use at indi-vidual sites. • Results will be timely and available to those who provide and collect the data. • Recognizing that individuals have different learning styles, development of data-visual-ization tools will be iterative and part of the system-improvement process. New Family Center Tools In developing feedback loops, the centers chose a set of measures based on their new theory of change. This included establishing these mea-surement domains to benchmark progress on selected long-term outcomes for children:• action by staff and the organizations believed necessary to support positive behavior change for the center staff, includ-ing how reliably individuals or organiza-tions are using empathic care, providing quality services, and linking individuals to needed services and supports; • parenting behaviors that contribute directly to children’s outcomes, such as reading daily with young children, consistent nur-turing and care, and other approaches to healthy parenting; and • family and neighborhood conditions that embody protective factors at the individual and neighborhood level and other factors that impact family stability, including social connections; safe environments; safe and stable housing; jobs and financial stability; and resident involvement and leadership. To measure these domains across the six sites, the centers adapted three new data tools that col-lectively capture information that illustrates for the CBOs and center teams the interrelatedness of a set of layered actions. These actions begin with CBO support for staff, which then leads to staff support for parents and changes in parent behaviors and elicits actions that impact families and neighborhoods. The tools also draw forth the perspectives of staff and the experience of families, ensuring that programs are as respon-sive as possible. All of these ultimately affect children’s outcomes.Tool No. 1: The Practice Change SurveyThis survey, which is administered annually to measure CBO actions and organizational change, is used to assess whether the overall work envi-ronment is conducive to learning, adapting, and improving. This tool provides the opportunity for review if changes within the organizations or the larger system affect the staff’s ability to respond to the changing circumstances of family and neighborhood life. The findings show man-agers how staff is functioning in an ever-chang-ing work environment and how they can be best equipped to work effectively. To measure these domains across the six sites, the centers adapted three new data tools that collectively capture information that illustrates for the CBOs and center teams the interrelatedness of a set of layered actions. The Foundation Review // 2017 Vol 9:2 59A Redesign Process: Taking a Systems PerspectiveToolsThe survey, adapted from a tool developed to evaluate practice change in patient-centered medical homes (Nutting et al., 2010), measures such attributes as:• Sense making. People have the information needed to do their jobs well and, when confronted with a problem, make a serious effort to address it.• Trust. Staff can rely on other people to do their jobs.• Work environment. People have what they need to do their jobs well, get frequent and helpful feedback, have clear expectations and opportunities to grow, and seem to enjoy their work. • Social and task interaction. People get together regularly to talk about their work and personal lives.• Safety. People feel their mistakes have led to positive changes and are not held against them, errors are openly discussed, people aren’t afraid to ask questions, and safety is never sacrificed to get more work done. • Learning culture. The network learns from its mistakes, and mistakes lead to positive changes. This tool provided redesign participants with a better sense of how to use limited resources for professional development, training, and organi-zational capacity-building. Cross-site discussions led to an exchange of practices, opportunities, and ideas for improvement that will be tested and shared as part of center-specific improve-ment plans. The Family Experience of Care Survey This survey, performed monthly to measure staff actions and behavior change, is aimed at ensuring that each family consistently receives a high-quality experience no matter which “door” they enter. (See Figure 1.) The tool measures whether families are being treated in the “Family Center Way,” a term adopted by redesign BFI Family Center Experiences of Care Survey ResultsOctober 2015 – February 201775%80%85%90%95%100%Oct Dec Jan Feb Mar Apr May June July Aug Sept Oct Nov Dec Jan FebDuring today's visit, did the people you spoke with:provide you with the information or help that you needed or connected you with someone who could help you?ask if you have concerns about your child's learning, development, or behavior?tell you how the Family Center could help you in addition to what you came for?suggest other programs in the community that can help you?tell you to let us know if you could not get help from these other community program(s)?FIGURE 1 Family Experience of Care Survey – Results 60 The Foundation Review // thefoundationreview.orgBowie and SussmanToolsparticipants to describe the “how” of achieving positive outcomes. The survey asks if parents feel welcomed and listened to and determines whether staff ask key questions designed to con-nect each family to the services and supports that best address its needs. This information is used to set specific improve-ment goals. Gathering the same data consistently across the sites has allowed the centers to test various approaches using Plan Do Study Act Cycles (PDSAs), a structured, iterative learning process (Langley et al., 2009) to innovate, learn, and share what works more quickly than trying to tackle this entrenched problem individually. The Family Wellness Survey This survey, administered every six months, provides an overall picture of family and neigh-borhood conditions of those residents seeking assistance at the center. It measures parents’ perceptions of their overall well-being as well as their awareness of available social supports and services, access to needed resources, neigh-borhood conditions, and other factors that affect optimal family functioning and child development. This information provides the centers with data necessary to evaluate the strengths and weaknesses of their efforts, helps them locate emerging trends and other shifts at the neighborhood level, and identifies possi-ble partnerships and professional development opportunities to help staff to respond more effec-tively to changing needs. Adopting a Learning ProcessMoving from building a system for consistent data collection and review to a structured pro-cess for testing and improvement offered the centers the opportunity to implement practice changes and innovation. Currently, centers generate monthly experiences-of-care data and the teams from the six centers meet monthly to implement improvements and share learning, which facilitates the spread of successful prac-tices and innovation across all of the centers. Making data available to staff and parents in a consistent and timely way produces rapid feed-back on how these change ideas are impacting family experiences and conditions. For example, the one question least consistently asked of parents at the centers is whether they have concerns about their child’s learning, development, or behavior. (See Figure 1.) This question is critical to encouraging families to talk freely about their concerns, and serves as an access point for center staff if future concerns arise. Given that the Family Wellness Survey found that 30 percent of parents did not have someone to turn to for day-to-day emotional help with parenthood and 28 percent did not have someone with whom they felt comfortable discussing personal problems, center teams, which include parents, looked into why some staff might be uncomfortable asking such an essential question. Research on practitioners introducing a screen-ing tool on child development indicates that the one of the major reasons why practitioners do not ask parents about their concerns is because they do not have a process or resources with which to respond (Bowie & Inkelas, 2014). It was not that the practitioners didn’t know such questions were important or how to ask them; they simply did not want to surface problems that they had no mechanism to address. This finding resonated with the center teams and echoed some staff comments, and a pair of centers responded with two approaches to improve linkage and response times for families needing assistance. Those Research on practitioners introducing a screening tool on child development indicates that the one of the major reasons why practitioners do not ask parents about their concerns is because they do not have a process or resources with which to respond.The Foundation Review // 2017 Vol 9:2 61A Redesign Process: Taking a Systems PerspectiveToolscenters agreed to test each approach through a PDSA process and share their continued learning until they saw improvements. Another example involves recognizing that pos-itive changes in family and neighborhood con-ditions are key levers in improving the healthy growth and development of young children (Hertzman & Power, 2003). Centers are explor-ing the potential connection between percep-tions of neighborhood safety and the sense of connection necessary to feel able to rely upon neighbors for help. Strategies to enhance social connectedness, both at the center and among those living on the same block, can have a direct health benefit for those who may lack access to a reliable support system and can improve percep-tions of neighborhood cohesion and safety. Finally, center teams have also shared this new data process and results with their Center Parent Leadership Councils. Through this engagement, parent leaders participate in developing improve-ment goals and contribute their own ideas for change and innovation, and the approach con-tinues the process of strengthening the skills and capacities of the parents, staff, and organizations to innovate, learn, and adapt. The Organization’s LearningComing together regularly to plan, implement, and review have helped the centers define their core functions and given them a better under-standing of the work they do, the challenges they face, and the need for collaborative efforts. Both CBOs and center staff indicated that the data have helped them reflect on how to be more effective as an organization and as a system and, more specifically, helped the center teams to identify areas of programming that work well and those that need restructuring. This has enabled them to be more focused, intentional, and timely in responding to breakdowns in ser-vice delivery or problematic staff behaviors. An added benefit — and one that center staff hadn’t expected — is how the process helped them strengthen community partnerships and create new ones. Centers have found it much easier to communicate the “Family Center Way” and community partners have a clearer under-standing of how the centers operate, which has resulted in greater alignment and coordination of efforts to meet the needs of children and families. As one center staff member commented, “It has helped me to understand how relationships influ-ence the effectiveness of the work we do with families, parents, and our community partners.” The Foundation’s Learning From the foundation’s perspective, the biggest takeaway is that when individuals are allowed to ask questions about how best to do their work, their practice changes, their clients enjoy better experiences, and the impact of the support those clients receive is strengthened. By building indi-vidual and organizational capacities to use such processes as human-centered design and itera-tive learning cycles for testing and prototyping, by establishing more timely feedback loops, and by increasing employee engagement, ser-vices and service delivery can be continuously improved and more effectively adapted to ever changing conditions. The foundation’s attention to its own need to learn with its grantees has not only allowed it to continue to study its impact and evaluate its practice, but has also enabled the foundation to more effectively adapt its grantmaking to make the most appropriate and timely investments, From the foundation’s perspective, the biggest takeaway is that when individuals are allowed to ask questions about how best to do their work, their practice changes, their clients enjoy better experiences, and the impact of the support those clients receive is strengthened. 62 The Foundation Review // thefoundationreview.orgBowie and SussmanTools and ones that are more aligned with the learn-ing generated by their grantees and the families themselves. Larger Lessons• Build a common learning agenda. While it is important to have a shared goal, it is just as critical to adopt a learning agenda, which allows for a diversity of ideas and innova-tion toward achieving that common goal. A theory of change can provide this as long as it captures the system design and how each actor will experience and benefit from it. • Select a small set of measures that include common outputs and outcome indicators that are relevant to everyone involved. These are the most meaningful and motiva-tional for collective action and learning. • Determine key drivers and system leverage points. This helps to reach beyond individ-ual program goals to underlying practices that support change in relationships and connections, culture, norms, and processes — which then leads to change in the larger system. • Design more immediate feedback loops with participation from all those who sup-port and are affected by the outcomes of the effort. Collecting and providing data at all levels allows everyone to find the informa-tion that motivates them to make a change. • Introduce structures and processes, such as PDSA Cycles, for collective learning and that enable all to respond at their level of influence. Other projects and initiatives have been invited to participate in the redesign process to observe the progress, provide feedback, and share how this has influenced their own work. As one observer said, Where the tools and discussion from the meeting add to my thinking is around how we can do better to collect data about needs and more fully involve families in informing what we offer and how it is delivered. We ask about satisfaction and what fam-ilies take away, but don’t do enough to systemati-cally mine their experience, interests, and needs.It is the foundation’s hope that what we have demonstrated on the local level will be observed by others and affect a larger change — even if change comes a bit at a time, perhaps first in other areas of the foundation’s own work and, later, by other funders. Conclusion As a foundation officer and as an academic con-sultant, we both take pride in asking how to improve practice — to continuously learn, grow, do things better, and help people realize their goals. Through the connections and trusted relationships built over the course of this work, we have learned that this was the same question that CBO leaders, staff, and parents were asking themselves. Yet it was the degree to which they could give up control and actually ask this ques-tion of one another, and share the responsibility for making the decision to enter into joint learn-ing, that has had such a profound impact on the work. Building this capacity for collective learn-ing holds the most promise for getting to the ever-elusive results we seek. While believing that we have demonstrated the potential of this work, it was undertaken within a specific context. The work ahead for both the foundation and UCLA is to assess how this approach and the resulting actions can become practice across multiple projects, engage new target populations, and scale enough to create a larger system supportive of continuous inquiry, Other projects and initiatives have been invited to participate in the redesign process to observe the progress, provide feedback, and share how this has influenced their own work.The Foundation Review // 2017 Vol 9:2 63A Redesign Process: Taking a Systems PerspectiveToolslearning, and improvement. And, over time, we will have to see if it is possible to truly flip current evaluation practice and start with this approach to learning and evaluation, rather than have it follow as a redesign after a more tradi-tional evaluation approach.ReferencesBowie, P. (2011). Getting to scale: The elusive goal – Mag-nolia Place Community Initiative. Seattle, WA: Casey Family Programs. Bowie, P., & Inkelas, M. (2014). Using data to drive change in complex community systems. In N. Cytron, K. L. S. Pettit, & G. T. Kingsley (Eds.), What counts: Harnessing data for America’s communities (pp. 378–395). San Francisco: Federal Reserve Bank; Washington, Urban Institute. Brown, T. (2009). Change by design: How design thinking transforms organizations and inspires innovation. New York: Harper Collins. Bryk, A. S., Gomez, L. M., & Grunow, A. (2011). Getting ideas into action: Building networked improvement communities in education. In M. Hallinan (Ed.), Fron-tiers in sociology of education, (pp. 127–162). New York: Springer. Deming, W. E. (1986). Out of the crisis. Boston: MIT Press. Gray, D. (with Vander Wal, T.). (2012). The connected company. Cambridge, UK: O’Reilly Media. Hertzman, C., & Power, C. (2003). Health and human development: Understandings from life-course research. Developmental Neuropsychology, 24(2–3), 719–744. Langley, G., Moen, R., Nolan, K., Nolan, T., Norman, C., & Provost, L. (2009). The improvement guide: A practical approach to enhancing organizational perfor-mance. San Francisco: Jossey-Bass. Meadows, D., & Wright, D. (2009). Thinking in systems: A primer. New York: Earthscan. Mitchell, M. (2009). Complexity: A guided tour. New York: Oxford University Press. Nutting, P. A., Crabtree, B. F., Miller, W. L., Stew-art, E. E., Stange, K. C., & Jaén, C. R. (2010). Journey to the patient-centered medical home: A qualitative analysis of the experiences of practices in the National Demonstration Project. Annals of Family Medicine, 8 (Suppl. 1), s45–s56. Senge, P., Scharmer, C. O., Jaworski, J., & Flowers, B., (2004). Presence: An exploration of profound change in peo-ple, organizations, and society. New York: Doubleday. Richard A. Sussman, Ph.D., is director of early child-hood investments at the Hartford Foundation for Public Giving. Correspondence concerning this article should be addressed to Richard A. Sussman, Hartford Foundation for Public Giving, 10 Columbus Boulevard, Hartford, CT 06106 (email: rsussman@hfpg.org).Patricia Bowie, M.P.H., is an independent consultant and works with UCLA’s Center for Healthier Children, Families & Communities.
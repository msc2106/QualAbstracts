ABSTRACT: 
The paper shows how ideas that explain the sense of an expression as a method or algorithm for finding its reference, preshadowed in Frege's dictum that sense is the way in which a referent is given, can be formalized on the basis of the ideas in Thomason (1980). To this end, the function that sends propositions to truth values or sets of possible worlds in Thomason (1980) must be replaced by a relation and the meaning postulates governing the behaviour of this relation must be given in the form of a *logic program*. The resulting system does not only throw light on the properties of sense and their relation to computation, but also shows circular behaviour if some ingredients of the Liar Paradox are added. The connection is natural, as algorithms can be inherently circular and the Liar is explained as expressing one of those. Many ideas in the present paper are closely related to those in Moschovakis (1994), but receive a considerably lighter formalization. 
 
PREDICTION: 
this paper proposes a higher - order theory of logic programming where the usual logic is replaced by a higher - order theory of reasoning .<n> the idea is that the usual logic can be represented by a higher - order theory of reasoning where the usual logic can be represented by a higher - order theory of reasoning . <n> the idea is that the usual logic can be represented by a higher - order theory of reasoning where the usual logic can be represented by a higher - order theory of reasoning . <n> the idea is that the usual logic can be represented by a higher - order theory of reasoning where the usual logic can be represented by a higher - order theory of reasoning . <n> the idea is that the usual logic can be represented by a higher - order theory of reasoning where the usual logic can be represented by a higher - order theory of reasoning . <n> the idea is that the usual logic can be represented by a higher - order theory of reasoning where the usual logic can be represented by a higher - order theory of reasoning . <n> the idea is that the usual logic can be represented by a higher - order theory of reasoning where the usual logic can be represented by a higher - order theory of reasoning . <n> the idea is that the 
 
FULL TEXT: 
  1 Introduction In this paper I will pursue the Fregean idea that the sense of an expression essentially is a method or algorithm to get at its reference. I will argue that this idea can be formalized in a simple way and that an existing account of linguistic semantics (the one in Thomason 1980) in fact already goes halfway in capturing it, although it presumably was never intended to do so. The view has repercussions in at least two areas of foundational difficulty, as it sheds light on problems of intensionality, but also on the question of circular propositions such as the famous Liar Paradox. That algorithms can be inherently circular and their execution diverging explains why the Liar arises (Moschovakis 1994) and the reason that the move also illuminates problems of intensionality is that once we assume that senses are recipes for finding referents it is not only easy to see how senses that lead to the same ∗To appear in Linguistics and Philosophy. 1 referent can be different, but we also actually get some grip on their identity criteria. If senses are a certain kind of algorithms, then two senses are identical if the corresponding algorithms are. While identity of algorithms itself is a non-trivial problem, this at least gives something to start with. The idea that senses are procedures that can be used to compute ref- erence is an old one, attributed to Frege in Dummett (1978), and Frege’s famous explanation of sense as the Art des Gegebenseins of a referent (the way the referent is given1) certainly can be read as expressing something closely akin to this point of view. The idea was provided with extensive philosophical justification in Tichý (1988),2 where it lies at the heart of a system of intensional logic. It received its most rigorous formalization in Moschovakis (1994), where a system called the Lower Predicate Calculus with Reflection (LPCR) is used to capture it. Conceptually, LPCR is based on Kripke’s formalism to tackle the Liar (Kripke 1975) and the system is obtained by adding a form of recursion to first-order logic.3 The result is rather heavy artillery and van Lambalgen and Hamm (2003) propose to study the idea of senses-as-algorithms in an alternative context that likewise combines the declarativity of semantics with a form of procedurality: the paradigm of logic programming. In logic programming classical logic gets a procedural interpretation and from the point of view of linguistic theory Van Lambalgen and Hamm’s move has the great advantage that procedural aspects of semantics can be studied without the need of additional logical overhead. I will follow this move of taking a logic programming perspective on natural language semantics, but while Van Lambalgen and Hamm apply their insights to the area of lexical semantics, in particular the semantics of temporal operators, I will put them to use in the compositional semantics of phrases, with intensionality and Liar-like phenomena remaining the main focus of interest. The starting point of this paper will be the Intentional Logic of Thoma- son (1980), which is essentially a Montague-like system with an extra type p for propositions, which are thus treated as objects in their own right, not constructed from other objects such as possible worlds. Natural language expressions in this system are rendered as terms of type p or terms of types derived from p and there is a function (denoted with ∪) sending proposi- 1Sometimes translated as ‘mode of presentation’, but the present more pedestrian translation seems closer. 2I take it that Tichý’s notion of senses as constructions esentially captures the same idea. 3Moschovakis (2003) gives a highly interesting higher-order Montague-like system, which unlike LPCR cannot capture Liar-like phenomena however. 2 tions to their extensions. The behaviour of this function is constrained by meaning postulates and this is where the connection with logic programming will be made. I will argue that, after some slight alterations of Thomason’s system, these meaning postulates can not only be cast rather naturally in the form of a logic program, but also that, if this is done, they provide an axiomatization that allows interpreting the elements of the type p domain as consisting of certain algorithms. In particular, type p objects definable in the system can naturally be associated with certain queries. The set-up of the remainder of the paper is as follows. In the next sec- tion we briefly review Thomason’s Intentional Logic; we will get rid of some minor redundancies in section 3 and give a streamlined version that also contains possible worlds in section 4. After a short comparison of the the- ory with other approaches to hyperintensionality (section 5) this version is then altered in section 6 by replacing the function sending propositions to their associated sets of possible worlds (two notions that should be distin- guished on the present account) by a family of relations and by replacing the meaning postulates governing the behaviour of the original function by meaning postulates for these relations. The latter form a logic program and it is shown how finding the set of worlds associated with a given proposition corresponds to the execution of a certain query. In section 7 we consider circular propositions and show how the addition of a rudimentary system of anaphoric reference and a trivial notion of truth leads to divergence (infinite computation) in certain cases, while it works in a perfectly straightforward manner in other, ‘innocent’, ones. A brief conclusion ends the paper. 2 Thomason’s Intentional Logic Thomason (1980) gives a simple and elegant theory of intentionality4 which follows Montague (1973) in translating a fragment of natural language into a version of type logic (Church 1940). Intentionality is obtained by introducing a special basic type p for propositions (which are conceived of as primitive 4From this point on I will follow Thomason in using the word ‘intention’ instead of ‘intension’ in a context where senses can be distinguished with much finer grain as is possible in their usual possible worlds treatment. The notion of intentionality has a long and respectable history, whose modern part is summed up as follows by Tichý (1988): In modern literature the notion first appears in Brentano’s thesis of inten- tional inexistence, and can then be traced through Twardowski’s notion of content and Meinong’s notion of pure object to its clearest manifestation in Frege’s notion of mode of presentation. 3 Variables x, y, z τ i, j P π P Type e st s e(st) p ep Table 1: Typographical convention. Variables of the form indicated will have the associated type. The convention will hold throughout this paper. entities). The usual logical constants ¬, ∧, and → are mirrored by a set of newly introduced ones ∼pp, ∩p(pp), and ⊃p(pp). Thus if Φ and Ψ are propositions, then ∼Φ, ∩ΦΨ, and ⊃ΦΨ are too, the last two typically written as Φ ∩Ψ and Φ ⊃ Ψ. Similarly ∀, ∃ and = are mirrored by logical constants ⋂ (αp)p, ⋃ (αp)p, and ≈α(αp), for each type α. With some notational sugaring this means that we now also have proposition denoting terms of the forms ⋂ XαΦ, ⋃ XΦ, and Aα ≈ Bα, mirroring the usual quantificational and identity statements. In short, the whole usual logical apparatus, which, loosely speaking, essentially operates at the level of truth values (type t), is mirrored at the level of propositions (type p). Having set up these operations on the propositional level, Thomason introduces a function ∪ of type pt and imposes the following homomorphism constraints. (Here π and π′ are variables of type p and x is of type e. See also the convention in Table 1.) (1) a. ∀π[∪∼π = ¬∪π] b. ∀π∀π′[∪ [π ∩ π′] = ∪π ∧ ∪π′] c. ∀π∀π′[∪[π ⊃ π′] = ∪π → ∪π′] d. ∪ ⋂ xΦ = ∀x∪Φ e. ∪ ⋃ xΦ = ∃x∪Φ f. ∪[A ≈ B] = [∪A = ∪B] The idea is that if Φ is a proposition, then ∪Φ is its reference. Note that while these meaning postulates connect the p and t domains, they leave open the possibility that the identity relation on the first of these domains has a much finer grain than the identity relation on the second. For example, we have that ∪∼ ⋂ x∼Φ = ¬∀x¬∪Φ = ∃x∪Φ = ∪ ⋃ xΦ. But there will be many models in which ∼ ⋂ x∼Φ = ⋃ xΦ fails to hold. In general, while ∪ is required to be a homomorphism, it need not be an isomorphism. A natural language such as English can now be provided with a se- mantics by associating each sentence with a proposition. For example, one could associate common nouns and intransitive verbs such as ‘woodchuck’, ‘groundhog’, ‘unicorn’, and ‘walk’ with translations woodchuck, groundhog, 4 unicorn, walk, etc. of type ep5 and determiners such as ‘all’ and ‘a’ with trans- lations all and a of type (ep)((ep)p). Then ‘a woodchuck is walking’ would be associated with the type p term ((a woodchuck)walk) and ‘all woodchucks are groundhogs’ should be translated as ((all woodchuck)groundhog).6 In order for this to work and to connect such translations to their usual truth values, we must impose some requirements, as in (2). (2) a. ∀x[∪(woodchuck x) = woodchucket x], and similar for groundhog, unicorn, walk, . . . b. ∀P ′∀P[allP ′P = ⋂ x[P ′x ⊃ Px]] c. ∀P ′∀P[aP ′P = ⋃ x[P ′x ∩ Px]] The first of these requirements associates the translations that were intro- duced for common nouns and intransitive verbs with their usual extensions in type et.7 The second two connect the translations of ‘all’ and ‘a’ with the newly introduced constants ⋂ and ⋃ . The ∪ function will send these to ∀ and ∃. Again, that what is identified at the level of truth values may be kept distinct at the level of propositions. For example, we may well want to require (3a), which in view of (2a) is equivalent to (3b). But this requirement is fully compatible with (3c). Although all woodchucks are groundhogs and vice versa, the sense of ‘a is a woodchuck’ may be distinct from the sense of ‘a is a groundhog’ for some a. Indeed, it may consistently be assumed that this is the case for all a.8 (3) a. ∀x[∪(woodchuck x) = ∪(groundhog x)] b. ∀x[woodchuck x = groundhog x] c. ¬∀x[woodchuck x = groundhog x] 5I am presenting a streamlined version of Thomason’s theory here and will deviate in non-essential ways from the original. For example, the translation of the intransitive verb ‘walk’ in Thomason (1980) is is a constant walk′ of type ((ep)p)p, which is then systematically related to a constant walk† of type ep by a meaning postulate of the type shifting variety. My walk corresponds to the latter. A similar remark can be made about the translation of ‘believes’ below. 6The result of applying A to B is written as (AB). Parentheses may be omitted on the understanding that association is to the left; e.g. ABC is ((AB)C). 7Note that (2a) can be read as an abbreviatory convention that allows us to write woodchuck for λx.∪(woodchuck x). In other words, (2a) constrains the class of models only in an inessential way. 8Thomason (1980) provides a model in which both (3a) and ∀x¬[woodchuck x = groundhog x] hold. 5 With the meaning postulates in (1) and (2) in place, translations in our mini-fragment of English are connected to their truth conditions via the ∪ function. For example, the following short derivation shows that the propo- sition ((all woodchuck)groundhog) is sent to the usual truth conditions. (4) ∪((all woodchuck)groundhog) = (2b) ∪ ⋂ x[woodchuck x ⊃ groundhog x] = (1d) ∀x∪[woodchuck x ⊃ groundhog x] = (1c) ∀x[∪(woodchuck x)→ ∪(groundhog x)] = (2a) ∀x[woodchuck x→ groundhog x] As long as only extensional constructions are considered, translations will not differ from those in the usual set-up. But as soon as intentional con- structs are taken into account, things begin to change. Consider, for ex- ample, the translation believe of ‘believes’. We may take this translation to be of type p(ep), as it combines with a proposition and a subject to form a proposition. The sentence ‘John believes that a unicorn walks’ could, on the reading where ‘a unicorn’ takes wide scope, be translated as ((a unicorn)λx(believe(walk x)john)). The following computation gives the truth conditions. (5) ∪((a unicorn)λx(believe(walk x)john)) = (2c) ∪ ⋃ x[unicorn x ∩ (believe(walk x)john)] = (1e) ∃x∪[unicorn x ∩ (believe(walk x)john)] = (1b) ∃x[∪(unicorn x) ∧ ∪(believe(walk x)john)] = (2a) ∃x[unicorn x ∧ ∪(believe(walk x)john)] This may be reduced a bit further if the postulate in (6a) is adopted (where believe is a constant of type p(et)). We then arrive at (6b). (6) a. ∀π∀x[∪(believe πx) = believeπx] b. ∃x[unicornx ∧ believe(walk x)john] But here the process stops and, crucially, there is no reduction of the embed- ded proposition walkx to its denotation. This is as it should be, as belief is a relation to the sense of an expression, not to its reference. Consider ((all woodchuck)woodchuck) and ((all woodchuck)groundhog). In the pres- ence of (3a) these will get equivalent denotations (∪ sends both to truth). Still, they may denote different propositions. As a consequence (7a) and 6 (7b) are not equivalent. In particular, the first statement can be true while the second is false, even with (3a) in force. (7) a. believe ((all woodchuck)woodchuck) john b. believe ((all woodchuck)groundhog) john 3 Ironing out a Redundancy Thomason’s treatment of intentionality is so simple that the introductory paragraphs of Thomason (1980) even express a fear that its simplicity may be mistaken for triviality. Nevertheless, the theory can be simplified a bit further, as it turns out that the non-standard logical constants ∼, ∩, ⊃, ⋂ , ⋃ , and ≈ can be gotten rid of. A closer look at the workings of the theory shows that they are superfluous. The essential function of Thomason’s meaning postulates is to connect the sense of an expression with its denotation. This succeeds, but the non-standard logical constants only play an intermediate role in this. With the exception of (2a), the meaning postulates in (1) and (2) can be given up in favour of the more direct ones in (8). (8) a. ∀P ′∀P[∪(allP ′P) = ∀x[∪(P ′x)→ ∪(Px)]] b. ∀P ′∀P[∪(aP ′P) = ∃x[∪(P ′x) ∧ ∪(Px)]] This short-circuits the theory in a way that will not effect the sense-reference function. The derivation (4), for example, can now be replaced by the slightly shorter (9). (9) ∪((all woodchuck)groundhog) = (8a) ∀x[∪(woodchuck x)→ ∪(groundhog x)] = (2a) ∀x[woodchuck x→ groundhog x] As far as I can see, such a streamlining has no negative impact upon Thoma- son’s theory and in any case the streamlined theory will do as a starting point for this paper. There is an advantage to this that goes beyond simplification of an al- ready simple theory. The logical constants that were dispensed with had a property that is not normally associated with logical constants: their inter- pretations could vary with each model. One of the usual criteria that come with the notion of logicality is that the interpretation of a logical constant in a given model can only depend on the domain(s) of that model. In In- tentional Logic this is not so. For example, it is possible to have models M , 7 M ′, based on the same frame (i.e. with all domains identical), such that, for some Φ, Ψ, [[Φ ∩ Ψ]]M 6= [[Φ ∩ Ψ]]M ′ , even while [[Φ]]M = [[Φ]]M ′ and [[Ψ]]M = [[Ψ]]M ′ . Doing away with ∼, ∩, ⊃, ⋂ , ⋃ , and ≈ rids us of a set of logical constants with a decidedly non-logical behaviour. We still have ∪, but since considerations about logicality similar to those above hold for this constant as well, we will change it into a non-logical constant, receiving its interpretation from the usual interpretation function. 4 A Larger Fragment with Possible Worlds All special logical constants of Intentional Logic have at this point either been dispensed with, or, in the case of ∪, been re-interpreted as ordinary non-logical constants. Technically this boils down to a move from a special- ized type logic to a standard one. In particular, we can use the three-sorted Church-Henkin type logic TY3 in this paper. Ground types will be e, t, s, and p, for entities, truth-values, possible worlds, and propositions respec- tively. We have assumed that the range of the function ∪ is the set of truth values and this has given a purely extensional logic on formulas ∪Φ, but, as was already observed in Thomason’s paper, an attractive alternative is to also consider possible worlds. This will allow us to combine intentionality with the advantages of possible worlds semantics. Accordingly, we will now replace ∪ with a non-logical constant r of type p(st), which sends proposi- tions to sets of possible worlds.9 In Table 2 some non-logical constants are given of which the ones in sans serif will be used to directly translate words of English and the ones in italic will play a role in our meaning postulates.10 This means that the expressions in (10), for example, are of type p. (10) a. ((a woman)walk) b. ((no man)talk) c. (hesperus λx((a planet)(is x))) d. ((if((a woman)walk))((no man)talk)) e. ((if((a man)talk))((no woman)walk)) 9Clearly, on the present account propositions cannot be identified with sets of possible worlds (although they still determine sets of possible worlds). 10The type s(st) constant acc in Table 2 will be used in the meaning postulates for necessarily and possibly. Its denotation plays the role of the usual accessibility relation. Additional meaning postulates may further constrain the behaviour of acc, requiring re- flexivity, transitivity, etc. Details are left to the reader. 8 Non-logical Constants Type Non-logical Constants Type not pp hesperus, mary, . . . e and, or, if p(pp) love, kiss, . . . e(e(st)) every, a, no, the (ep)((ep)p) planet, man, run, . . . e(st) is, love, kiss, . . . e(ep) acc s(st) hesperus, mary, . . . (ep)p try, wish p(e(st)) planet, man, run, . . . ep believe, know, aware p(e(st)) necessarily, possibly pp try, wish p(ep) believe, know, aware p(ep) Table 2: Some non-logical constants f. (mary(aware((if((a woman)walk))((no man)talk)))) g. (mary(aware((if((a man)talk))((no woman)walk)))) h. ((a woman)λx(mary(aware((if(walk x))((no man)talk))))) i. (mary λx((try(run x)) x)) It should be emphasized that these expressions contain no logical constants (unless λ is regarded as such). The constants some, no etc. are non-logical, but will be connected to their expected logical interpretation shortly. Also, although there is a clear and intended analogy with natural language, these are logical terms, amenable to logical manipulation. Let us write TLF for the smallest set of terms that a) contains all variables of type e, b) contains all constants for which we have used sans serif type in Table 2, and c) is closed under application and abstraction over variables of type e. The examples in (10) are closed TLF terms of type p. Note that closed TLF terms are virtually identical to the ‘Logical Forms’ we find in generative syntax, whence the subscript. The following are meaning postulates connecting the p and st levels (initial universal quantifiers are suppressed, so free variables get a universal interpretation). (11) a. r(not π) = λi.¬rπi b. r(and ππ′) = λi.rπi ∧ rπ′i c. r(or ππ′) = λi.rπi ∨ rπ′i d. r(if ππ′) = λi.rπi→ rπ′i e. r(every P ′P) = λi.∀x[r(P ′x)i→ r(Px)i] f. r(a P ′P) = λi.∃x[r(P ′x)i ∧ r(Px)i] 9 g. r(no P ′P) = λi.¬∃x[r(P ′x)i ∧ r(Px)i] h. r(necessarily π) = λi.∀j[acc ij → rπj] i. r(possibly π) = λi.∃j[acc ij ∧ rπj] j. r(mary P) = r(P mary) (and similarly for hesperus etc.) k. r(is xy) = λi.(x = y) l. r(love xy) = love xy (similarly for kiss, . . . ) m. r(planet x) = planet x (similarly for man, woman, . . . ) n. r(believe πx) = believeπx (similarly for try, wish, know, aware) Again, these postulates can be used to compute the truth conditions associ- ated with proposition denoting terms. In (12), for example, it is shown how (10d) unfolds. (12) r((if((a woman)walk))((no man)talk)) = (11d) λi.r((a woman)walk)i→ r((no man)talk)i = (11f) λi.∃x[r(woman x)i ∧ r(walk x)i]→ r((no man)talk)i = (11g) λi.∃x[r(woman x)i ∧ r(walk x)i]→ ¬∃x[r(man x)i ∧ r(talk x)i] = (11m) λi.∃x[woman xi ∧ walk xi]→ ¬∃x[man xi ∧ talk xi] Let w be some fixed constant of type s (which we can think of as denoting the actual world). Type p terms A1, . . . , An will be said to entail a type p term B if (11), rA1w, . . . , rAnw |= rBw , i.e. if, given the meaning postulates in (11), truth of A1, . . . , An in the ac- tual world implies truth of B in the actual world, or, equivalently, if the intersection of rA1, . . . , rAn must denote a subset of rB, given the meaning postulates. The truth conditions of (10e) can be found using a computation very similar to the one in (12) and clearly (10d) and (10e) co-entail. On the other hand, it is consistent to assume that (10d) 6= (10e) and equivalence of (10f) and (10g) cannot be derived. The truth conditions of (10f) are given in (13a), those of (10g) in (13b). Since the embedded type p terms need not corefer, (13b) could be true in some world where (13b) is false. The treatment therefore is hyperintensional and does not suffer from the logical omniscience problem. (13) a. aware ((if((a woman)walk))((no man)talk)) mary b. aware ((if((a man)talk))((no woman)walk)) mary 10 5 A Short Comparison with Other Approaches There is a sense in which Thomason’s is an almost minimal theory of in- tentionality: the few ingredients present in it must well-nigh be present in any other theory of hyperintensional phenomena as well. If a theory of in- tentionality is to say anything about the logical relations we find among expressions it should contain some algebraic domain L where we find no- tions such as entailment, conjunction, disjunction and the like. It should presumably also contain some domain P of propositions. If L is anything like the usual algebras of truth-values, possible worlds etc., it must be dis- tinct from P, as identifying L and P in that case will immediately lead to the very problems any theory of hyperintensionality is set out to solve. There must also be a connection C associating the P and L domains, as it is uncontroversial that propositions (often) do have truth-conditions and do enter into logical relationships. In the previous section L was the domain of type st, P the domain of type p and C was the function r, whose behaviour was axiomatized in (11). While mentioning these elements almost sums up Thomason’s theory, it seems that very similar ones must also be present in competing approaches, and indeed if we analyse some of these it is not difficult to recognize the L, P and C ingredients. Take, for example, the theory of structured meanings, which took its origin in Carnap (1947) and was revived in Lewis (1972) and Cresswell (1985). On Lewis’ account the meaning of an expression is a finite ordered tree having at each node a category and an appropriate intension. The intension associated with the expression is the one found at the root of that tree. The role of the domain P is therefore played by a set of trees labelled with categories and intensions; the domain L is a domain of intensions, much as in our previous section; and the connection C is given by simply taking the intension found at the root node of any meaning.11 Since the identity criteria of trees of intensions are more fine-grained than those of these intensions themselves, most unwanted equivalences are blocked. Another example of an approach in which the essential ingredients of Thomason’s theory can easily be recognised is the theory of impossible worlds. The idea behind this line of thought is that if the usual set of possible worlds is not large enough to make enough distinctions between se- mantic values, extra worlds, impossible ones, should be added. A key point is that the logical operators need not have their usual meaning at these 11In fact the construction of meanings in Lewis (1972) is such that postulates closely akin to (11) will be satisfied by this C. 11 points of reference and that logical validities will therefore cease to hold throughout the set of all worlds. The name “impossible (possible) world” derives from Hintikka (1975), but the idea was also present in Montague (1970) and Cresswell (1972) and has been followed up in Rantala (1982), Barwise (1997), and Zalta (1997), to mention but a few. The set P here consists of sets of possible and impossible worlds; L contains only sets of possible worlds and C is the function that, given any set of worlds, returns the subset that contains just the possible ones, i.e. those in which the logical operators do have their standard meaning. For a formulation of impossible worlds semantics very much along these lines but within a standard logic, see Muskens (1991). For a third approach in which the Thomasonian ingredients are manifest, let us look at Property Theory (Turner 1987; Chierchia and Turner 1988; Fox and Lappin 2001). Property Theory does not only give an account of hyperintensionality, but also aims to be a theory of self-predication (as in having fun is fun). This makes it harder to compare the approach with the current one, but if one looks at models for the theory, as given in Chierchia and Turner (1988), one finds a homomorphism T sending an algebra of ‘information units’ I to a boolean algebra P. These are essentially our C, P and L ingredients respectively (see also Lappin and Pollard 2000), and the basic picture reemerges. When we claimed minimality for Thomason’s theory above, we were careful to hedge our claim by calling it an almost minimal theory of in- tentionality. There was a good reason for this hedge, as in fact one can do without the L and C ingredients. Consider the entailment relation on propo- sitions defined in the previous section. It is easy to see that this relation is reflexive and transitive but that it is not necessarily antisymmetric. It is therefore a preorder and using the interpretations of and, or, if and not one easily sees that our p domains form a boolean prelattice (as defined in Fox, Lappin, and Pollard 2002). Of course, this notion can also be axiomatized independently and one then can do without a domain of truth values. This is the strategy followed in Fox, Lappin, and Pollard (2002) who also construct worlds as ultrafilters on their basic boolean prelattice. The paper describes a higher-order logic that is close to Church’s simple theory of types and to the approach we have described above. However, in the following section we shall argue that the trajectory from propositions to truth-conditions is of independent interest and admits of a computational interpretation. A move to discard the L and C elements (or to identify P and L, another way to view the matter) therefore does not suit our purposes. For a last comparison, let us consider an area where nonextensionality is 12 studied for reasons that differ from our present concerns: the proof theory and model theory of higher order logic. It has long been known that the axiom of extensionality is an obstacle to proving cut-elimination for higher order logic. However, Takahashi (1967) and Prawitz (1968) manage to prove cut-elimination by considering a wider class of structures that are not nec- essarily extensional (the extensionality axiom can be added again after the theorem has been proved). Such nonextensional structures have also been used in Andrews (1971), which lies at the basis of much work in computa- tional higher order logic, but, somewhat surprisingly, an explicit modeltheo- retic use of them had to await more recent times (Fitting 2002; Benzmüller, Brown, and Kohlhase 2004; Muskens 2005). In Fitting (2002) one finds a construction in which type logical expressions of type t are mapped to domains H(t) of that type. The elements of these domains need not be sets, not even if t = 〈t1, . . . , tn〉 is complex (Fitting uses relational, not functional, types). A special extension function E sends objects in domains H(〈t1, . . . , tn〉) to subsets of H(t1) × · · · × H(tn). Again, we see the basic picture emerge, be it on the level of the metatheory of the logic this time, not on its object level. In fact, our domain of type p now corresponds to H(〈s〉) and the extension function E restricted to that domain resembles our r. This is an extremely interesting route to follow, as it proceeds by generalizing existing type logic, not adding to it, with nice complete tableau systems to boot. However, the move of pushing the connection between in- tensions and extensions to the metalevel does not suit our present purposes for a reason just touched upon: we want to explicitly have this connection at the object level in order to be able to give it a computational interpretation. In this section I have mentioned a series of approaches to hyperinten- sionality that are alternatives to the theory this paper is based upon. Lack of space has prevented me to do any of the works mentioned the justice it deserves and I must refer the reader to the originals for details. However, what I do think has been established is the recurrence within all theories of intentionality of a certain pattern in which some function C sends a do- main of propositions P to a logical algebra L. Since Thomason’s theory is a particularly straightforward and lean formalization of this idea, it seems a good idea to study it further. In the next section we will do so, giving a computational interpretation to the connection C. 13 6 Senses as Queries What exactly are propositions? We have treated propositions as primitive objects in our theory and will continue to do so, but this does not preclude a further investigation of their character. There are many theories in which objects that, from a model-theoretic point of view, are considered to be primitives obtain considerable structure when looked at from a theory in- ternal perspective. In axiomatic set theories, for example, the elements of a models’ domain are primitive but they are interpreted as sets from the view- point of the theory. This gives them a rich structure. Likewise, a model of second-order Peano Arithmetic can have any kind of objects in its domain, but the theory will interpret them as indistinguishable from the natural numbers, so that they will enter in all kinds of arithmetical relations. In both cases it is the axioms that impose this structure and since our theory also contains axioms, in the form of meaning postulates, we can ask our- selves what structure they impose on the p domain and what structure the objects in this domain get. Let us take a closer look at (12). This derivation consists of a series of equations, but clearly also allows for a computational interpretation in which we progress from top to bottom. We can therefore interpret our meaning postulates as providing an algorithm that, when given a TLF term of type p as input, returns a term denoting a set of possible worlds. In fact we can also interpret the TLF terms themselves as programs. In such a view the meaning postulates act as a kind of interpreter for the TLF language and the term ((if((a woman)walk))((no man)talk)), for example, is a small program that will lead to the computation in (12). All this happens on the syntactic level of the logic, not on the semantic level. But taking into consideration that it is really the essential function of, say, ((if((a woman)walk))((no man)talk)) that it should lead to (12), it becomes reasonable to start thinking about the proposition that is the de- notation of this type p term as if it were an algorithm itself. When it is run, it calls the algorithms for ((a woman)walk) and ((no man)talk) and uses the output of these to arrive at its own output. In what follows nothing will hinge on this interpretation, at least not formally, but we will let ourselves be inspired by this view when it is necessary to make choices of design. The choice that will fit better into the propositions-as-algorithms picture will be the one that is preferred. The theory thus leads to a computational interpretation but this compu- tational interpretation in its turn naturally leads to a revision of the theory. Since r(π) = τ should now be read as ‘algorithm π will output τ ’ we may 14 well wonder what happens when an algorithm does not lead to an output, as algorithms sometimes do. As things stand the formalization is not able to capture this possibility and we therefore move to a somewhat different set-up. Let d be a constant of type p((st)t). dπτ , written d(π, τ), is to be read as ‘τ is an output of algorithm π’. The possibility that there is no τ for a given π such that d(π, τ) is left open, as computations may fail or diverge. On the other hand, we will not allow any sense to determine more than one set of worlds and so we will adopt the following functionality requirement as a meaning postulate. (14) d(π, τ) ∧ d(π, τ ′)→ τ = τ ′ From now on statements using d (and its generalizations dn—see below) will replace statements that make use of r. We could now proceed with giving meaning postulates such as those in (15), where (11b) is replaced by two statements, but in fact a further revision of the theory suggests itself. If our meaning postulates are to capture the computation that is needed when progressing from sense to reference (or from sense to reference-in-each-possible-world), then (15a) is needed, but (15b) seems superfluous. In order to find a value τ such that d(and ππ ′, τ) we need to find τ ′ and τ ′′ such that d(π, τ ′) and d(π′, τ ′′) and set τ = λi.τ ′i∧τ ′′i. For going in the opposite direction there is no need. (15) a. d(π, τ) ∧ d(π′, τ ′)→ d(and ππ′, λi.τ i ∧ τ ′i) b. d(and ππ′, τ)→ ∃τ ′τ ′′[d(π, τ ′) ∧ d(π′, τ ′′) ∧ τ = λi.τ ′i ∧ τ ′′i] Readers familiar with logic programming12 will recognize (15a) as (a variant of) a definite clause. If we can frame the other meaning postulates as defi- nite clauses as well, the set of meaning postulates will be a logic program! This can be done, but a generalization is needed. Using (15a) the statement d(if (john walk)(john talk), λi.walk john i → talk john i) can be concluded from the simpler d(john walk,walk john) and d(john talk, talk john), for ex- ample, and this in general suggests finding the st term associated with a TLF term of type p by progressively breaking down the latter. But meaning postulates such as (15a) are insufficiently general to carry out this plan. Consider (a unicorn)λx.and(walk x)(talk x), for example. Decomposing this term will lead to λx.and(walk x)(talk x), but the rule in (15a) cannot be used for further decomposition in view of the initial abstraction. What is needed 12See e.g. (Apt 1990) for the theory; (Blackburn, Bos, and Striegnitz 2001) is a nice introduction to the programming language Prolog based on this theory. 15 is a general way to associate terms of type enp13 with terms of type en(st). In order to obtain this we will assume the existence of constants dn, where, for each natural number n, dn is of type (enp)((en(st))t). The original d will be d0, but we will continue to write it simply as d. The following postulates are schemas; a concrete postulate can be ob- tained by instantiating n to any natural number, ~z to a sequence of pairwise distinct variables z1 . . . zn, and x and y to distinct variables of type e that are also distinct from all ~z. ~u must be a sequence of variables of type e of length n+2 and ~v a similar sequence of length n+1. The notation dk(R, R) of course entails that R is of type ekp and R is of type ek(st). (16) a. dn(R, R)→ dn(λ~z.not R~z, λ~zλi.¬R~zi) b. dn(R, R) ∧ dn(R′, R′)→ dn(λ~z.and(R~z)(R′~z), λ~zλi.R~zi ∧R′~zi) c. dn(R, R) ∧ dn(R′, R′)→ dn(λ~z.or(R~z)(R′~z), λ~zλi.R~zi ∨R′~zi) d. dn(R, R) ∧ dn(R′, R′)→ dn(λ~z.if(R~z)(R′~z), λ~zλi.R~zi→ R′~zi) e. dn+1(R, R) ∧ dn+1(R′, R′)→ dn(λ~z.every(R′~z)(R~z), λ~zλi∀x[R′~zxi→ R~zxi]) f. dn+1(R, R) ∧ dn+1(R′, R′)→ dn(λ~z.a(R′~z)(R~z), λ~zλi.∃x[R′~zxi ∧R~zxi]) g. dn+1(R, R) ∧ dn+1(R′, R′)→ dn(λ~z.no(R′~z)(R~z), λ~zλi.¬∃x[R′~zxi ∧R~zxi]) h. dn+1(R, R)→ dn(λ~z.mary(R~z), λ~zλi.∃x[x = mary ∧R~zxi]) i. dn(R, R)→ dn(λ~z.necessarily(R~z), λ~zλi.∀j[acc ij → R~zj]) j. dn(R, R)→ dn(λ~z.possibly (R~z), λ~zλi.∃j[acc ij ∧R~zj]) k. dn+2(λ~u.is xy, λ~uλi.x = y), where ~u contains x and y l. dn+2(λ~u.love xy, λ~u.love xy), where ~u contains x and y m. dn+1(λ~v.planet x, λ~v.planet x), where x is among the ~v n. dn+1(λ~z.believe (R~z), λ~z.believe (R~z)) These schemas are to be interpreted paradigmatically (so, say, (16h) will not only govern the behaviour of mary, but also that of bill, john, hesperus and the like) and can be used to break down any closed TLF term into its constituent parts and compute the value that it determines in terms of the values of the latter. The ~z in (16) take care of variable management and make sure that the bound variables that are encountered in the process of breaking down a TLF term are handled correctly. Here is a derivation using (16) that illustrates the process. 13For any types α and β, we define α0β = β and αn+1β = α(αnβ). 16 (17) d 1(λx.girl x, λx.girl x) d 2(λxy.boy y, λxy.boy y) d2(λxy.kiss yx, λxy.kiss yx) d 1(λx.(every boy)λy.kiss yx, λx∀y.boy yi→ kiss yxi) d((a girl)λx.(every boy)λy.kiss yx, λi∃x[girl xi ∧ ∀y[boy yi→ kiss yxi]]) Reading this derivation from bottom to top, note how superscripts on d increase with each quantifier that is met and how the arguments of the dn come with an initial prefix of lambdas of length n. Not all abstractors in this prefix need to actually bind a variable (e.g. the λx in λxy.boy y does not). The idea is that initial abstractors λ~z contain all variables that potentially occur free in the rest of the term. Note also that the variables in initial abstractors come in the order in which quantification has taken place; this may not be the order in which operators take their arguments. Meaning postulates such as (16l) provide for this possibility by just requiring that the variables filling the argument slots of a given argument-taking expression should be among the variables that are abstracted over, without prescribing order. Derivations such as the one in (17) have a conventional form. They derive statements of the form d(π, τ); they do not find a τ such that d(π, τ), given some π. But since (16) is in fact a logic program it is possible to interpret it as providing an algorithm that does just that. This squares well with the view of senses as recipes for finding referents, and therefore we now turn to this interpretation. First, let us introduce some technicalities. Logic programming involves a notion of unification, but while in the standard theory this notion is taken to involve first-order terms only, we need a generalization, as the terms in (16) contain second-order variables. We must therefore introduce some notions from the theory of higher-order unification (for a survey of higher- order unification theory see Dowek 2001). A substitution σ is defined as a finite function from variables to terms, such that σ(X) and X always have the same type. If dom(σ) = {X1, . . . , Xn} and σ(Xi) = Mi we may use [X1 := M1, . . . , Xn := Mn] to denote σ. If M is a term and σ = [X1 := M1, . . . , Xn := Mn] is a substitution, then Mσ is the term obtained from M by simultaneously substituting each Xi in M by Mi, with possible renaming of bound variables in order to avoid variable clashes. The composition of the substitutions σ1 and σ2 is the substitution σ1σ2 such that, for all variables X, σ1σ2(X) = Xσ2σ1 if X 6= Xσ2σ1 and σ1σ2(X) is undefined otherwise. A unifier of M1 and M2 is a substitution σ such that M1σ and M2σ have the same βη normal form and a most general unifier of M1 and M2 is a unifier σ of M1 and M2 such that for all unifiers ϑ of M1 and M2 there is an η such 17 that ϑ = ησ. There is no general algorithm that, given two terms M1 and M2, de- cides whether M1 and M2 have a unifier (Huet 1973). Huet’s proof uses third-order terms while the terms in (16) are second-order, but second-order unification is also undecidable (Goldfarb 1981) and therefore unattractive for our purposes. Fortunately there is a notion of unification, higher-order patterns unification (Miller 1991), that fits our bill. A pattern is a term M such that for every subterm of the form XM1 . . .Mn, where X is a free vari- able, the terms M1, . . . ,Mn are distinct variables bound in M . Note that the terms dk(M,M ′) in (16) are all of this form. Unification of patterns is well-behaved: it is decidable in polynomial time and when a unification problem has a unifier, it has a most general unifier (Miller 1991). We will adopt higher-order patterns unification as our notion of unification here.14 With the right concept of unification in place we can now consider logic programming proper. If α = (α1 . . . (αn−1(αn β)) . . .), for some type α, where β is a basic type, β is called the target type of α. Fix a set of constants A all of whose types have target type t and such that dk ∈ A for all k. Atoms will be terms of type t of the form aM1 . . .Mm, where a ∈ A. Literals will be atoms (positive literals) or the negations of atoms (negative literals), while clauses are disjunctions of literals. Note that a clause with positive literals B1, . . . , Bm and negative literals ¬A1, . . . ,¬An can equivalently be written as A1∧. . .∧An → B1∨. . .∨Bm. In the logic programming literature this is often written in the clausal form B1, . . . , Bm←A1, . . . , An, even when m = 0, in which case the disjunction is identified with ⊥, or when n = 0 and the conjunction reduces to >. The free variables in a clause are interpreted universally, so that a clause is interpreted as its universal closure. A variant of a clause is the result of renaming the free variables of that clause. The variant is fresh (to some proof) if the new free variables have not been used before (in that proof). A clause is Horn if it has at most one positive literal; if it has exactly one, it is called definite; if it has none, it is called a goal or query. In a definite clause A1 ∧ . . . ∧An → B, the atom B is the head and A1 ∧ . . . ∧An is the body. A (logic) program or database is a set of definite clauses. Note that the meaning postulates in (16) form a program.15 14One clarification may be necessary: Higher-order unification is normally defined for languages that are built up from variables and constants, using λ-abstraction and applica- tion only. This means that, since we want the standard theory to apply to our higher-order logic, logical operators such as =, ∀, ∃, ∧, . . . must be treated with the help of these. In order to obtain the universal quantifier, for example, we will assume that, for each type α, the initial vocabulary contains a constant Π(αt)t, and that ∀Xα ϕ is syntactic sugaring for Π(αt)tλXα ϕ. The other logical constants are assumed to be treated in similar ways. 15Programs are usually defined to be finite sets of definite clauses, for obvious practical 18 In logic programming there is a single rule of inference, called the reso- lution rule, which can be formulated as follows. (18) Resolution Rule. Let Π be some logic program and let B1 ∧ . . . ∧Bm → B be a fresh variant of a definite clause in Π. From A1 ∧ . . . ∧Ai ∧ . . . ∧An → ⊥ to infer [A1 ∧ . . . ∧Ai−1 ∧B1 ∧ . . . ∧Bm ∧Ai+1 ∧ . . . ∧An → ⊥]σ , where σ is the most general unifier of B and Ai. The atom Ai is called the selected atom. This resolution rule can be used in the following manner. Suppose that, given the program in (16), you want to find a τ such that (19) d((if((a woman)walk))((no man)talk), τ) holds. This amounts to finding a constructive proof for (20) ∃τ d((if((a woman)walk))((no man)talk), τ) , i.e. a proof that does not only affirm the existence of such a τ , but also gives one. In order to find this constructive proof, you can form the query (21) ← d((if((a woman)walk))((no man)talk), τ) and try to refute it. This will work because the query is equivalent to the negation of the sentence you want to prove. There is exactly one clause in (16) whose head unifies with the only atom in this goal, namely (16d), the rule for if, with n = 0. Here is a fresh variant of that rule, in claual form. (22) d(ifπ1π2, λi.τ1i→ τ2i)← d(π1, τ1), d(π2, τ2) The head of this rule unifies with your query, with most general unifier reasons. But since the meaning postulates in (16) are schemas which have infinitely many instantiations, we will allow programs to be infinite. Even so, our derivations have the property that, at each inference step, only finitely many (and in fact just one singular) definite clause needs be considered. 19 (23) [π1 := ((a woman)walk), π2 := ((no man)talk), τ := λi.τ1i→ τ2i] The value of τ has now been expressed in terms of the new variables τ1 and τ2 and you can proceed with trying to find values for these, continuing with the new goal (24) ← d(((a woman)walk), τ1), d(((no man)talk), τ2) . The rest of the search is depicted in Figure 1, where only those parts of the relevant substitutions are given that matter for the final answer. Note that the computation ends with ←, which is short for the absurdity ⊥←>, and the original query has thus been refuted. The conclusion is that a τ with the given specifications indeed exists and composition of the substitutions that were found gives it the value (25) λi.∃x[woman xi ∧ walk xi]→ ¬∃x[man xi ∧ talk xi] Figure 2 gives a similar refutation for a query that is slightly more complex than (21), with more embedding of operators. The reader will have no difficulty in constructing more examples. Figure 3 goes the other way round; it takes (25) and then starts out finding the corresponding π, which clearly must lead to the value π = (if((a woman)walk))((no man)talk) . The query in a sense is the reverse of (21). Note however that in general the reversibility of computations is imperfect in the following sense. For any closed π in TLF it is possible to compute a τ such that d(π, τ). Moreover this τ will be equivalent to any τ ′ such that (16) |= d(π, τ ′). But the reverse is not the case. On the one hand, some closed st terms τ may lack a π such that d(π, τ) will be computed, and, on the other, equivalent τ and τ ′ may lead to nonequivalent π and π′ such that d(π, τ) and d(π′, τ ′). This is because the equivalence relation on terms of type p has much finer grain than that on terms of type st. We now come back to the question asked at the beginning of this sec- tion and to our decision to interpret propositions as algorithms, at least informally. Clearly, the theory in itself does not force us to make any iden- tification of the model-theoretic object denoted by a given term Φ of type p and the query ← d(Φ, τ), but we may decide that this is the intended in- terpretation. More generally, we can identify the denotation of any closed TLF term Θ of type e np with the query ← dn(Θ, R), where R is a variable of type en(st). Such a computational interpretation answers some questions 20 ← d((if((a woman)walk))((no man)talk), τ ) ← d(((a woman)walk), τ1), d(((no man)talk), τ2) ← d(((a woman)walk), τ1), d 1(man, P1), d 1(talk, P2) ← d(((a woman)walk), τ1), d 1(talk, P2) ← d1(woman, P3), d 1(walk, P4), d 1(talk, P2) ← d1(walk, P4), d 1(talk, P2) ← d1(walk, P4) ← τ := λi.τ1i→ τ2i(16d) τ2 := λi.¬∃x[P1xi ∧ P2xi](16g) P1 := man(16m) τ1 := λi.∃y[P3yi ∧ P4yi](16f) P3 := woman(16m) P2 := talk(16m) P4 := walk(16m) Figure 1: A refutation of ← d((if((a woman)walk))((no man)talk), τ). Se- lected atoms are underlined. Composition of the substitutions that are found gives the value τ = λi.∃x[woman xi ∧ walk xi]→ ¬∃x[man xi ∧ talk xi]. about the identity relation on senses. For example, the question whether, in general, not notΦ = Φ has an immediate negative answer. The first leg of this equation leads to the computation in (26), while the second does not. (26) ← d(not not Φ, τ ) ← d(notΦ, τ1) ← d(Φ, τ2) ... τ := λi.¬τ1i τ1 := λi.¬τ2i What about conjunctions? Will the interpretation of senses as queries force us to identify andΦ1Φ2 and andΦ2Φ1, for arbitrary Φ1 and Φ2? This de- pends on our identification criteria for queries. (27) ← d(andΦ1Φ2, τ ) ← d(Φ1, τ1), d(Φ2, τ2) ... τ := λi.τ1i ∧ τ2i ← d(andΦ2Φ1, τ ) ← d(Φ2, τ2), d(Φ1, τ1) ... τ := λi.τ2i ∧ τ1i In (27) it is shown how the first proposition under consideration leads to ← d(Φ1, τ1), d(Φ2, τ2), while the second leads to ← d(Φ2, τ2), d(Φ1, τ1). 21 ← d((a man)(λx.necessarily((every unicorn)(λy.kiss yx))), τ ) ← d1(man, P1), d 1(λx.necessarily((every unicorn)(λy.kiss yx)), P2) ← d1(λx.necessarily((every unicorn)(λy.kiss yx)), P2) ← d1(λx.(every unicorn)(λy.kiss yx), P3) ← d2(λx.unicorn, R1), d 2(λxy.kiss yx,R2) ← d2(λxy.kiss yx, R2) ← τ := λi∃x[P1xi ∧ P2xi] P1 := man P2 := λxλi∀j[acc ij → P3xj] P3 := λxλi∀y[R1xyi→ R2xyi] R1 := λx.unicorn R2 := λxy.kiss yx Figure 2: ← d((a man)(λx.necessarily((every unicorn)(λy.kiss yx))), τ) leads to a refutation as depicted here. In each case the first atom is se- lected. Composition of subsitutions gives τ = λi∃x[man xi ∧ ∀j[acc ij → ∀y[unicorn yj → kiss yxj]]]. These queries are certainly equivalent and that would warrant the conclu- sion that the two propositions are identical.16 On the other hand, while in computations that arise from (16) atoms can always be selected in any order, it is evident that as soon as things are scaled up and anaphora and presup- positions are taken into account, dependencies will arise that will make some form of control imperative (the next section will give an example). In fact, it seems almost unavoidable to assume that natural language has a control regime that computes subgoals more or less strictly in the left-to-right order in which they appear in syntax (either surface syntax or LF). If control is factored in into the identity criteria for queries in some way, the propositions andΦ1Φ2 and andΦ2Φ1 may well be distinguished. At the start of this section we decided to replace the function r, that was sending propositions to their corresponding sets of possible worlds, by a relation d (or rather a family of relations dn). This necessitates a redefinition of the notion of entailment between propositions, as the definition in section 4 depended on r. Although it is true that for every closed term Φ ∈ TLF of type p there is a ϕ such that d(Φ, ϕ) is derivable from the meaning postulates, this property will not be retained in the following section. The definition of entailment between propositions must therefore take into account the possibility that propositions may fail to determine a set of worlds. (28) gives two notions that seem reasonable, one of strict entailment, where all 16This conclusion agrees with the one reached in Moschovakis (1994). 22 ← d(π, λi.∃x[woman xi ∧ walk xi]→ ¬∃x[man xi ∧ talk xi]) ← d(π1, λi.∃x[woman xi ∧ walk xi]), d(π2, λi.¬∃x[man xi ∧ talk xi]) ← d(π1, λi.∃x[woman xi ∧ walk xi]), d 1(P1,man), d 1(P2, talk) ← d(π1, λi.∃x[woman xi ∧ walk xi]), d 1(P2, talk) ← d1(P3,woman), d 1(P4,walk), d 1(P2, talk) ← d1(P4,walk), d 1(P2, talk) ← d1(P4,walk) ← π := if π1π2 π2 := noP1P2 P1 := man π1 := aP3P4 P3 := woman P2 := talk P4 := walk Figure 3: A refutation of ← d(π, λi.∃x[woman xi ∧ walk xi] → ¬∃x[man xi ∧ talk xi]). Selected literals are underlined. π = (if((a woman)walk))((no man)talk) results if substitutions are composed. propositions involved are required to provably determine a set of worlds, and a derived notion of entailment that leaves room for non-determining propositions, as long as these are redundant to the argument. (28) Entailment between Propositions. Let Φ1, . . . ,Φn and Ψ be terms of type p and let MP be a set of meaning postulates. We say that Φ1, . . . ,Φn strictly entail Ψ given MP if 1. MP |= ∃τ d(Ξ, τ) holds for all Ξ ∈ {Φ1, . . . ,Φn,Ψ}, and 2. MP, d(Φ1, ϕ1)∧ . . .∧d(Φn, ϕn)∧d(Ψ, ψ)∧ϕ1w∧ . . .∧ϕnw |= ψw, where the ϕk and ψ are any terms of type st and w is any constant of type s If Γ is a set of type p terms, Γ is said to entail Ψ given MP if there are Φ1, . . . ,Φn ∈ Γ such that Φ1, . . . ,Φn strictly entail Ψ given MP. The fact that some propositions may fail to determine a set of worlds in extensions of our system also creates room for variation where meaning postulates are concerned. Consider the treatment of and, or and if. If the meaning postulates in (16) are all we can go by, a term ifΦ1Φ2 can only prov- ably determine a set of worlds if both Φ1 and Φ2 do. Similar remarks can be made about and and or. The situation resembles that of having a Weak 23 Kleene evaluation scheme in a logic with truth value gaps, where a com- plex formula will be undefined if one of its constituent parts is. Additional meaning postulates can be adopted and then lead to behaviour reminiscent of stronger evaluation schemes. Adding the following set, for example, gives a Strong Kleene way of evaluating:17 (29) a. d(π1, λi.⊥)→ d(andπ1π2, λi.⊥) b. d(π2, λi.⊥)→ d(andπ1π2, λi.⊥) c. d(π1, λi.>)→ d(or π1π2, λi.>) d. d(π2, λi.>)→ d(or π1π2, λi.>) e. d(π1, λi.⊥)→ d(ifπ1π2, λi.>) f. d(π2, λi.>)→ d(ifπ1π2, λi.>) Whether such extra meaning postulates need be adopted may be a matter of empirical investigation. But it is curious that one can, within one logic, have options that are strongly reminiscent of evaluation schemes that in the usual setting are constitutive of different logics. 7 Circular Propositions ‘A logical theory,’ Russell famously wrote in On Denoting, ‘may be tested by its capacity for dealing with puzzles . . . ’ The puzzles we are turning to in this section are the Liar and friends. Linguistic semantics has an obligation to say something about these puzzles for the simple reason that they can be formulated very easily in natural language, with the help of mechanisms that seem central to the workings of language itself and that, in a vast majority of cases, present no puzzle at all. Semantic theory must explain the workings of these mechanisms, and if it does, the behaviour of the Liar should follow from this explanation as a corollary. The ingredients of the Liar are well-known: self-reference and the ca- pacity to talk about truth and falsity. But, as Kripke (1975) has argued convincingly, the property of self-reference, although it needs to be present if a sentence18 or set of sentences is to be circular, need not be evident from a Liar-like sentence at all, and even a seemingly innocent statement like (30), may, under unfavourable circumstances, turn out to be paradoxical. 17The formulation in (29) can easily be extended to deal with dn for arbitrary n. 18I will take a sentence to be circular if the proposition it expresses (on the intended reading) is circular. 24 (30) Most of Blair’s assertions about Iraq are false A set of unfavourable circumstances which turn (30) into a paradox are: (30) is uttered by Jones, whose other statements about Iraq are all true. Blair’s statements about Iraq, on the other hand, are evenly divided among the True and the False, with the exception of one extra claim, the contention that everything Jones says about Iraq is true. It is easy to see that paradox results. This shows that circular sentences need not wear self-referentiality upon their sleeves, that normal utterances can turn out to be circular, and that the normal mechanisms that allow reference to other statements, the kind of mechanisms linguistic theory has to deal with, are sufficient to also obtain circular reference. What about the other ingredient for the paradox, the possibility to pro- nounce a statement true (or false)? We are conditioned to think about languages that can express their own syntax here, and about a truth predi- cate that can hold or fail to hold of syntactic objects expressed with the help of coding (e.g. Gödel numbering). But in a setting such as the present one, where propositions are available as first-class citizens, it seems much more natural to let truth and falsity attach directly to the latter (see also Barwise and Etchemendy 1987). In fact, as Moschovakis (1994) makes clear, as soon as self-reference is present in such a setting, the paradoxes already pop up with the help of negation only. The following are informal examples of the Liar (31a) and the Truth-teller (31b) considered by Moschovakis (1994). (31) a. ¬(31a) b. (31b) Let us build truth, falsity, and reference to propositions into the TLF lan- guage by adding the non-logical constants true and false of type pp and the constants this, that, this0, that0, this1, that1, . . . of type p to the list of sans serif constants in Table 2 and by closing off as before. (32) a. A: If a woman is walking no man is talking. B: That’s true. b. (if((a woman)walk))((no man)talk) c. (true that) d. ant(that, (if((a woman)walk))((no man)talk)) The little dialogue in (32a) can be translated with the help of (32b) and (32c), which are closed TLF terms of type p under the new definition. But 25 ← d(true that, τ ) ← d(that, τ ) ← ant(that, π), d(π, τ ) ← d((if((a woman)walk))((no man)talk), τ ) ... (continued as in Figure 1) π := (if((a woman)walk))((no man)talk) Figure 4: A refutation tree for d(true that, τ). Added to the database is the information that ant(that, (if((a woman)walk))((no man)talk)). the translation is incomplete if it does not additionally represent the fact that the demonstrative in B’s utterance is anaphorically linked to A’s obser- vation. This is expressed in (32d), where the p(pt) constant ant expresses antecedenthood. It is assumed that ant ∈ A, so that the constant is treated on a par with the dn. We need meaning postulates for the new constants. Those for the truth predicates in (33), essentially treat false as negation and true as the redun- dant connective that Frege already thought it was. (33) a. d(π, τ)→ d(true π, τ) b. d(π, τ)→ d(false π, λi.¬τi) The postulates for the constants translating demonstrative pronouns are given in (34). The basic idea is that the set of worlds determined by such a constant is simply the set of worlds determined by its antecedent. (34) a. ant(this, π) ∧ d(π, τ)→ d(this, τ) b. ant(that, π) ∧ d(π, τ)→ d(that, τ) Now assume that whenever a hearer figures out that an anaphoric relation holds between a demonstrative pronoun that (or this) and some sentence translated by the p term Φ, he adds ant(that,Φ) to his database of defi- nite clauses. For example, a person overhearing (32a) who interprets the anaphoric relation between that and A’s utterance in the way obviously in- tended by B may add (32d) to his logic program. This seems to be a natural way to deal with anaphoric elements. While other words have more or less fixed meanings and thus can obtain meaning from postulates permanently 26 ← d(false this, τ ) ← d(this, τ1) ← ant(this, π), d(π, τ1) ← d(false this, τ1) ← d(this, τ2) ... τ := λi.¬τ1i π := false this τ1 := λi.¬τ2i ← d(true this, τ ) ← d(this, τ ) ← ant(this, π), d(π, τ ) ← d(true this, τ ) ← d(this, τ ) ... π := true this a.– Liar b.– Truth-teller Figure 5: Search trees for the Liar (a) and the Truth-teller (b). In case of the Liar ant(this, false this) was added to the program; for the Truth-teller this was ant(this, true this). In both cases search results in an infinite loop. present in the database, the meaning of an anaphoric element depends on its antecedent and therefore must lead to an addition to the logic program after that antecedent has been established. Now consider the query ← d(true that, τ) in a context where (32d) was added to the database. Figure 4 gives a refutation tree,19 that in a few steps leads to the query considered in Figure 1. Executing this query (or remembering its result) will establish that (32b) and (32c) determine the same set of worlds. We have now set up a rudimentary mechanism dealing with reference to propositions and truth that will work in perfectly unspectacular ways in normal cases. But it will also lead to circular behaviour. Consider the Liar, formalized in (35). (35) a. false this b. ant(this, false this) When← d(false this, τ) is evaluated against a database which contains (35b), a search as in Figure 5a results, with a variant of the original query reached in a few steps. A very similar behaviour results if the Truth-teller is evaluated. (36) a. true this 19Note that here we have an example where adding control is necessary. It would not be a good idea to select the atom d(π, τ ) from the query← ant(that, π), d(π, τ ) in Figure 4 as this would lead to unnecessary indeterminism. 27 b. ant(this, true this) The latter’s formalization is given in (36) and a search tree is given in Figure 5b. A simple example of a Liar cycle is found in (37), with (37a) referring to (37b) and vice versa. If ← d(true that0, τ) is evaluated with (37c) and (37d) added to the database, circular behaviour will occur. (37) a. true that0 b. false that1 c. ant(that0, false that1) d. ant(that1, true that0) A difference between the Liar and the Truth-teller is that it seems possible to arbitrarily assume that the Truth-teller is true (or false), while no such assumption is possible in case of the Liar. The present formalization agrees with this intuition, as adding an extra d(true this,>) (or d(true this,⊥)) to the database considered in (36) is perfectly possible (and leads to a one-step refutation of ← d(true this, τ)), but adding d(false this,>) to the database for (35) leads to conflict with (14). Thus the senses-as-queries view, when combined with mechanisms for referring to propositions and talking about truth, leads to normal results in normal cases and to circular results in cases of simple Liar-like sentences. Queries may diverge and propositions therefore may fail to determine a set of worlds. What about more elaborate forms of the Liar paradox such as the Strengthened Liar in (38)? (38) This sentence is false or does not denote Unlike the simple Liar, the strengthened Liar uses a word that is not part of the common vernacular but is technical, and it may well be that here we reach a limit of what is expressible in ordinary language. Can a language contain a word denote that is applicable to any statement of that language? We are used to be able to express about anything we like and this creates an illusion that the answer must be ‘yes’, but the senses-as-queries view strongly suggests a negative answer. After all, we know that, in general, there can be no program H that, given the description of any program Π, decides whether Π halts or not, i.e. the Halting Problem is undecidable. But since, in the senses-as-queries view, the question whether a sentence denotes is closely related to the question whether a certain query halts, we should 28 not be surprised if this result carries over to natural language. If senses are queries then the limits of computation are also limits of language. Suppose we had a pp term denotes with the property that, in any model M , d(denotes Φ, λi.>) holds in M if there is a ϕ such that d(Φ, ϕ) holds in M and d(denotes Φ, λi.⊥) is true in M if there is no such ϕ. The usual diagonalization proof that shows the undecidability of the Halting Problem can be turned into a reductio ad absurdum of this assumption provided that meaning postulate (29e) is adopted. Consider (39). (39) a. (if (denotes this1))(false this2) b. ant(this2, false this2) c. ant(this1, (if (denotes this1))(false this2)) It is clear that in any model satisfying (39b) and the previous meaning pos- tulates (39a) will denote iff this1 does not denote. Adding (39c) therefore immediately leads to inconsistency. We conclude that a term denotes with the required properties cannot be part of our system. The reductio follows that of the existence of a machine H deciding the halting problem by con- structing a machine H ′ from it that halts iff its input does not halt ((39a) with (39b) added to the database) and then feeding H ′ to itself (adding (39c)). 8 Conclusion We have shown how a relatively standard fragment of logical grammar can deal with the foundational problems of intentionality and circularity if propositions are accepted as primitive objects, in Thomason’s way, and if the determination relation which associates propositions with sets of possi- ble worlds is axiomatized by means of a logic program. Such a set-up pushes part of the usual Tarski-style interpretation procedure from the metalevel of the logic to the object level and allows us to interpret propositions as queries. Often the result of a query will be some set of possible worlds, but in some cases the query will not lead to a result because it diverges. Distinct queries can lead to the same result and identity criteria on queries can be very strict, thus leading to an intentional (hyperintensional) semantics. A third possibility for queries, besides diverging or duly returning an answer, we have not gone into because it did not fall within the boundaries drawn up for this paper. This is the possibility of aborting with error be- cause necessary preconditions for computation have not been satisfied. This 29 possibility corresponds to the notion of presupposition in natural language but its treatment within (a liberalized version of) the present framework will have to await future work. Acknowledgements This paper is based on talks held at the Sinn und Bedeutung workshop in Osnabrück 2001 and the Sinn und Bedeutung workshop in Konstanz 2002. I would like to thank my audiences there for asking the right questions. Two anonymous referees gave valuable comments. References Andrews, P. (1971). Resolution in Type Theory. Journal of Symbolic Logic 36 (3), 414–432. Apt, K. (1990). Introduction to Logic Programming. In J. van Leeuwen (Ed.), Handbook of Theoretical Computer Science, Volume B, pp. 495– 574. Amsterdam: Elsevier. Barwise, J. (1997). Information and Impossibilities. Notre Dame Journal of Formal Logic 38 (4), 488–515. Barwise, J. and J. Etchemendy (1987). The Liar: An Essay on Truth and Circularity. New York, N.Y.: Oxford University Press. Benzmüller, C., C. E. Brown, and M. Kohlhase (2004). Higher Order Se- mantics and Extensionality. Journal of Symbolic Logic 69, (to appear). Blackburn, P., J. Bos, and K. Striegnitz (2001). Learn Prolog Now! www.consem.org. Carnap, R. (1947). Meaning and Necessity. Chicago: Chicago UP. Chierchia, G. and R. Turner (1988). Semantics and Property Theory. Linguistics and Philosophy 11, 261–302. Church, A. (1940). A Formulation of the Simple Theory of Types. Journal of Symbolic Logic 5, 56–68. Cresswell, M. (1972). Intensional Logics and Logical Truth. Journal of Philosophical Logic 1, 2–15. Cresswell, M. (1985). Structured Meanings. Cambridge, MA: MIT Press. 30 Dowek, G. (2001). Higher-Order Unification and Matching. In A. Robin- son and A. Voronkov (Eds.), Handbook of Automated Reasoning, pp. 1009–1062. Amsterdam: Elsevier. Dummett, M. (1978). Truth and Other Enigmas. London: Duckworth. Fitting, M. (2002). Types, Tableaus, and Gödels God. Dordrecht: Kluwer Academic Publishers. Fox, C. and S. Lappin (2001). A Framework for the Hyperinten- sional Semantics of Natural Language with Two Implementations. In P. De Groote, G. Morrill, and C. Retoré (Eds.), Logical Aspects of Computational Linguistics, Lecture Notes in Artificial Intelligence, Berlin, pp. 175–192. Springer-Verlag. Fox, C., S. Lappin, and C. Pollard (2002). A Higher-order Fine-grained Logic for Intensional Semantics. In G. Alberti, K. Balough, and P. Dekker (Eds.), Proceedings of the Seventh Symposium for Logic and Language, Pecs, Hungary, pp. 37–46. Goldfarb, W. (1981). The Undecidability of the Second-order Unification Problem. Theoretical Computer Science 13, 225–230. Hintikka, J. (1975). Impossible Possible Worlds Vindicated. Journal of Philosophical Logic 4, 475–484. Huet, G. (1973). The Undecidability of Unification in Third-Order Logic. Information and Control 22, 257–267. Kripke, S. (1975). Outline of a Theory of Truth. Journal of Philosophy 72, 690–716. van Lambalgen, M. and F. Hamm (2003). Moschovakis’ Notion of Meaning as Applied to Linguistics. In M. Baaz and J. Krajicek (Eds.), Logic Colloquium ’01, ASL Lecture Notes in Logic. Lappin, S. and C. Pollard (2000). Strategies for Hyperintensional Seman- tics. ms. Lewis, D. (1972). General Semantics. In D. Davidson and G. Harman (Eds.), Semantics of Natural Language, pp. 169–218. Dordrecht: Rei- del. Miller, D. (1991). A Logic Programming Language with Lambda- abstraction, Function Variables, and Simple Unification. Journal of Logic and Computation 1, 497–536. Montague, R. (1970). Universal Grammar. In Formal Philosophy, pp. 222– 246. New Haven: Yale University Press. 31 Montague, R. (1973). The Proper Treatment of Quantification in Ordi- nary English. In Formal Philosophy, pp. 247–270. New Haven: Yale University Press. Moschovakis, Y. (1994). Sense and Denotation as Algorithm and Value. In Logic Colloquium ’90 (Helsinki 1990), Volume 2 of Lecture Notes in Logic, pp. 210–249. Berlin: Springer. Moschovakis, Y. (2003). A Logical Calculus of Meaning and Synonymy. Corrected and edited notes for a course in NASSLLI 2003. Muskens, R. (1991). Hyperfine-Grained Meanings in Classical Logic. Logique et Analyse 133/134, 159–176. Muskens, R. (2005). Higher Order Modal Logic. In P. Blackburn, J. van Benthem, and F. Wolter (Eds.), Handbook of Modal Logic, Studies in Logic and Practical Reasoning. Dordrecht: Elsevier. (to appear). Prawitz, D. (1968). Hauptsatz for Higher Order Logic. Journal of Symbolic Logic 33 (3), 452–457. Rantala, V. (1982). Quantified Modal Logic: Non-normal Worlds and Propositional Attitudes. Studia Logica 41, 41–65. Takahashi, M. (1967). A Proof of Cut-elimination Theorem in Simple Type Theory. Journal of the Mathematical Society of Japan 19 (4), 399–410. Thomason, R. (1980). A Model Theory for Propositional Attitudes. Lin- guistics and Philosophy 4, 47–70. Tichý, P. (1988). The Foundations of Frege’s Logic. Berlin: De Gruyter. Turner, R. (1987). A Theory of Properties. Journal of Symbolic Logic 52 (2), 455–472. Zalta, E. (1997). A Classically-Based Theory of Impossible Worlds. Notre Dame Journal of Formal Logic 38 (4), 640–660. 32 
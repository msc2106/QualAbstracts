ABSTRACT: 
Background: Arts and health organisations must increasingly provide measurable evidence of impact to stakeholders, which can pose both logistical and ideological challenges. This article examines the relationship between the ethos of an arts and health organisation and external demands for evaluation. Methods: Research involved an ethnographic engagement where the first author worked closely with the organisation for a year. In addition to informal discussions, 20 semi-structured interviews were conducted with core staff and practitioners. Transcribed interviews were coded and emerging themes were identified. Results: Staff considered evaluation to be necessary and useful, yet also to be time-consuming and a potential threat to the organisation's ethos. Nevertheless, they were able to negotiate the terms of evaluation to enable them to meet their own needs as well as those of funders and other stakeholders. Conclusions: While not completely resisting outside demands for evaluation, the organisation was seen to intentionally rework demands for evidence into processes it felt it could work with, thus enabling its ethos to be maintained. 
 
PREDICTION: 
the value and effectiveness of a programme of public health evaluation for a single local authority is investigated .<n> the focus is on the relationship between performance and wellbeing in the context of monitoring and evaluation of a programme of social work ( vxw ) .<n> the study is motivated by the increasing demand for public health evaluation and the need for efficient and effective policies and practices in local government .<n> the analysis of vxw is made in the context of a programme of public health evaluation for a single local authority .<n> the analysis is made in the context of monitoring and evaluation of a programme of social work ( ssw ) . <n> the aim of this study is to investigate the relationship between performance and wellbeing in the context of monitoring and evaluation of a programme of social work ( vxw ) .<n> the analysis is made in the context of a programme of public health evaluation for a single local authority . <n> the aim of this study is to investigate the relationship between performance and wellbeing in the context of monitoring and evaluation of a programme of social work ( ssw ) . <n> the aim of this study is to investigate the relationship between performance and wellbeing in the context of ssw  
 
FULL TEXT: 
  consuming and a potential threat to their ethos. Nevertheless, they were able to negotiate the terms of evaluation to enable them to meet their own needs as well as those of funders and other stakeholders. Conclusions: While not completely resisting outside demands for evaluation, the organisation was seen to intentionally rework demands for evidence into processes they felt they could work with, thus enabling their ethos to be maintained. Keywords: arts and health, evaluation, outcomes, third sector, social enterprise 3 Introduction Arts and health organisations are under pressure to provide evidence of their impact (Staricoff, 2006). The vast majority of projects are managed through third sector organisations. In recent years, the nature of statutory funding has changed, moving from a grants-based system towards one in which third sector organisations are contracted to provide a specific service. A consequence of this is that third sector organisations have been increasingly asked to provide persuasive evidence that their way of working tangibly benefits the communities that they serve (Bridge, Murtagh, & O’Neill, 2009; Buckingham, 2009). In addition, there has been an increased emphasis on good practice, which is concerned with conforming to audit requirements, standards and guidelines (Morison, 2000). On the one hand, some view such approaches as necessary to ensure a high quality of service delivery (Bridge et al., 2009) and to strengthen the legitimacy of arts and health practices. However, it has also been argued that evaluation and ‘best practice’ are particular techniques utilised by the government as a way of exercising control over civil society (Larner & Butler, 2005). Some feel that this increased control has prevented third sector organisations from engaging effectively with local communities (Ilcan & Basok, 2004) as well as undermining collaboration and trust (Milbourne, 2009). This paper examines the relationship between the working ethos of an arts and health organisation with the demands for quantified monitoring and evaluation. Evaluation in Arts and Health The demand for evidence is a demand for a distinct type of evidence - objectively observed and measurable indicators of change in clearly specified dimensions to health and wellbeing. The field of arts and health is not alone in experiencing an increased expectation from funders for measurable monitoring systems. Social and political commentators have located contemporary trends in governance into a Foucauldian framework of disciplinary governmentality. In this framing, power is exercised not in managing the detail of policy implementation, but in managing the driving visions and concepts on the one hand and the monitoring of outputs on the other (Miller & Rose, 2008). In this model, the tight definition of indicators to measure and evaluate impact is far more than the dull, apolitical technique it appears superficially; rather the imperative for indicators in turn shapes, rather than reflects, the ways in which key concepts and processes of policy are conceived. Of particular importance is the dominant ideological 4 position concerning the centrality of the autonomous individual, the potential of the individual for developing one’s own identity and wellbeing, and the responsibility of the individual for maintaining their wellbeing (Atkinson & Joyce, 2011; Miller & Rose, 2008). The use of quantified indicators for monitoring and evaluation is now evident in almost all areas of public life, presenting performance measures, organisation ranked tables and both institutional and individual targets. While most fields are ambivalent about the dominance of and influence exerted by indicator driven methods of assessing performance, the field of arts and health faces particular challenges in meeting this demand. While health commissioners often prefer measurable data to richer, qualitative data (Lawthom, Sixsmith & Kagan, 2007), some have questioned whether this approach is suitable for arts and health projects at all, arguing that there are fundamental differences between arts and health perspectives (Angus, 2002; Dooris, 2005). In particular, the arts contrast traditional medical models, which seek to order and compartmentalise knowledge, in being fluid and incoherent with an explicit exploration of relations in an infinite number of ways (Smith, 2003). Arts practitioners acknowledge evaluation as necessary to demonstrate the benefits of their projects (White & Angus, 2003) and the majority of organisations and practitioners endeavour to evaluate their work in some way and to publicise their findings (Angus, 2002; Hacking, Secker, Kent, Shenton, & Spandler, 2006; Health Development Agency, 2000). However, much evaluation of arts and health activities is based around subjective interpretations or anecdotal evidence (Matarasso, 1997), and is thus deemed inadequate within the contemporary enthusiasm for monitoring. Many projects often “reinvent the wheel” by designing their own questions that could have been captured using existing measures (Hacking et al, 2006; Secker, Hacking, Spandler, Kent & Shenton, 2007). Very few projects monitor participants longitudinally, or include a control comparison group (Burton, 2009; MBC Sefton, 2009). At the same time, the use of randomised control trials would have both ethical and practical difficulties (Jermyn, 2001; MBC Sefton, 2009; Thomson et al, 2004). Longitudinal studies may pose difficulties given the frequent high turnover of participants (Jermyn, 2001), who may come from different backgrounds or be at different stages of progress (Jermyn, 2004). Obtaining measurable data may also pose a challenge for projects which are short term or small-scale, or for those with limited resources and comparatively small numbers of attendees (Angus, 2002; Jermyn, 2001). 5 Beyond these largely technical concerns, three particular challenges exist in measuring the impact of the arts that relate to the lack of clarity as to what outcomes are intended. First, many projects have a large number of stakeholders (Angus, 2002) and, as such, evaluative information designed to satisfy one stakeholder, for example, an arts funder, may not satisfy a medical or statutory funder (Angus, 2002). There is a need for greater clarity from funders, stakeholders, or anyone else seeking evidence on what is acceptable as evidence (Jermyn, 2001), and the uses to be made of such evidence (White & Angus, 2003). Secondly, many arts projects do not explicitly focus on improving health directly, but rather on aspects of health promotion and disease prevention through improving ‘distance travelled’ dimensions such as self-esteem (Angus, 2002; Arts Council, 2007; Nutbeam, 1998; Secker et al, 2007). The concepts involved in impacting on distance travelled, such as social capital, self-esteem, social wellbeing and so forth, are more greatly contested in their meanings and definitions than are specific health-related measures. Thirdly, not only are the meanings and measurement of dimensions to social wellbeing less well agreed, but the location of these dimensions is similarly contested. Monitoring approaches typically focus on measures of health and wellbeing at the individual level. But arts and health projects may explicitly aim to intervene at a community level. The pressure to define individually focussed monitoring indicators tends to undermine an understanding of social wellbeing as primarily a relational rather than an individual attribute. As a result, artists and experienced practitioners are often highly sceptical about the process of evaluation, believing it to be constraining in nature (Smith, 2003). Similarly, the emphasis on economic or managerial definitions of performance has been deemed unsuitable for organisations that primarily have a social focus, as the holistic benefits risk being overlooked (Jermyn, 2001). Mills (2003 cited in Putland, 2008) argued that evaluation reduces the meaning of art to merely a means in which particular targets can be met. Methodology To examine the relationships between the working ethos of arts and health organisations with the demands for quantified monitoring and evaluation, we used a case study approach (Yin, 2009). Whilst a single case study may limit transferability of findings to other third sector or ‘arts and health’ organisations, the ‘thick description’ of a case study enables detailed study of the daily challenges and dilemmas facing an organisation caught between the need to interact with a range of funders and the desire to maintain its holistic, person-centred and community-centred ethos. The research involved an ethnographic engagement in which the first author worked closely alongside core staff, practitioners and 6 participants and participated in the day to day running of the organisation, its interactions with funders and other stakeholders, and its relationship with participants. Overt participant observation was conducted in a number of settings within the organisation, ranging from team meetings through to the various activities. Adopting such an in-depth approach enabled a greater understanding of how both core staff and practitioners manage evaluation on a daily basis. The researcher was largely independent of the organisation, funded externally through a post-graduate scholarship from the Economic and Social Research Council. This was, however, a CASE studentship in which the research, which focussed on the tensions between the organisation’s ethos and the contemporary climate of quantified monitoring, was developed based on the partner organisation’s own central concerns. In addition to informal discussions within the office or during sessions, semi-structured interviews were conducted with core staff and practitioners. Interviews focussed on a variety of topics, including the interviewee’s relationship to the organisation, how their work had changed over time, and how they felt arts and health schemes were generally perceived. The interviews were useful in allowing any observations to be followed up in more detail, as well as allowing the opinions of core staff and practitioners to be compared. Questions were tailored to the interviewee depending on their position and experience, whilst remaining flexible enough to allow for any interesting points to be explored further (Bryman, 2008). This paper draws upon twenty interviews conducted with twelve staff members between July 2010 and June 2011. Ethical approval for this study was granted through Durham University. The names of the organisation and interviewees are pseudonyms to protect their identities. Transcripts and field notes were printed, with any important observations and statements highlighted and assigned a code. Coding occurred concurrently with data collection, and enabled emerging themes to be explored, confirmed, or followed up in greater depth (Bryman, 2008). Given the focus on how the organisation interacts with and negotiates the demand for quantified monitoring, the three broad themes that structure the results emerged from an implicit dialogue between the researcher, the literature and the participants. These three themes are the value of evaluation, the risks of evaluation, and the negotiation of evaluation. 7 A Community Arts and Health Organisation The case study was based on a community arts and health organisation located in a small market town in Northern England, to which the pseudonym ‘Artspace’ has been given. Its overall aim is to use creativity and celebration to promote the health and wellbeing of both individuals and communities, engaging with participants in a safe and non-judgemental environment. Whilst predominantly providing arts-based interventions, Artspace has an expanded view of ‘artistry’ as doing something well, which may include cooking, gardening, or even healthy living. Despite historically focussing on the needs of disadvantaged or isolated people, Artspace is open to all in the surrounding community and further afield, playing an important role in nurturing social inclusion. Whilst Artspace operates out of a specific building, the organisation believes in fostering relationships through celebration and gathering, and runs several community projects such as lantern making workshops which precede the annual lantern parade. The organisation also runs sessions or groups in other towns and villages in the district, recognising that obtaining transport to the main centre may be difficult for many people in the surrounding rural areas. Artspace considers itself a social enterprise, defined by the previous government in the United Kingdom as ‘a business with primarily social objectives whose surpluses are principally reinvested for that purpose in the business or in the community, rather than being driven by the need to maximise profit for shareholders and owners’ (DTI, 2002). Social enterprises adopt a ‘double bottom line’ mode of accounting that recognises not only the extent of income generation but also the production of social value and meeting social obligations (Emerson & Twersky, 1996). While the exact definition of a social enterprise may differ between countries owing to their emergence at different times and in response to different events, organisations face similar challenges when balancing their focus between income generation and meeting their social goals (Borzaga & Defourny, 2001). In the last few years, Artspace has expanded, purchasing its own premises and diversifying their services. Since Artspace owns its premises, it can generate income through room hire to community groups and to the local county council, who run a range of adult learning classes. It also runs a weekly community café, but the organisation is looking to expand the range of income generating activities, for example, through becoming a training provider for arts and health work, and through sales of craftwork 8 produced by participants. Nonetheless, the nature of the work means that Artspace is likely to remain largely dependent on income from grants and contracts, much of which is limited or short-term in nature. The organisation receives its income from a number of sources, including trusts, the local authority, and the Big Lottery. While some of the income was given to Artspace to pay for staff salaries, other income was given for the provision of certain services to participants in the community, with the expectation that specific goals be achieved. In common with many third sector organisations, Artspace must provide evidence to funders that outcomes are being met and that funding is being spent effectively. The Big Lottery monitors the organisation on a quarterly basis through a number of specific outcome measures negotiated with Artspace at the time of the funding bid. Social services are a second significant funder supporting the equivalent to a day service for people with severe and enduring mental health difficulties. Previous statutory evaluation requirements were minimal, limited to monthly returns on the numbers of people attending the sessions paid for by social services. This, however, has changed and Artspace must now report back on individual attendance rather than the total number of people attending a particular session. It is likely that this will further shift in the near future, with the organisation being expected to report back on individual outcomes and participant progression as part of their contract. Artspace will also be affected by reforms in the United Kingdom towards commissioning by General Practitioners (GP) which will likely bring demands for new reporting formats on specific outcomes if GP funding is secured. Findings The Value of Evaluation Members of the organisation were responsive to the prevailing climate of quantified monitoring. Monitoring was deemed to benefit the organisation in three ways: by meeting external demand and promoting the work done by the organisation, by providing a better and personalised service, and by enabling reflective practice. Interviewees generally felt that conducting evaluation was a necessary part of their work and that it helped to ensure their legitimacy. For example, by monitoring the numbers who not only attended specific classes but also who came into the building, they documented a considerable rise in users over a year, showing Artspace’s ever growing importance to the local community. The interviewees saw this kind of tangible evidence as necessary to ensure the organisation’s survival, especially given that it was felt that stakeholders and the wider public were often 9 uninformed as to what they do. Staff were sympathetic to funders’ need for evidence that their money has been spent effectively, and thus felt it was essential that Artspace conducted appropriate evaluation: “…we need that body of evidence to be able to go to funders and say that this is what we can do and this is what we can achieve, so it’s absolutely vital that we do it…” (Interview with Yvonne (core staff), 21/7/10) Moreover, while staff had not conducted as much evaluation in the past as they would have liked, they expected that NHS reforms would result in evaluation becoming a necessity. The proposal for GPs to directly commission services in future made it essential for Artspace to invest substantial time now on obtaining evidence of their activities’ benefits in order to position themselves favourably with the GPs, otherwise they would fail to secure the required levels of funding or recognition: “…so you can’t prove your value without monitoring what you’re doing, so you have to value your existence, and then other people will value your existence as well…” (Interview with Rebecca (core staff), 4/3/11) Despite the external demand for evaluation, staff and practitioners believed it had a number of internal benefits. For instance, several of the practitioners were only employed for one session a week, yet many participants attended Artspace activities on multiple days. Keeping records in sessions was seen as a way by which Artspace could offer a more coherent and effective service to its participants. For instance, noting down any concerns about a particular participant would enable appropriate attention by other practitioners in later sessions. In this case, monitoring supported Artspace’s commitment to ensuring that its participants remain at the forefront of their practice: “…I think it’s also essential that we do that [monitor participant progress] so that as practitioners we work out whether or not the people that we’re being paid to serve are benefiting from what we’re doing…” (Interview with Jennifer (practitioner), 5/4/11) Evaluation was also deemed to be “healthy” and necessary in that it allowed people’s progression to be monitored, thus maximising the ways in which each person could best benefit from attending activities. Evaluation was thus a way in which Artspace could continue to maintain its ethos as an organisation which is primarily focused on the needs of the individual. It was considered important that the participants themselves could keep track of their progress and personal development over time. Artspace now, as a matter of course, ask all new participants a number of questions about where they feel they are in 10 life. It was felt that asking the same questions six months later would allow them to see if they had benefited from attending any Artspace activities. Artspace occasionally runs reflective practice meetings, where practitioners meet to evaluate their experiences, share good practice and learn from one another. These were valued as it allowed the practitioners to discuss what occurred within the sessions, rather than the information “just being written down and then filed.” Staff felt that such sessions were beneficial for both participants and practitioners alike. Challenges of Evaluation Despite welcoming some of the benefits of evaluation, Artspace staff also explicitly discussed the challenges involved in the monitoring and evaluation of their activities. These fell into four groups of concern about quantified monitoring: technical and logistical challenges, the risk of disruption to working practices, damaging or unethical practices in the context of some of the clients’ health issues, and the inappropriateness of measurement in capturing the benefits of arts-based practice. Implementing an effective system of monitoring would require a substantial investment of time and effort. In the past, staff acknowledged that evaluation was done in a somewhat ad hoc manner as best they could with the resources and time available. While it was expected that the amount of time spent on evaluation would almost certainly have to increase in future, staff felt that they were already working at full capacity and that that any increase in their workload would be difficult to manage. Positioning evaluation explicitly as an integral part of the practice was seen as a possible solution: “…it always seems a bit weird to have it kind of tacked on to the end of the group when nobody’s actually interested at all in filling the form in, and some people can’t, so I think finding a way of making it integral to the practice is the answer, if possible.” (Interview with Jennifer (practitioner), 5/4/11) Secondly, however, staff also feared that filling in evaluation forms during the session could detract from the essential, valuable personal contact between artists and participants. A central tenet of Artspace’s working ethos is that it is imperative that the organisation is capable of responding to participants in a professional and caring manner with “a big heart and open arms.” As Artspace works closely with people who are unwell or have particular needs, it was felt that practitioners needed to be aware of the situation 11 within the sessions at all times. Completing paperwork during the sessions was seen as potentially “taking your eye off the ball.” The possibility that the ethos of the organisation could be seriously compromised by increased monitoring or evaluation was a view quite widely held. Many felt that the organisation already spent too much time completing paperwork instead of interacting with participants. As a result, evaluation was seen in negative terms, being described as “boring”, a “burden” or something which the organisation “needs” to do. The negativity was largely levelled at the quantitative aspects of evaluation, although one staff member felt that even the reflective practice sessions failed to generate new insights or topics for discussion. Thirdly, staff and practitioners identified various instances where conducting evaluation would have been inappropriate and damaging. For instance, new participants may have made a brave step beyond their comfort zone to attend an Artspace activity, and asking them a suite of personal or complex questions in an early session may have deterred them from returning in future: “…it’s a fine line between catching somebody in their early stages of engagement with us…to not wanting to put them off coming…” (Interview with Yvonne (core staff), 4/5/11) Since the staff at Artspace were aware of the potential for alienation from data collection, they have devised strategies to minimise the risks. For example, they conducted interviews informally in a quiet corner of the main art room rather than within the more formal space of an enclosed office. Nonetheless, for some groups of people and for some types of Artspace activities, staff decided that conducting evaluation was unsuitable. Asking people complicated or intrusive questions was inappropriate at those events attended by a large number of children and families. Some participants had specific difficulties communicating their thoughts and feelings effectively, and staff did not want to make people anxious by asking them to do so. “…I think it is important that we find ways of evaluating that suit the participants, for example, there are some people that I work with who can’t write, they can’t fill in a form.” (Interview with Jennifer (practitioner), 5/4/11) Lastly, staff challenged the relevance and ability of many outcomes monitoring tools to capture ‘softer’ benefits such as self esteem. Staff believed that some of the things at 12 which they succeeded, such as increasing people’s confidence and widening their social networks, were hugely important to people’s wellbeing. However, many of these benefits were considered to be difficult to measure. Moreover, these benefits were neither evident nor measurable over short time periods. Staff who had worked at Artspace for some years recalled how Artspace had been structured by the demands of funders in the past in a way which challenged its participant-centred focus. This included pressure on the organisation to show evidence of its benefits within a comparatively short period of time: “…it’s normally the funders that are asking the questions, and like I say they’ll always put a timescale on it, and not always our outcomes are within that timescale, our outcomes are definitely there, but might not be achieved within that actual timescale…” (Interview with Steph (practitioner), 12/4/11) Many of Artspace’s activities were not time limited and participation may continue throughout the year. While participation might benefit some people in the short term, practitioners and core staff alike felt that real differences could only be observed on a longer term basis, for example, over a period of six months or more. Negotiating Evaluation Given the concerns expressed by staff and practitioners of the challenges, risks and appropriateness of implementing a quantified monitoring approach to evaluation at Artspace, staff were actively exploring organisational and practice-relevant approaches which they felt will meet the needs of staff, clients and external funders. Two of these approaches aimed to realise the perceived benefits of monitoring and evaluation for the organisation’s own working practices. These concern a streamlining of the responsibility for on-going monitoring away from the majority of practitioners, and exploring alternative forms of evidence that enable less communicative participants to be included. Artspace was also taking a pro-active approach to negotiating with funders about the terms on which evaluation might be based. In particular, Artspace staff had been developing their own outcomes measurement tool relevant to the needs of their participants. This was based on their understanding of the benefits which engagement in the arts may bring, with the acknowledgement that some participants may take considerably longer than others to benefit from their intervention. Staff predicted that the demand for increased evaluation will result in practitioners and staff spending more time setting particular goals with participants and monitoring their progress towards these goals. Given workloads were already stretched, the organisation was 13 following a staff-led suggestion to allocate the majority of the evaluation work to a specific, specialised member of staff. The staffing structure included a facilitator who worked with new attendees and it was this position that could potentially be expanded to cover all participants. This was not a wholly new idea; Artspace had previously applied unsuccessfully for funding for a pathway worker to support people throughout their time with the organisation. The staff at Artspace were also experimenting with alternative methods to quantified indicators through which to establish a simple way of recording the outcomes of the various activities undertaken. These included visual methods of recording such as taking photographs as well as noting informally made comments from participants. These alternative methods will not only serve to illustrate the work of Artspace in terms of what it delivers, but also enable the organisation to capture how its activities benefit those who may have difficulty communicating or expressing their feelings. The Artspace team considered themselves to be “skilled at producing meaningful findings from informal methods”, such as using the artwork produced by participants as evidence that they had achieved specific outcomes. However, while meaningful ‘informal’ methods may support the internal benefits of evaluation to the organisation, they are limited if external funders still require evidence based on quantified monitoring. Significantly, Artspace had succeeded in negotiating with certain funders on some of its outcomes and the nature of acceptable evidence. For examples, the funder ‘Big Lottery’ did not initially accept the inclusion of attendees at workshops for a community lanterns event in the annual total number of beneficiaries. However, Big Lottery changed its position after Artspace produced a number of positive quotes from attendees at the workshops. Big Lottery also stipulated that Artspace should conduct a wellbeing action plan with all lantern workshop participants, a process which Artspace considered inappropriate given that attendees were largely children and families. Through negotiation, Big Lottery was persuaded that the activity was beneficial through the use of a brief, informal questionnaire that was not too intrusive. Artspace was also proactive in negotiating with funders around the terms of evaluation through investment in developing its own outcomes monitoring tool that was specific to its own work. A core member of staff at Artspace, Susan, has the job of developing such a tool. Existing outcomes monitoring tools were unsuitable for Artspace’s work in several 14 ways: they did not take the complexity of particular situations into account such as the way in which apparently insignificant decisions can have huge impacts later; they mostly focus on individual change and cannot take into account the importance of networks, relationships or community; and they give insufficient recognition to so-called softer outcomes: “…people are doing creative things all the time, and creative things benefit your wellbeing, but it’s, for some reason isn’t allowed to be recognised, people don’t count it…” (Interview with Susan (core staff), 17/11/10) The holistic ethos of Artspace was based on providing a warm welcome and a “congenial space” for participants; these are attributes which may be difficult to capture using existing outcomes tools. Artspace also considered creative engagement to be an important aspect of the organisation. The development of a new tool aimed to take these benefits into account. Moreover, a new monitoring tool that captures Artspace’s own understanding of the benefits they provide could be used to standardise the way they report back to their stakeholders: “…what we need to try and do is make sure that we’ve got a system that’s suitable for both so that we’re not having to sort of count it one way for one funding organisation and another way for another cos the burden of monitoring is quite a lot really, and if you’ve got to do it sort of three or four times in three or four different ways it’s a pain in the neck.” (Interview with Yvonne (core staff), 21/7/10) In line with the concerns of other staff at Artspace, Susan believed existing monitoring tools were unsuitable for their work. Such tools often involved an initial conversation between participants and practitioners, where practitioners aimed to find out prescribed information within a specific period of time. The often ‘institutional’ focus of such conversations conflicts with the working ethos of Artspace, which aimed for genuine contact based on a relationship of trust without being overly intrusive or complicated. Susan similarly reflected Artspace’s critique of the way progress is conceptualised and measured through existing monitoring tools. Artspace viewed participant progress as non-hierarchical in which each so-called stage in a participant’s wellbeing pathway was neither more nor less significant than any other. Susan aimed to involve participants in the development and trialling of the model which, in keeping with the ethos of the organisation, enabled participants to select the particular outcomes which they want to aim for, rather than such aims being imposed from outside. As well as fitting with Artspace’s unique 15 ethos, the new outcomes tool could be a resource for other arts and health organisations and from which Artspace could generate further income. Nonetheless, even with the mobilisation of the new, more flexible monitoring tool, it was felt that much of Artspace’s work would likely remain under-recognised by potential funders and other stakeholders: “…it will probably always remain something of a problem, working in a what is often a somewhat too rigid, rational environment where you’re using a medium or media which are working in lateral ways to stimulate change in people…” (Interview with Scott (core staff), 10/2/11) Truly understanding the benefits which Artspace brought to the community may only occur through first-hand experience of the organisation’s atmosphere. Susan recalled the occasion when she found it almost impossible to explain the nature of the organisation to a key stakeholder but mentioned that “the minute he walked in the door he got it.” Discussion and Conclusion The paper set out to explore the relationships between the working ethos of arts and health organisations with the demands for quantified monitoring and evaluation. The case study of Artspace highlighted a range of ways in which the organisation and its staff engaged with this growing demand, embracing some aspects, recognising a number of tensions with the organisation’s ethos of working and actively negotiating the terms through which monitoring and evaluation may be legitimate. Although this was a UK based study, the findings have implications for third sector organisations elsewhere who may feel they have to increasingly negotiate with public funders in response to the influences of neoliberal discourse. Practitioners regarded evaluation as being time consuming and potentially detrimental to the way they operate, a view held by practitioners in other arts and health organisations. Angus (2002) found that while many practitioners recognise that evaluation is necessary, they also felt that its main purpose is to satisfy funders. Practitioners were often the most sceptical about the process of evaluation, believing it to be constraining in nature (Smith, 2003). Despite acknowledging that quantitative monitoring was by and large a pervasive discourse in contemporary society, and that implementing this kind of evaluation poses a number of challenges, Artspace staff accepted that it could bring positive benefits. These benefits were both external in that it could help them prove their worth to funders and other 16 stakeholders, and also internal in that they saw it as helping them to improve their practice and be more aware of participants’ needs. However, deeper discussion with Artspace staff revealed that their acceptance of these internal benefits did not necessarily correspond to an acceptance of the external climate of quantified monitoring. Whilst claiming to recognise that this form of evaluation was both beneficial and necessary, in practice the organisation had some serious reservations about the practicality, ethics and appropriateness of these approaches. One of the major concerns was that the organisation’s ethos could be significantly compromised by demands for evaluation. A challenge for many arts in health organisations, and indeed third sector organisations as a whole, was that the demands for evaluation may reshape the structures, procedures and the working practices of the organisation in line with those of the funder, a process known as ‘institutional isomorphism’ (DiMaggio & Powell, 1983). Focussing on measurable benefits may mean that softer, less quantifiable outcomes were ignored or sidelined (Amin, Cameron, & Hudson, 2002), leading to the organisation operating in ways distinct from its original ethos (Carmel & Harlock, 2008). Organisations may also focus more upon their accountability to funders and less on those they seek to benefit (Laratta, 2009). The scope or direction of community arts projects may be influenced by requirements for evaluation (Angus, 2002), with the art being seen as ‘merely instrumental to prescribed social outcomes and public policy agendas’ (Putland, 2008: 266). Staff and practitioners at Artspace described similar experiences in this direction through the influence of social services, who determined the structure of their week and the terminology that was used. While it was felt that this form of influence may become stronger with moves towards personalisation, GP commissioning and outcomes based contracts, Artspace was fully aware of this potential threat to their ethos and are exploring strategies to mitigate this. One such strategy involved negotiation with funders. Artspace have successfully negotiated with the Big Lottery around their outcomes and the evidence they are expected to provide. While this may seem like a major achievement by Artspace, it could be argued that the aims of the Big Lottery Well-being programme were not far removed from Artspace’s ethos. For instance, Big Lottery viewed wellbeing in a similar, holistic way, being concerned with good mental health, social networks and social capital, and not just 17 with an absence of disease (Abdallah, Steuer, Marks, & Page, 2008). It remains to be seen whether Artspace can negotiate in such a way around outcomes with the statutory sector, whose practices may be considerably more rigid and uncompromising in nature (Warner et al., 1998). Experimentation with alternative forms of evaluation was another strategy utilised by Artspace. Recognising that particular funders may always require numerical evidence of participant progress, Artspace was developing its own outcomes monitoring tool. It was felt that this would satisfy stakeholders who require numerical evidence of progression, while at the same time enabling the organisation to track the ‘softer’ outcomes which they felt were just as important. Again, however, it remains to be seen whether such an approach will meet the needs of Artspace’s funders. Angus (2002) argues that evaluatory methods which satisfy an arts funder may not necessarily satisfy one from the statutory sector. There is also the possibility that any evidence, no matter how rigorously it has been obtained, may be discounted by those who disagree with the findings or happen to have their own specific agendas (Matarasso, 1997; Mitchell, 1999). Nevertheless, Artspace appears to have made considerable headway in its relationship with the statutory sector. Its board of trustees includes several people who either work or have worked in the statutory sector, and Artspace has succeeded in obtaining a monthly slot at the local surgery where the facilitator will meet with potential new participants and signpost them onto various Artspace activities. This was seen as being hugely important, and was referred to one staff member as being social prescribing “in through the back door.” The strategies adopted by Artspace were seen to challenge and negotiate the terms of evaluation with funders. While these strategies did not involve a complete resistance to imposed practices from external funders, neither do they involve full or uncritical compliance. Artspace’s attempts to negotiate with funders is an intentional way in which it is reworking the structures imposed from outside the organisation into processes it feels it can work with, thus enabling it to maintain its overall ethos. 18 Acknowledgements Many thanks to all the staff at Artspace for their support over the year, and to the core staff and practitioners who gave up their time to be interviewed. The project is funded through an ESRC CASE studentship held at Durham University. References Abdallah, S., Steuer, N., Marks, N., & Page, N. (2008). Well-Being Evaluation Tools: A Research and Development Project for the Big Lottery Fund. London: nef. Available from http://www.biglotteryfund.org.uk/wellbeing_evaluation_tools.pdf (accessed May 2011). Amin, A., Cameron, A., & Hudson, R. (2002). Placing the Social Economy. Routledge: London. Angus, J. (2002). A review of evaluation in community based art for health activity in the UK, London: CAHHM/HDA. Arts Council, (2007). A prospectus for arts and health, Department of Health with Arts Council England. Atkinson, S. & Joyce, K.E. (2011) The place and practice of wellbeing in local governance. Environment and Planning C: Government and Policy, 29(1), 133-148. Borzaga, C. & Defourny, J. (eds) (2001) The Emergence of Social Enterprise, Routledge: London. Bridge, S., Murtagh, B., & O’Neill, K. (2009). Understanding the social economy and the third sector, Basingstoke: Palgrave Macmillan. Bryman, A. (2008). Social Research Methods, Oxford: Oxford University Press. 19 Buckingham, H. (2009). Competition and contracts in the voluntary sector: exploring the implications for homelessness service providers in Southampton. Policy and Politics, 37(2), 235–254. Burton, A. (2009). Bringing arts-based therapies in from the scientific cold. Lancet Neurology, 8(9), 784–785. Carmel, E., & Harlock, J. (2008). Instituting the ‘third sector’ as a governable terrain: partnership, procurement and performance in the UK, Policy & Politics, 36(2), 155–71. DiMaggio, P., & Powell, W. (1983). The Iron Cage Revisited: Institutional Isomorphism and Collective Rationality in Organizational Fields, American Sociological Review, 48(2), 147–160. Dooris, M. (2005). A Qualitative Review of the Walsall Arts into Health Partnership. Health Education, 105(5), 355–373. Department of Trade and Industry (DTI). (2002). Social Enterprise: A Strategy for Success, London: DTI. Emerson, J., & Twersky, F. (Eds.) (1996). New social entrepreneurs: The success, challenge, and lessons of non-profit enterprise creation. San Francisco: The Roberts Foundation. Hacking, S., Secker, J., Kent, L., Shenton, J., & Spandler, H. (2006). Mental health and arts participation: the state of the art in England. Journal of the Royal Society of Health Promotion, 126(3), 121–127. Health Development Agency (HDA). (2000). Arts for health: A review of good practice in community-based arts projects and interventions which impact on health and wellbeing. London: Health Development Agency. Ilcan, S., & Basok, T. (2004). “Community Government: Voluntary Agencies, Social Justice, and the Responsibilization of Citizens.” Citizenship Studies, 8(2), 129–144. 20 Jermyn, H. (2004). The art of inclusion. London: Arts Council England. Jermyn, H. (2001). The arts and social exclusion: A review prepared for the Arts Council of England. London: Arts Council England. Laratta, R. (2009). Autonomy and accountability in social services nonprofits: Japan and UK, Social Enterprise Journal, 5(3), 259–281. Larner, W., & Butler, M. (2005). Governmentalities of Local Partnerships: The rise of a ‘partnering state’ in New Zealand. Studies in Political Economy 75, 85–108. Lawthom, R., Sixsmith, J., & Kagan, C. (2007). Interrogating Power: The case of arts and mental health in community Projects. Journal of Community and Applied Social Psychology, 17(4), 268–279. Matarasso, F. (1997). Use or ornament? The social impact of participation in the Arts. Stroud: Comedia. MBC Sefton (2009). Arts on Prescription in Sefton. Programme Report, December 2009. Available from http://www.artsforhealth.org/resources/CA%20Report%202009.pdf [Accessed July 2010] Milbourne, L. (2009). Remodelling the third sector: advancing collaboration or competition in community based initiatives? Journal of Social Policy, 38(2), 277–297. Miller, P. & Rose, N. (2008). Governing the Present. Polity Press: London. Mitchell, J. (1999). Evidence-based practice: Critique and alternative view. Nursing Science Quarterly, 12, 30–35. Morison, J. (2000). The Government-Voluntary Sector Compacts: Governance, Governmentality, and Civil Society. Journal of Law and Society, 27(1), 98–132. Nutbeam, D. (1998). Evaluating health promotion- progress, problems and solutions. Health Promotion International, 13(1), 27–44. 21 Putland, C. (2008). Lost in Translation: The question of evidence linking Community based Arts and Health promotion. Journal of Health Psychology, 13, 265–276. Secker, J., Hacking, S,. Spandler, H., Kent, L., & Shenton, J. (2007). Mental health, social inclusion and arts: developing the evidence base. National Social Inclusion Programme, Care Services Improvement Partnership, London. Available from http://www.socialinclusion.org.uk/publications/MHSIArts.pdf (accessed March 2011). Smith, T. (2003). An evaluation of sorts – learning from Common Knowledge. CAHHM, University of Durham. Staricoff, R. (2006). Arts in health: the value of evaluation. The Journal of the Royal Society for the Promotion of Health, 126(3), 116–120. Thomson, H., Hoskins, R., Petticrew, M., Ogilvie, D., Craig, N., Quinn, T. & Lindsay, G. (2004). Evaluating the health effects of social interventions. British Medical Journal, 328 282-285. Warner, L., Ford, R., Bagnell, S., Morgan, S., McDaid, C., & Mawhinney, S. (1998). Down your street: models of extended community support services for people with mental health problems. London. Sainsbury Centre for Mental Health. Available from www.centreformentalhealth.org.uk/pdfs/down_your_street.pdf (accessed June 2011). White, M., & Angus, J. (2003). Arts and Adult Mental Health Literature Review. CAHHM, University of Durham. Yin, R.K. (2009) Case study research: design and methods. Sage: London. 
ABSTRACT: 
Although a relatively minor project in terms of its impact on the broader international language movement, Basic English is interesting for the elaborate semiotic theory that lies behind it. The creator of Basic, Charles Kay Ogden (1889–1957), is today remembered chiefly as co-author of The Meaning of Meaning, a book widely regarded as a classic of early twentieth-century semiotics. In this paper, we engage in a critical examination of the design of Basic and demonstrate how it essentially represents an implementation of the key doctrines set out in that book, tempered by the practical exigencies of language construction. We focus on Ogden’s method of ‘panoptic conjugation’, which he used to select the Basic core vocabulary of 850 words, as well as his conception of the grammar of Basic as an outgrowth of its vocabulary. We observe additionally how Ogden’s approach does not result in a self-contained, independent international language, but rather a language that is subservient to Standard English idiom. 
 
PREDICTION: 
we analyse the relationship between language and perception in relation to the interpretation of language .<n> we prove that a language s perception of a medium is determined by its perception of its language .<n> we show that the perception of a medium is determined by its ability to express a point of view in a language .<n> in particular , we show that the perception of a medium is determined by its ability to express a point of view in a language .<n> we demonstrate this by examining the different ways in which a point of view can be represented in a language .<n> we show that a point of view can be represented in a language by a point of view in a particular language .<n> we examine the different ways in which a point of view can be represented in a language by a point of view in a particular language .<n> we demonstrate this by examining the different ways in which a point of view can be represented in a language by a point of view in a particular language .<n> we examine the different ways in which a point of view can be represented in a language by a point of view in a particular language .<n> we show that the different ways in which a point of view can be represented in a language by a point of view 
 
FULL TEXT: 
 1. IntroductionAlthough a relatively minor project in terms of its impact on the broader international language movement, Basic English is interesting for the elaborate semiotic theory that lies behind it. The creator of Basic, Charles Kay Ogden (1889–1957), is today remembered chiefly as co-author – along with the literary critic Ivor Armstrong Richards (1893–1979) – of The Meaning of Meaning (Ogden and Richards 1989[1923]), a book widely regarded as a classic of early twentieth-century semiotics.1 In this paper, we critically examine the design of Basic and demonstrate how it 1 There are ten editions of The Meaning of Meaning published in Ogden and Richards’ lifetime, the first from 1923 and the last from 1949. The first edition is significantly longer than all subsequent editions: in particular, chapter 2 in the first edition was cut down in the second edition. The revisions made from the second to the tenth edition are all minor (see Gordon 1990:67-68). The discussion in this paper is based on a 1989 reprinting of the 1949 edition, 1essentially represents an implementation of the key doctrines set out in The Meaning of Meaning, tempered by the practical exigencies of constructing a usable language.2The overarching problem that animates The Meaning of Meaning is ‘word-magic’, a term Ogden and Richards use to describe a superstitious awe of the power of words which clouds our understanding and interferes with proper communication (see chapter 2 of Ogden and Richards 1989[1923], in particular pp.44-45). The ‘science of symbolism’, as Ogden and Richards call their semiotic theory throughout the book, is intended to awaken our awareness of the true nature of language and offer guidelines for its proper use. In section 2 we sketch the key parts of this semiotictheory and the ‘method of definition’ emerging from it, which is intended to make meanings explicitand thereby overcome word-magic.The solution to ‘the problem of a Universal language’, asserted Ogden (1929a:1), lies in shrinking the entire language down to ‘no more than can be made easily legible to the naked eye, in column form, on the back of a sheet of notepaper.’ His ideal was a ‘panoptic’ language, a language ‘seen at a glance’.3 The heart of Basic was its ‘core vocabulary’, a list of 850 words ‘scientifically selected’ using the method of ‘panoptic conjugation’.4 This approach would not only reduce the amount of material the learner had to assimilate, but would also reduce the vocabulary down to a core of the most necessary and reliable words, forcing the speakers of the language to spell out whatthey mean in terms of these words. In section 3 we examine panoptic conjugation in detail and showhow it is in fact an applied form of the method of definition familiar from The Meaning of Meaning.In Ogden’s view, an escape from word-magic and ease of learning were not the only benefits of vocabulary reduction; a restricted vocabulary would also solve all other difficulties that concern language constructors: grammar, pronunciation, orthography, meaning and idiom. Whereas most other language constructors involved in the international language movement concerned themselvesin equal measure with grammar and vocabulary, Ogden saw the vocabulary alone as the key to the problem. For Ogden, words make the language, and the correct selection of words would determine all other aspects of a language’s design. Ogden’s belief that only the right vocabulary would result in ‘grammatical reform’ is examined in section 4.which represents the book in the final state that Ogden and Richards left it. There are various in-depth critiques of the theory of meaning presented in The Meaning of Meaning. Some of the most significant of these are collected in volume 5 of Gordon (1994). See also Hotopf (1965:10-32) and chapter 7 of Russo (1989). Gordon (2006) presents acomprehensive, up-to-date, and very compact assessment of The Meaning of Meaning and its subsequent influence in linguistics and semiotics.2 The examination of Basic conducted in this paper is based chiefly on Ogden’s original descriptions of the project from the late 1920s and early 1930s, which appeared mostly as editorials and articles in Psyche magazine, and as short monographs published by Kegan Paul. Ogden (1968) is a posthumous edited compilation of Ogden’s key writings on Basic that provides a concise overview of the project.3 The term ‘panoptic’ is of course drawn from the work of the English Utilitarian philosopher Jeremy Bentham (1748–1832). One of Bentham’s most well-known projects was the ‘Panopticon’, a design for an ideal prison based around creating the impression of unrelenting surveillance (see Bentham 1843[1791]). Around the same time Ogden began promoting Basic, he was also building up a reputation as a Bentham scholar, publishing expositions ofBentham’s ideas and critical editions of his works. Ogden in fact attributed many of the insights leading to Basic directly to Bentham (see, e.g., Ogden 1932d; 1993[1932]). 4 Ogden frequently repeated the claim that the Basic vocabulary was ‘scientifically selected’; he probably first mentioned it in Ogden (1929a:1), which is repeated word-for-word in Ogden (1933[1930]:1).22. Ogden’s semiotics‘We ought to regard communication as a difficult matter,’ write Ogden and Richards (1989[1923]:123), ‘and close correspondence of reference for different thinkers as a comparatively rare event.’ A central objective of The Meaning of Meaning is to explain how this difficulty arises, and to offer a remedy for it. To this end, Ogden and Richards present a model of how reference is achieved in language. At the highest level, the model recognises that reference is just one of the many functions language performs; it is the task of the ‘symbolic’ function, which is contrasted to the ‘emotive’ functions, a collection of what would now be considered various pragmatic and attitudinal aspects of meaning.5 Reference comes about when a ‘symbol’, a word or any other type of sign, evokes a ‘thought or reference’, an idea in the mind of the hearer or perceiver of the sign,6 which is then directed to a ‘referent’, some entity or object in the world. Ogden and Richards summarise this account in the ‘Triangle of Reference’ diagram, reproduced in Figure 1 below.7Figure 1. The Triangle of Reference (Ogden and Richards 1989[1923]:11)5 The symbolic function is clearly the most important of the functions outlined by Ogden and Richards (1989[1923]):while the emotive functions do receive some exposition (mainly in chapter 10 of ibid.), the symbolic function is introduced first and is the only one to be treated comprehensively. The symbolic function is the key to the ‘reflective, intellectual use of language’ (ibid.:10; cf. p.233), the characteristic mode of modern discourse. Functional models of language like that presented in The Meaning of Meaning were a commonplace at this time. Nerlich (1992) provides a detailed examination of this historical background.6 Ogden and Richards (1989[1923]) elaborate on the psychological aspects of their theory chiefly in chapter 3 .7 Three-term accounts of reference of the sort Ogden and Richards offer have a long tradition in western thought, extending back at least as far as Aristotle (384-322 B.C.; see McElvenny 2014:213-214).3Word-magic arises, argue Ogden and Richards, when the imputed relation between the symbol and referent, represented by the base of the triangle, is assumed to be a direct relationship between a symbol and its referent, whereas in fact every reference must first pass through the intermediate stage of the ‘thought or reference’ (Ogden and Richards 1989[1923]:9-12). The remedy is to ‘expand’ the symbol so that it reflects its ‘thought or reference’ most clearly; this is the aim of the ‘method of definition’, a form of paraphrase (outlined in chapter 6 of ibid.). A successful definition sets out from a secure starting point shared by speaker and hearer and follows a clearly signposted route of definition to reach the reference: ‘It is never safe to assume that it [correspondence of reference for different thinkers] has been secured unless both the starting-points and the routes of definition, whereby the referent of at least a majority of the symbols employed have been reached, are known’ (ibid.:123).8 The starting points should ideally be objects of everyday phenomenal experience; they should be ‘things, that is, which we can point to or experience’ (ibid.:115).9Basic English, as we will see in the following section, is essentially a guided implementation of this method. The 850 words of the Basic core vocabulary are both the product of this definitional procedure and the raw material for formulating expressions according to its principles. The genetic relationship between these two projects was acknowledged by Richards in his later reminiscences:The chapter on Definition in “The Beadig of Beadig”, as we came to call it in memory of a frustrating cold in the head, led us into long discussions of the number of radically different ways there may be of telling anyone what any word may mean. This inquiry was the germ of Basic English. Ogden had long been deep in the history and theory of universal languages, and it was no long step from our account of Definition to notions of a minimal English capable of serving all purposes. (Richards 1977:108; see also Brower 1973:34 and Richards 1943:xliii, 22-23)3. Panoptic conjugationThe Basic core vocabulary was arrived at by selecting words from the vocabulary of Standard English using ‘panoptic conjugation’, a technique derived from the method of definition, designed to reveal the semantic relations between words. Under panoptic conjugation, the semantic ‘conjugates’, as Ogden put it, for a central ‘root word’ can be discovered by following various ‘radial definition routes’; that is, semantic dimensions along which the conjugates differ from the root word. This is ‘conjugation’ because Ogden imagined these words forming a semantic paradigm– like the inflectional paradigm, or conjugation, of a verb – where each of the peripheral words is derived from the root word. He described the procedure in the following terms (see also Ogden 1930:9-17; Lockhart 1931:73-75): 8 The method of definition in turn rests on the ‘canons of symbolism’, six rules of semiotic hygiene that ‘allow us to perform with safety those transformations and substitutions of symbols by which scientific language endeavours to reflect and record its distinctions and conclusions’ (Ogden and Richards 1989[1923]:108). These rules essentially stipulate that equivalent symbols can be substituted and still pick out the same referent (thus making definition possible), and that there should be no ambiguity in the relation of a symbol to its referent (see ibid.:88-106; cf. Gordon 1991:167).9 Paraphrase as a technique for clarifying expressions was a feature of other theories of meaning in Ogden’s immediate intellectual environment, most notably the theory of descriptions of Bertrand Russell (1872–1970) and the significs of Victoria Lady Welby (1837–1912). See McElvenny (2014) for discussion of this context.4To conjugate a verb is to put it through its tricks. Conjugates, in another connexion, are words related to the same root. If we apply the terms to words in general so that any word can have its conjugation and conjugates, it will be convenient to exhibit these so that they can be appreciated at a glance – panoptically. The most convenient panoptic method is to place the word under consideration at the centre of a circle, whose radii canthen represent the directions in which the conjugates may be sought. For example, in thecase of ‘House’, cottage, bungalow, hotel, sanatorium, palace, hut, hovel, home, city, room, chimney, etc. (Ogden 1928:2)The ‘panoptic’ overview of the procedure comes out in the diagram reproduced in Figure 2 below. Here the root word is surrounded by its conjugates, each connected along one of the twenty radial definition routes – clearly the definition routes of The Meaning of Meaning catalogued and enumerated – or one of the additional operations of metaphor, opposition and derivation (cf. Gordon1991:168).Figure 1. Panoptic Conjugation (Ogden 1930:12)5The semantic roots discovered through panoptic conjugation become the words adopted into the Basic core vocabulary, while their peripheral conjugates are eliminated, a procedure Ogden (1930:14) codified in his ‘elimination formula’: ‘Given the word at the centre [of the panoptic conjugation diagram], and the means of covering the radial definition route in not more than nine words, then the conjugate at the periphery can be eliminated.’ The eliminated words are replaced byparaphrases based on the root word and the radial definition route: ‘Southerner’ becomes ‘a man from the South’; ‘dwarf’, ‘a man much smaller than normal size’, and so on. The paraphrases are enshrined in the Basic dictionary as ‘dictionary clichés’, the standard translation of the eliminated words into Basic (see Ogden 1929b:20; Ogden 1930:14; Ogden 1932c is the actual Basic dictionary).We may ask from what point we should set out along these radial definition routes. From The Meaning of Meaning we have the dictum that the starting points should be things that ‘we can point to or experience’ (see section 2 above), a position that is reiterated in relation to Basic by Ogden’s assistant Leonora Wilhelmina Lockhart (1906-1987). In her theory of ‘Word Economy’ (Lockhart 1928; 1931) – endorsed by Ogden as a contribution to the theory behind Basic (see his preface to Lockhardt 1931:7-8) – she comments: ‘If language is to consult human convenience – and being a tool fashioned by the human mind for its own purposes, this can scarcely be denied – it should symbolize objects, as far as possible, at the level of our perceptions. Facts that cannot be inferred directly from contact with the object should not be covered by the unit symbols’ (Lockhart 1931:60;cf. Walpole 1937 and Myers 1938). The Basic core vocabulary should therefore be words that refer to things at the level of everyday human phenomenal experience.If we now turn to the examine the actual words selected for the Basic vocabulary through panoptic conjugation, we very quickly see the theoretical neatness of Ogden’s semiotics give way topractical expedience and unarticulated intuitions. The twenty radial definition routes, for instance, are never described rigorously; we have to divine them from the examples Ogden provides. In his ‘elimination formula’ Ogden rejects paraphrases that are more than nine words long or otherwise ‘awkward’, preferring in these cases to retain the original word. But a limit of nine words may seemsomewhat arbitrary, and it is never explained how we might assess ‘awkwardness’. Peripheral words are also granted a reprieve from elimination if they help avoid homophony, are very frequent,or are useful in forming derivatives and metaphors (Ogden 1929a:5; 1930:14). Determination and elimination of homophony can be performed mechanically, but this principle clearly has subordinate status in forming the core vocabulary: I and eye are both among the 850. Word frequency similarly requires no special talent – it is simply a matter of counting – but Ogden was highly critical of learning vocabularies based on word frequency, of which there were many compiled at the time, commenting (Ogden 1929b:9): ‘[T]he real statistical task of linguistic [sic] is not so much the determination of the number of words actually used by any particular person or class of persons as the study of how a reduction may be effected in the number of words which needbe used; i.e. how a given field of reference may be covered with the greatest economy.’ He closed by reiterating: ‘What is really required is a scientifically selected vocabulary minimum’ (see also Ogden 1929b:6-9; Walpole 1937; Myers 1938:55-70). But under close examination, Ogden’s ‘scientific’ method takes on the character of an art, dependent on judgements that find no explicit 6expression.The possibilities of derivation and metaphor did receive detailed elaboration from Ogden, but at the same time they reveal Basic’s subservience to Standard English and the problematic status of hisclaim of 850 words: we see that the core vocabulary in fact consists of 850 word forms that are generally polysemous and whose formal and semantic scope is bound by Standard English idiom. Interms of derivation, only words that would be idiomatic in Standard English can be created with the agentive suffix -er/-or (with the choice between -er and -or dictated by the corresponding word in Standard English), the gerund and present participle suffix -ing, and the past participle suffix -ed (see Ogden 1933[1930]:47-50). Compounding involves further difficulties: permissible compounds are not only restricted by English idiom, but their senses are often ‘different from what would be thenormal suggestion of the parts’, as in the cases of ‘become (= come to be)’ and ‘outcome (= what comes out)’ (Ogden 1932a:54-56). In the processes of ‘extension’ and ‘specialization’, the possibility of consistency between form and meaning is abandoned as Basic core words take on additional senses without any change in form (Ogden 1933[1930]:45-46). Extension proceeds through metaphor, such as when letter, which in its simplest sense is taken to be a letter of the alphabet, becomes letter, an epistle, or lift the action becomes lift, an elevator. In specialisation a word takes on a more specific sense than it prototypically has, such as when judge refers specifically to a judge at law rather than a judge of any other sort. In addition, some words can be used as different parts of speech without any formal marking: for example, the noun back can become an adverb and the adjective round can become a preposition (Ogden 1933[1930]:47). Thesevarious nuances and additional senses inherited from the standard language are catalogued in The Basic Words: a detailed account of their uses (Ogden 1932b) which, at 101 pages, is far from the panoptic ideal.The claim to 850 words suffers further when it is revealed that Basic can, as the need arises, take on ‘special vocabularies’ consisting of personal and place names, trade terms, ‘localized names’, slang, ‘measuring terms’ (numbers and units of measure), and scientific words (technical terms). It is thus legitimate to say in Basic, ‘He went to London in his Ford’ (i.e. Ford-brand automobile; Ogden 1929b:12), where London and Ford qualify as supernumerary Basic words because they are a place name and a trade name respectively. ‘He went to “Town” in his “bus,”’ is equally legitimate:Town is a ‘localized name’ and bus a slang term (Ogden 1929b:12). But there is an unacknowledgedcontinuum of acceptability in these ad hoc additions: localised names and slang receive quotation marks from Ogden. In addition, onomatopoeic words are considered ‘universally intelligible without explanation’ and can also be used freely in Basic. This includes such unarguably onomatopoeic expressions as pop and splash, but also cuckoo (the bird species), hiccup (the bodily action) and tom-tom (the drums; Ogden 1929b:14-15). The same provisos attached to the ‘elimination formula’ for selecting core words are operative in special vocabularies: we should prefer, for example, ‘a word like clay, forming fire-clay, china-clay, pipe-clay, etc., [because it] has obvious uses in definition, as have also filtration and distillation, being key-operations in the definition or description of more complicated processes’ (Ogden 1929c:21-22). In his pursuit of lexical minimalism Ogden may have fallen prey to his own ‘word-magic’. He triumphantly cites the figure of ‘850 words’, but behind many of these word forms lurks a tangled 7web of unpredictable and idiomatic additional senses. This problem did not go unnoticed by Basic’scritics. Among them were Michael West (1888–1973; 1944[1939]:152) and Janet Aiken (dates unknown; 1944[1936]:147) – proponents of rival reduced Englishes, the ‘Carnegie vocabulary’ and ‘Little English’ respectively – as well as Morris Swadesh (1909–1967; 1944:204), at the time a student of Edward Sapir’s (1884–1939) engaged in cross-linguistic research for International Auxiliary Language Association, who later went on to develop his own concept of a ‘core vocabulary’ in the form of the ‘Swadesh list’, a list of 100 words thought to be highly resistant to borrowing that could be used for lexicostatistical comparison of languages (see Swadesh 1955; finalversion in Swadesh 1972:283-284). Aiken identified the source of Ogden’s problem in an insufficient appreciation for the underlying structure of the language:The English language is like an iceberg – two-thirds below the surface. Words are what we see on a page. They are indeed necessary, but their importance is on the whole secondary to linguistic construction, pattern, or structure. Words are more easily learnedthan inflections or grammatical rules. The vocabularies which have been devised thus far may be likened to a steeple without a church. What they need most of all is to have asolid underpinning of grammar and construction. If English can be simplified not only in words, but also in these more fundamental respects, then we shall have a result worthy of much praise.(Aiken 1944[1936]:147)But it would seem that Ogden saw the situation precisely reversed: grammatical reform would proceed through the right selection of words.4. Grammatical reformUnlike many other language constructors, who devoted equal effort to fashioning vocabulary and grammar, Ogden saw the grammar of Basic as simply emerging from the behaviour of the core vocabulary items. Whatever grammar exists in Basic is imported clinging to its words. An additional consideration in selecting the Basic core vocabulary is then the grammatical properties ofthe words. Their behaviour should be as simple as possible, and they should embody single, directlyreferential categories that are close to experience (cf. Lockhardt 1931:20-37). This view of grammaras an agglomeration growing out of semiotic activity – as opposed, for instance, to a logical system – is clearly presaged by the treatment of grammar in The Meaning of Meaning (see, in particular, Appendix A of Ogden and Richards 1989[1923]). Standard English – from which the Basic words, and hence also its grammar, are drawn – recommends itself as the basis of a refined and perfected international language, Ogden (1931:28) claimed, since it is already ‘the most adaptable language the world has yet seen’. According to Ogden, English is in the grip of an advanced ‘analytic tendency’, a diachronic move towards a grammar almost totally reliant on syntax and free of complexity and irregularity that frequently lurks in morphology.10 This ‘analytic tendency’ has 10 Ogden would seem to have borrowed the term ‘analytic tendency’ from Sapir (1921), where it is used to refer to thediachronic development observable in Western European languages, especially English, under which inflections and complex conjugations of verbs increasingly disappear and are replaced with syntactic constructions. ‘Analytic’ 8already brought English grammar close to the simple, humanly tractable ideal.The attempt to control Basic grammar through word selection begins with the types of words adopted into the language. The parts of speech that manifest themselves in natural languages, Ogden claimed, are to a large extent simply artefacts of each language’s historical development, anddepart from the original scheme of ‘universal grammar’ based on human perception of the world, which recognises a division into ‘objects’, ‘operations’ and ‘directions’: [T]he level at which ordinary language is effective, is one where the distinctions between ‘entity’, ‘state’, ‘change’, ‘process’, ‘event’, ‘behaviour’ and ‘relation’ are reflected in a threefold symbolic differentiation. From the anthropomorphic standpoint, there are the objects which we wish to talk about, the operations which we perform on them, and the directions in which we operate.(Ogden 1929a:3)Later that same year, he proposed a different threefold scheme involving ‘things’, ‘events’ and ‘qualities’, recognising qualities as ‘mentally differentiated though physically they are inseparable from the objects and happenings which they are said to qualify’ (Ogden under the pseudonym More 1929:31).11 The Basic vocabulary should therefore not be populated by ‘nouns’, ‘verbs’, or ‘pronouns’, but by ‘things’ (corresponding to nouns), ‘qualities’ (adjectives), ‘operators’ (verbs), and ‘directives’ (prepositions; Ogden 1932a:2). These naturalised parts of speech are central to Basic: the first item in Ogden’s (1933[1930]:12) list of the knowledge required to use Basic is ‘the functions of the different parts of speech’. But unfortunately for Ogden’s scheme, there remained several purely grammatical categories that he could not do without: pronouns, conjunctions, adverbsof manner derived from ‘qualities’, and sentence adverbs, such as ‘tomorrow’, ‘together’, and ‘though’. These he subsumed in the Basic word list under the label ‘etc.’Nouns, or ‘things’, are at the heart of the vocabulary since – even if our ontologies advance into the abstract – at base nouns are names of objects in the world. An immediate pedagogic advantage presents itself: a language based on nouns can be taught largely through ‘the pictorial method, and particularly from the pictorial dictionary to which the various Larousse compilations are already pointing the way’ (Ogden 1929c:29).12 Ogden’s emphasis on the visible or otherwise observable carries over into the treatment of adjectives or ‘qualities’. This is especially useful in the case of ‘emotive adjectives’, where it ‘[...] may not be possible to convey all the subtleties of mood and attitude, but the behaviour by which alone they are recognized is usually less elusive’ (Ogden – and its opposite, ‘synthetic’ – are terms common in nineteenth-century schemes of morphological language typology, and were first used in this sense by August Wilhelm Schlegel (1767–1845). See Morpurgo Davies (1975; 1998) for this historical background. An admiration of the ‘analytic’ in language was a growing sentiment among linguists and language constructors in the early twentieth century, finding its most articulate and strident expression in the work of Otto Jespersen (1860–1943; see Jespersen 1894; 1922; 1962[1941]). See also Falk (1995:245-246; 1999:57-58, 61-66), and Joseph and Newmeyer (2012) for discussion of the broader context.11 ‘Adelyne More’ was one of Ogden’s numerous pseudonyms. See Gordon (1990:136, notes 5 and 6) for discussion.12 Only 200 of the 600 ‘things’ in the Basic core vocabulary are explicitly marked as ‘pictured’, but Ogden’s efforts to realise the ‘pictorial method’ for Basic would lead to his collaboration with the Vienna Circle philosopher Otto Neurath (1882–1945) on ‘Isotype’, a pictographic system originally designed for representing statistics, and later extended to other uses (see McElvenny 2013). Richards went on to independently develop methods of teaching Basic using comics and animated cartoons, for which he spent the northern summer of 1942 at Walt Disney Studios in California to receive instruction in the relevant techniques (Russo 1989:436).91929b:21). So, for example, in the place of ‘coy’ we describe the behaviour by which we recognise a coy woman: ‘one who does not put forward her female attractions, or who does not give herself away readily to men’ (loc. cit.). Similarly, ‘barbaric’ is ‘like the natives of Central Africa or the South Sea Islands’, and ‘envious’ is ‘feelings about some one in a much desired position’ (loc. cit.). The most undesirable part of speech is the verb, since it typically conflates many functions in a single inscrutable package. At its most extreme, argued Ogden, a verb can include all of an ‘operation’, an ‘object’ and a ‘direction’, as in the case of ‘disembark’, analytically paraphrased as ‘get [operation] off [direction] a ship [object]’. In the various systems of tenses, moods and aspects attached to them, verbs also harbour the most formal complexity and irregularity among the parts ofspeech. Ogden (1929a:3; repeated in Ogden 1933[1930]:19-20) states: ‘When the most necessary names, the most fundamental operators and the essential directives have been determined, it can be shown that a verb is primarily a symbolic device for telescoping an operation and an object or a direction (“enter” for go into). Sometimes an operator, a directive and a name are thus telescoped, as in the odd word “disembark” (get, off, a ship) ; Latin goes so far as to throw in a pronoun, and a tense auxiliary.’ Simultaneously reinforcing his naturalised grammatical scheme and his faith in English as its surest medium, especially in its American varieties, he adds:So long as the essentially contractive nature of the verb was concealed by the existing grammatical definitions, there could be no reduction in the vocabulary sufficiently radical to affect the problem of a Universal Language, nor is this now possible in any language other than English ; and it is the continuous approximation of East and West (especially in its latest American developments), which makes this particular form of English basic for the whole world.(Ogden 1929a:4; emphasis original; see also Ogden 1933[1930]:53-54)The solution to the evils of verbs lies in dissecting them to reveal their semantic parts. This is the ‘the chief grammatical provision for substitution in the grammar of Basic’ (Ogden 1929b:17). The result is the ‘operators’ of Basic (come, do, get, give, go, keep, let, make, put, take, send, say, seem, see), which are supported by two auxiliaries (be, have), which can also act as operators (see Ogden 1932a:20-24; 1933[1930]:53-60). These operators can be combined with ‘directives’ (prepositions) and ‘things’ (nouns) to paraphrase any verb in Standard English: for the Standard English word ‘insert’ Basic has the operator-directive equivalent put in. With a variety of different ‘things’ this can replace many more Standard English verbs, such as ‘put (a word) in = “interject”, put (an account) in = “render”, put (the tea) in = “infuse”, put (the sheep) in = “fold”, put (a request) in = “file”, put (a seed) in (the earth) = “plant”, put (the baby) in (the bath) = “immerse”, put (things) in (a house) = “install”, and so forth’ (Ogden 1933[1930]:54-55). As we might expect in light of the role of Standard English idiom in word derivation (see section 3 above), the range of objects that can collocate with these operator-directive paraphrases – and the sense they take on in these collocations – follows the usage of the corresponding phrasal verb in the standard language, drastically restricting the freedom and true compositionality of this technique.Even though the parts of speech have been rechristened with their semantic labels, they continue to follow the full morphological patterns of their Standard English equivalents, including all 10irregularities. ‘Things’ exhibit number inflection (including the distinction between mass and count nouns, irregular and semi-irregular forms such as ‘feet’ and ‘knives’, and forms that have zero inflection, such as ‘sheep’, or are always formally plural, such as ‘trousers’ and ‘scissors’; Ogden 1932a:10); the ‘operators’, like English verbs, agree with their subjects and have all the same tenses, including compound tenses with be and have auxiliaries; the ‘qualities’ have periphrastic comparative and superlative forms when they are more than one syllable long, or the endings -er and -est when only one syllable (with some exceptions: bent, like, wrong, early; Ogden 1933[1930]:51-52); and the pronouns inflect for case (Ogden 1932a:73-77). ‘These facts may be sad,’ Ogden (1932a:10) tells us in Basic, ‘but what are seven [irregular noun forms] among such a number?’ But, so claimed Ogden, the natural ‘analytic tendency’ of Standard English would quickly eliminate these ‘sad facts’ in the standard language, and in its derivative, Basic. This minor unpleasantness in Standard English idiom should soon disappear:[… I]t is an historical accident that the operator group still inflect. If put and take had developed as far as the model word cut, only the regular third person singular would differentiate them from the similar roots in an analytic language like Chinese. ‘I cut,’ ‘we cut,’ ‘they cut’ – today and yesterday – ‘I have cut,’ ‘the cake is cut,’ ‘a cut cake,’ ‘acut off the cake,’ and so on. But ‘he cuts.’ This lamentable and unmannerly hissing about a third person has been characterized by Sir Richard Paget as un-English. It wouldprobably have disappeared long ago in the normal course of events had not printers, lexicographers, and schoolmasters rallied so egregiously to its defence ; and if any reform is overdue in our accidence, here is surely an appropriate casualty.In due course, all irregular plurals and possibly all plurals – since we have already learntto dispense with sheeps – might well follow it.(Ogden 1936:57; see also Ogden 1931:30-31)13Grammatical reform, Ogden insisted, could only proceed in a piecemeal fashion. The various failed attempts at English spelling reform show us how futile it is to overhaul a single aspect of the language at once. The only hope for Basic, and for Standard English, would be to isolate a reasonably well-behaved subset of the language and rely on the natural analytic tendency and the further simplifications of learners to effect grammatical reform: ‘Basic, then, offers us for the first time a rational incentive to reform the essentials by degrees’ (Ogden 1936:58-59). Complete changecould propagate to the entire system quite rapidly – ‘in a single generation’ – in this modern age of ‘printing, radio, and world-travel’. This could occur, says Ogden (1931:30-31), wryly expressing hisappreciation of American idiom, ‘[…] with much less of a shock than the average Englishman experiences when confronted by a youthful American – whose more elastic phraseology is nevertheless perfectly intelligible to him. He is slowly learning to “get busy” and “put over” his own “concepts”. “Right now” his “co-ed” offspring are “talkie fans” ; they get “psyched” and knowall the “dope” - “and then some”.’ American English, according to Ogden, is the leading dialect in the analytic tendency. Later reflecting on work he had done in removing ‘Americanisms’ from a textfor an English audience, Ogden ‘was unable to get away from the feeling that this foolish process 13 The example of ‘cut’ is probably due to Jespersen (1922:333).11was like putting wax lights back into a Club because certain old men had not got used to the electricsystem. But it was worse than a waste of time. From the point of view of an International Language it was clearly a step in the wrong direction’ (Ogden 1993[1932]:42).With the words and their behaviour in place, all that remained was putting them together to makesentences. To this end Ogden offered a simple schematic syntax based on that of Standard English. This would be imparted principally through ‘model sentences’, which are supposed to exhibit the full range of possible syntactic permutations. Several of these model sentences appear in the Basic pedagogic literature, and two of them, which are intended to illustrate maximally expanded sentences, where every possible sentence position is filled, appear in the fold-out list of the 850 words in all Basic books: ‘The camera man who made an attempt to take a moving picture of the society women, before they got their hats off, did not get off the ship till he was questioned by the police,’ and ‘We will give simple rules to you now.’ In this connection Ogden invoked the ‘panoptic’ principle once again with his own ‘panopticon’, or ‘Basic Word Wheel’ (shown in Figure3). Each of the concentric discs of Ogden’s panopticon contains all words of one part of speech, andby rotating them it is possible to make grammatically correct sentences. Figure 3. Ogden’s Panopticon (Ogden 1932a:183)125. ConclusionWhile only ever a minor international language project, Basic English is of interest as an implementation of Ogden’s semiotic theory. The design of Basic, in terms of both its vocabulary and grammar, rests on principles and techniques first outlined in Ogden and Richards’ The Meaningof Meaning. In Basic, Ogden strove to create a language reliable in reference, which guides its speakers around the pitfalls of word-magic. Panoptic conjugation, the method for selecting the Basic vocabulary, was simply an implementation of the method of definition proposed in The Meaning of Meaning. The treatment of grammar as a mere outgrowth of vocabulary, and the ‘analytic’ properties sought in its structure, are similarly ideas that first find expression in Ogden and Richards’ book. As a design for an international language, we see that Ogden’s approach perhaps falls short. Basic is simply an extract from Standard English and, while Ogden’s semiotic theory might provide a basis for selecting the material to be extracted, it leaves many details of word formation and grammar undetermined, making Basic parasitic on Standard English idiom. Forhis part, Ogden discounted these difficulties, insisting that the structure of Standard English already had most of the qualities his theory would demand, and where it was deficient its ‘analytic tendency’ would soon make amends.ReferencesAiken, Janet Rankin. 1944[1936]. ‘Little English’. Johnsen (1944:142-147).Bentham, A Jeremy. 1843[1791]. ‘Panopticon; or, the Inspection-House’. The Works of Jeremy Bentham, vol. IV, ed. by John Bowring, 39-66. Edinburgh: William Tate.Brower, Reuben, Helen Vendler and John Hollander, eds. 1973. I. A. Richards: essays in his honor. New York: Oxford University Press.Falk, Julia S. 1995. ‘Words without grammar: linguists and the international auxiliary language movement in the United States’. Language and Communication 15.241-59.—. 1999. Women, Language and Linguistics: three American stories from the first half of the twentieth century. London: Routledge.Gordon, W. Terrence. 1990. C. K. Ogden: a bio-bibliographic study. Metuchen, N.J.: The Scarecrow Press.—. 1991. ‘From “The Meaning of Meaning” to Basic English’. ETC: A Review of General Semantics 48:2.165-171.—. 1994. C. K. Ogden and Linguistics, 5 volumes. London: Routledge / Thoemmes Press.—. 2006. ‘Linguistics and semiotics I: the impact of Ogden and Richards’ The Meaning of Meaning’. History of the Language Sciences, vol. 3, ed. by Sylvain Auroux, E.F.K. Koerner, Hans-Josef Niederehe and K. Versteegh, 2579-2588. Berlin: Walter de Gruyter.Hotopf, W.H.N. 1965. Language, Thought and Comprehension: a case study of the writings of I. A. Richards. London: Routledge and Kegan Paul.Jespersen, Otto. 1894. Progress in Language. London: S. Sonnenschein.—. 1922. Language: its nature, development, and origin. London: Allen and Unwin.13—. 1962[1941]. ‘Efficiency in Linguistic Change’. The Selected Writings of Otto Jespersen, 381-466. London: Allen and Unwin. (Original published Copenhagen: Ejnar Munksgaard.)Johnsen, Julia E., ed. 1944. Basic English. New York: H.W. Wilson.Joseph, John E. and Frederick J. Newmeyer. 2012. ‘“All languages are equally complex”: the rise and fall of a consensus’. Historiographia Linguistica 39:2/3.341-368.Lockhart, Leonora Wilhelmina. 1928. ‘Word formation’. Psyche 9:2.8-12.—. 1931. Word Economy. London: Kegan Paul.McElvenny, James. 2013. ‘International language and the everyday: contact and collaboration between C.K. Ogden, Rudolf Carnap and Otto Neurath’. British Journal for the History of Philosophy 21:6.1194-1218.—. 2014. ‘Ogden and Richards’ The Meaning of Meaning and early analytic philosophy’. LanguageSciences 41.212-221.More, Adelyne [pseudonym of C. K. Ogden]. 1929. ‘The theory of fictions’. Psyche 10:1.31-38.Morpurgo Davies, Anne. 1975. ‘Language classification in the nineteenth century’. Current trends in linguistics: historiography of linguistics, ed. by Thomas A. Sebeok, 607-716. The Hague: Mouton.—. 1998. History of Linguistics, vol. 4: nineteenth-century linguistics. London: Longman.Myers, Adolph. 1938. Basic and the Teaching of English in India. Bombay: The Times of India Press.Nerlich, Brigitte. 1992. Semantic Theories in Europe, 1830–1930: from etymology to contextuality. Amsterdam: John Benjamins.Ogden, Charles Kay. 1928. ‘Debabelization (editorial)’. Psyche 9:1.1-3.—. 1929a. ‘The universal language (editorial)’. Psyche 9:3.1-9.—. 1929b. ‘Work in progress (editorial)’. Psyche 10:1.1-30.—. 1929c. ‘Editorial’. Psyche 10:2.1-38.—. 1930. ‘Penultima (editorial)’. Psyche 10:3.1-29.—. 1931. Debabelization. London: Kegan Paul.—. 1932a. The ABC of Basic English. London: Kegan Paul.—. 1932b. The Basic Words: a detailed account of their uses. London: Kegan Paul.—. 1932c. The Basic Dictionary. London: Kegan Paul.—. 1932d. Bentham’s Theory of Fictions. London: Kegan Paul.—. 1933[1930]. Basic English: a general introduction with rules and grammar. London: Kegan Paul.—. 1936. ‘Basic English and grammatical reform’. Psyche 16.51-75. (Reprinted as supplement to the basic news 1937.)—. 1993[1932]. Jeremy Bentham: 1832–2032. Bristol: Thoemmes Press. (Original published London: Kegan Paul.)—. 1968. Basic English: international second language, prepared by E.C. Graham. New York: Harcourt, Brace and World.Ogden, Charles Kay and Ivor Armstrong Richards. 1989[1923]. The Meaning of Meaning. San 14Diego: Harcourt Brace Jovanovich. (Original published London: Kegan Paul.)Richards, Ivor Armstrong. 1943. Basic English and its Uses. London: Kegan Paul.—. 1977. ‘Co-author of the “Meaning of Meaning”’. C.K. Ogden: a collective memoir, ed. By P. Sargant Florence and J.R.L. Anderson, 96-109. London: Pemberton.Russo, Paul. 1989. I.A. Richards: his life and work. Baltimore: John Hopkins University Press.Swadesh, Morris. 1944. ‘Scientific linguistics and Basic English’. Johnsen (1944:194-206).—. 1955. ‘Towards greater accuracy in lexicostatistic dating’. International Journal of American Linguistics 21.121-137.—. 1972. The Origin and Diversification of Language. London: Routledge.Walpole, H. 1937. ‘The theory of definition and its application to vocabulary limitation’. The Modern Language Journal 21.398-402.West, Michael. 1944[1939]. ‘Vocabulary limitation’. Johnsen (1944:148-152). (Original in Journal of Education 71.582-584.)15